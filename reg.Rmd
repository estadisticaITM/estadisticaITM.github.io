---
title: "Regresión lineal"
output:
  html_document:
    toc: true
    toc_depth: 5
    #toc_float:
     # collapsed: falsed
      #smooth_scroll: true
---



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## Gráfico de dispersión

Diagrama matemático que utiliza las coordenadas cartesianas para mostrar los valores de dos variables cuantitativas, de la forma (x,y), aunque también se puede incluir una variable cualitativa.
Sirve para la detección de puntos atípicos.




En el siguiente diagrama se ilustra la presión atmosférica en relación a la temperatura

```{r pressure, echo = TRUE}
plot(pressure)

```




En el siguiente diagrama se ilustra el ancho y el largo de la hoja en relación al tipo de planta.

```{r}
library(ggplot2)
p <- ggplot(iris, aes(x = Petal.Length, y = Petal.Width, colour = Species))

p <- p + geom_point()
p


```

### Actividad

Elabore en su cuaderno un gráfico de dispersión de los siguientes datos, identificando con colores diferentes  el tipo de tapa.

|Hojas  |Peso|Tipo de tapa|
|-------|----|------------|
|885 |800 | dura |
|1016|950 | dura |
|1125|1050| dura |
|239 |350 |dura  |
|701 |750 |dura  |
|641 |600 |dura  |
|1228|1075|dura  |
|412 |250 |blanda|
|953 |700 |blanda|
|929 |650 |blanda|
|1492|975 |blanda|
|419 |350 |blanda|
|1010|950 |blanda|
|595 |425 |blanda|
|1034|725 |blanda|



## Regresión lineal 

Permite establecer asociaciones entre variables de interés, entre las cuáles la relación usual no es necesariamente de causa efecto.

El objetivo es obtener estimaciones razonables de Y para distintos valores de X a partir de una muestra de n pares de valores (x1, y1), . . . ,(xn, yn).



## Algunos ejemplos

- Estudiar cómo influye la estatura del padre sobre la estatura del hijo. 

- Estimar el precio de una vivienda en función de su área.

- Estudiar la relación entre el estrato de la vivienda y el pago del impuesto predial 


## Antes de hacer un modelo de regresión lineal

Se deben identificar observaciones extremas, alejadas hacia valores muy grandes o pequeños comparadas con el resto de valores, que puedan influenciar en la estimación de los parámetros del ajuste de regresión.

## Modelo de regresión lineal básico

El modelo más simple de regresión corresponde a: 

$$\Large y_i=\beta_0 +\beta_1 X_i+\varepsilon_i$$
Donde:

$\Large y_i$Es la variable respuesta o dependiente para la i-ésima observación\


$\Large \beta_0$ Intercepto\


$\Large\beta_1$ Pendiente\


$\Large X_i$ Variable predictora independiente para la i-ésima observación\


$\Large \varepsilon_i$ Error aleatorio para la i-ésima observación\


$$\Large \varepsilon_i \sim N (0,\sigma^2)$$


## Objetivos de la regresión lineal

- Construir un modelo que describa el efecto o relación entre una variable X sobre otra variable Y. 

- Obtener estimaciones puntuales de los parámetros de dicho modelo. 

- Estimar el valor promedio de Y para un valor de X 

- Predecir futuros de la variable respuesta Y


# Medidas de dependencia lineal

## Covarianza

La covarianza indica el grado de variación conjunta de dos variables aleatorias respecto a sus medias

$$\Large cov(x,y)=\frac{\sum_{i=1}^{n}(x_i-\bar{x})(y_i-\bar{y})}{(n-1)}$$
- Si hay relación lineal positiva, la covarianza será positiva y grande.

- Si hay relación lineal negativa, la covarianza será negativa y grande en valor absoluto.

- Si no hay relación entre las variables la covarianza será próxima a cero.

- La covarianza depende de las unidades de medida de las variables.

## Coeficiente de correlación

Indica la fuerza y la dirección de una relación lineal y proporcionalidad entre dos variables cuantitativas estadísticas, la fórmula es:


$$\Large cor(x,y)=\frac{\sum_{i=1}^{n}(x_i-\bar{x})(y_i-\bar{y})}
{\sqrt{\sum_{i=1}^{n}(x_i-\bar{x})^2\sum_{i=1}^{n}(y_i-\bar{y})^2 }}$$



## Características del coeficiente de correlación

- Rango entre -1 y 1

- Valores cercanos a -1 la relación es fuertemente negativa.

- Valores cercanos a 1 la relación es fuertemente positiva.

- Valores cercanos a 0 la relación es débil, es decir no hay una relación lineal


```{r fig.asp=0.8, fig.align='right', echo=FALSE}
library(png)
library(grid)
IM <- readPNG("corre.png")
grid.raster(IM)
```


## Medida de bondad de ajuste R^2

El coeficiente determina la calidad del modelo para replicar los resultados. Mide la proporción de la variabilidad total observada en la respuesta que es explicada por la asociación lineal.
En regresión lineal el R cuadrado es simplemente el cuadrado del coeficiente de correlación de Pearson, Por ser una proporción, esta cantidad varía entre 0 y 1, mientras más cercano sea a uno mejor.

## Estimador de mínimos cuadrados
Gauss propuso en 1809 el método de mínimos cuadrados para obtener los valores $\hat{\beta_0}, \hat {\beta_1}$ que mejor se ajustan a los datos:

$$\Large y_i=\beta_0+\beta_1x_i+\varepsilon_i$$

El método consiste en minimizar la suma de los cuadrados de las distancias verticales entre los datos y las estimaciones, es decir, minimizar la suma de los residuos al cuadrado:

$$\sum_{i=1}^n(y_i-\hat{y_i})^2=
\sum_{i=1}^n (y_i-(\hat{\beta_0}+ \hat{\beta_1}x_i))^2$$

El resultado que se obtiene es:

$$\Large \hat{\beta_1}=\frac{S_{xy}}{S_{xx}}=\frac{cov(x,y)}{S_{xx}}=\frac{\sum_{i=1}^{n}(x_i-\bar{x})(y_i-\bar{y})}{\sum_{i=1}^{n}(x_i-\bar{x})^2}$$

A las cantidades $\Large S_{xx}$ y $\Large S_{xy}$ se les conoce como suma corregida de cuadrados y suma corregida de productos cruzados de x y y, respectivamente

$$\Large \hat{\beta_0}=\bar{y}-\hat{\beta_1}\bar{x}$$

```{r fig.asp=0.5, fig.align='right', echo=FALSE}
library(png)
library(grid)
IM3 <- readPNG("mc.png")
grid.raster(IM3)
```



## Residuales

La diferencia de cada valor $y_i$ de la variable respuesta y su estimación $\hat{y_i}$ se llama residuo.
$$\Large \varepsilon_i= y_i- \hat{y_i}$$



```{r fig.asp=0.5, fig.align='right', echo=FALSE}
library(png)
library(grid)
IM4 <- readPNG("img4.png")
grid.raster(IM4)
```


## Cómo obtener un modelo de regresión lineal simple 


- Cómo estimar un modelo de regresión lineal en la calculadora

<iframe width="560" height="315" src="https://www.youtube.com/embed/4_WO31Dapv0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

- Cómo estimar un modelo de regresión lineal en Excel

<iframe width="560" height="315" src="https://www.youtube.com/embed/O7iPNwfZFcE" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>




## Regresión lineal múltiple

Considere el caso en el cual se desea modelar la variabilidad total de una variable respuesta de interés, en función de relaciones lineales con dos o más variables predictoras, cuantitativas o cualitativas, formuladas simultáneamente en un único modelo. Suponemos en principio que las variables predictoras guardan poca asociación lineal entre sí, es decir, cada variable predictora aporta información independiente de las demás predictoras presentes en el modelo (hasta cierto grado, la información aportada por cada una no es redundante). La ecuación del modelo de regresión en este caso es:

$$\Large y_i=\beta_0+\beta_1x_{i1}+\beta_2x_{i2}+...+\beta_kx_{ik}\varepsilon_i$$

## Tipos de variables y de efectos en los modelos

Las variables predictoras pueden ser:

- Cuantitativas, caso en el cual se supone se miden sin error (o el error es despreciable).

- Cualitativas o categóricas, en este caso su manejo en el modelo se realiza a través de la definición de variables  indicadoras, las cuales toman valores de 0 ó 1. 



Por ejemplo, suponga que en un modelo de regresión para el gasto mensual por familia en actividades recreativas, se tiene entre las variables predictoras el estrato socioeconómico, definido en cinco niveles, luego, para cada nivel se define una variable indicadora de la siguiente forma:


Estrato 1:
$$ \Large  I_1 =\left\lbrace \begin{array}{rcl}
            {1\quad familia \quad estrato \quad 1}
         \\
            {0 \quad En \quad otro \quad caso  }
         \end{array}  \right. $$
         

Estrato 2

$$ \Large   I_2 =\left\lbrace   \begin{array}{rcl}
            {1\quad familia \quad estrato \quad 2}
            \\
            {0 \quad En \quad otro \quad caso  }
         \end{array}  \right.          $$
Estrato 3

$$ \Large  I_3 =\left\lbrace   \begin{array}{rcl}
            {1\quad familia \quad estrato \quad 3}
         \\
            {0 \quad En \quad otro \quad caso  }
         \end{array}  \right.  $$
  
  Estrato 4
$$    \Large I_4 =\left\lbrace   \begin{array}{rcl}
            {1\quad familia \quad estrato \quad 4}
         \\
            {0 \quad En \quad otro \quad caso  }
         \end{array}  \right.$$
  

En general, una variable cualitativa con c clases se representa mediante c -1 variables indicadoras, puesto que cuando en una observación dada, todas las c-1 primeras indicadoras son iguales a cero, entonces la variable cualitativa se haya en su última clase. En el ejemplo anterior basta definir las primeras cuatro indicadoras.


<iframe width="560" height="315" src="https://www.youtube.com/embed/eG5tI6aYgos" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>




## Ejemplo:

La siguiente base de datos relaciona 7 medidas del crecimiento de 5 tipos de arboles en el tiempo en meses y el diámetro en mm.

```{r echo = TRUE}

head (Orange)


```

El diagrama de dispersión simple es:

```{r echo = TRUE}
plot(Orange$age,Orange$circumference,lwd=3)
```

El modelo de regresión lineal simple corresponde a:

```{r echo = TRUE}

model=lm(Orange$circumference~Orange$age)
summary(model)

```

La ecuación del modelo de regresión general es:

$$\Large \hat y_i=17.4+0.1x_{i}$$
Donde $y_i$ es la circunferenciua del

La linea de regresión ajustada corresponde a

```{r echo = TRUE}

model=lm(Orange$circumference~Orange$age)


plot(Orange$age,Orange$circumference,lwd=3)

yest=fitted(model)
lines(Orange$age,yest,col=2)
abline(coef(model))


```

## Significado de la pendiente y el intercepto

El intercepto es la respuesta media observada en el crecimiento de los arboles.

La  péndiente indica que por cada mes que pasa la circunferencia del arbol aumenta 0.1 unidades


El diagrama de dispersión discriminando por los niveles de la variables factor es:

```{r echo = TRUE }
plot(Orange$age,Orange$circumference,col=Orange$Tree,lwd=3)

```

El modelo de regresión lineal con factores corresponde a 
```{r echo = TRUE}

model=lm(Orange$circumference~Orange$age+as.factor(Orange$Tree))
summary(model)

```


La recta general del modelo es:

$$\Large \hat y_i=17.4+0.1x_{i}+39.93arbol2_i+2.51arbol3_i-8.26arbol4_i-4.69arbol5_i$$

Las rectas ajustadas para cada arbol son:



Arbol 1:

$$\Large \hat y_i=17.4+0.1x_{i}$$

Arbol 2:
     $$\Large \hat y_i=57.33+0.1x_{i}$$
Arbol 3:
     $$\Large \hat y_i=19.92+0.1x_{i}$$

Arbol 4:
     $$\Large \hat y_i=9.14+0.1x_{i}$$
Arbol 5:
     $$\Large \hat y_i=12.71+0.1x_{i}$$




