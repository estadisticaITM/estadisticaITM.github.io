---
title: "COMPONENTES PRINCIPALES"
---

- Un problema central en el análisis de datos multivariantes es la reducción de la dimensionalidad

- Es posible describir con precisión los valores de p variables por un pequeño subconjunto r < p de ellas, reduciendo la dimensión del problema a costa de una pequeña pérdida de información.

- Objetivo: dadas n observaciones de p variables, se analiza si es posible representar adecuadamente esta información con un número menor de variables construidas como combinaciones lineales de las originales. 


Por ejemplo, con variables con alta dependencia es frecuente que un pequeño número de nuevas variables (menos del 20% de las originales ) expliquen la mayor parte (más del 80%) de la variabilidad original.

Su utilidad es doble:

1. Permite representar óptimamente en un espacio de dimensión pequeña, observaciones de un espacio general p-dimensional. Es el primer paso para identificar posibles variables **latentes** o no observadas, que están generando la variabilidad de los datos.

2. Permite transformar las variables originales correlacionadas, en nuevas variables incorrelacionadas, facilitando la interpretación de los datos.

La primera componente tiene la mayor varianza posible para una combinación lineal de las variables originales, la segunda componente tiene la segunda mayor varianza posible para una combinación lineal pero ortogonal a la primera componente, etc.


Antes de realizar un ACP se debe tomar la desición si trabajar con los datos originales o se se debe estandarizar cada variable a una media de cero y varianza unidad. Si las variables no se estandarizan y una variable tiene una varianza mas grande, entonces esta variable controlará la primera componente principal. la estandarización hace que todas las variables tengan el mismo peso. La fórmula para realizar la estandarización es

$$\Large X_i=\frac{x_i-\bar x}{\sigma}$$



Donde:

- $\large X_i$ es cada observación

- $\Large \bar x$ es la media del vector

- $\Large \sigma$ es la desviación estándar del conjunto de datos




sea x un vector aleatorio con k componentes $\Large E(x)=\mu$ y $\large var-cov(x)=D(x)=\sum _x>0$.

Hay un famoso teorema en álgebra lineal que nos permite factorizar matrices simétricas, digamos $\sum$como:

$$\large \sum=\Gamma \Lambda \Gamma'  $$

Donde $\Large \Lambda$ es una matriz diagonal con las raíces propias de $\Large \sum$ y $\Large  \Gamma=[\gamma_1,\gamma_2,...,\gamma_k]$ que contiene los vectores propios de $\Large \sum$



$$\large \Lambda=
\left[ \begin{array}{cccc}
\lambda_1 & 0  & \cdots & 0\\ 
0 & \lambda_2  & \cdots & 0 \\
\vdots & \vdots& \ddots & \vdots \\
0 & 0 & \cdots & \lambda_k
\end{array}\right]$$

Donde $\Large \lambda_1\geq \lambda_2 \geq\cdots \geq \lambda_k$

Consideremos la transformación lineal:

$$\Large y=\Gamma (x-\mu)$$
La idea es encontrar $\Large y_k$ componentes principales  que sean combinaciones lineales de las $\Large x_i$ variables originales que describen cada muestra, es decir:

$$\Large y_1=\gamma_{11}x_1+\gamma_{12}x_2+\cdots+\gamma_{1k}x_k$$



$$\Large y_2=\gamma_{21}x_1+\gamma_{22}x_2+\cdots+\gamma_{2k}x_k$$
$$\Large y_k=\gamma_{k1}x_1+\gamma_{k2}x_2+\cdots+\gamma_{kk}x_k$$



Se define 

$$ \Large y=\left
[\begin{array}{l}
y_1 \\ 
y_2\\
\vdots\\
y_k
\end{array}\right]=A'(x-\mu)$$

$$\Large z_i=\frac{y_i}{\sqrt \lambda_i}$$
con $i=1,...k$ estas variables serán llamadas las componentes principales estandarizadas de x. La varianza de $y_i$ sería

$$\large var(y_i)=\gamma_i'\sum \gamma_i=\lambda_i$$
La covarianza de las variables sería:

$$\large cov(y_i,y_j)=\gamma_i'\sum \gamma_j=0$$

## **¿Cuántas componentes conservamos?**

Se recomienda tomar varios aspectos en cuenta:

- Objetivo de la reducción de dimensionalidad. 

- Si por ejemplo, pretendemos construir un indicador, obviamente el número a retener es solo de una componente.

- Si no es claro, entonces consideramos las primera j componentes que posean el 80% de la variabilidad total.

## Videos



### Explicación de componentes principales en 5 minutos

<iframe width="280" height="158" src="https://www.youtube.com/embed/HMOI_lkzW08" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>


### Video completo de componentes principales

<iframe width="280" height="158" src="https://www.youtube.com/embed/FgakZw6K1QQ" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>


## **EJEMPLO**

La siguiente base de datos proporciona las intensidades relativas de emisión de fluoresencia a cuatro longitudes de ondas diferentes (300,350,400,450) para 12 compuestos.

1. Realizar un análisis descriptivo y de conglomerados para detectar posibles correlaciones.

```{r}


compuesto=as.factor(letters[1:12])
tress=c(16,15,14,15,14,14,17,16,15,17,18,18)
tress50=c(62,60,59,61,60,59,63,62,60,63,62,64)
cuat=c(67,69,68,71,70,69,68,69,72,69,68,67)
cuat50=c(27,31,31,31,30,30,29,28,30,27,28,29)

y=data.frame(tress,tress50,cuat,cuat50)

y
cor(y)
plot(y)

##conglomerados

y=data.frame(compuesto,tress,tress50,cuat,cuat50)
#matriz de dist
dist(y,method = "euclidean")

hc <- hclust(dist(y), "ave")

dend1 <- as.dendrogram(hc)

op <- par(mfrow= c(2,2), mar = c(3,3,1,1))

plot(dend1)

plot(dend1, nodePar=list(pch = c(1,NA),cex=0.8),type = "t", center=TRUE)

plot(dend1, edgePar=list(col = 1:2, lty = 2:3),edge.root = TRUE)

plot(dend1, nodePar=list(pch = 2:1,cex=.4*2:1,col = 2:3), horiz = TRUE)



```



2. **Modelo de componentes principales**

- Para este ejemplo habrá cuatro componentes principales  $Z_1, Z_2, Z_3, Z_4$, cada una de las cuales será una combinación lineal de $X_1,X_2,X_3, X_4$ las intensidades de fluorescencia a las longitudes de onda proporcionadas.

- Los coeficientes de las ecuaciones de componentes principales están determinadas de manera que las nuevas variables, a diferencia de las variables originales no se encuentren correlacionadas unas con otras.

- La generación de un nuevo conjunto de variables parece tener poco sentido porque se generan otras 4 variables nuevas, en lugar de las 4 variables originales.

- Las componentes principales también se eligen de manera que la primera componente principal $Z_1$recoge la mayor parte de variación que hay en el conjunto de datos, la segunda recoje la siguiente mayor parte de la variación y así sucesivamente.

- Por consiguiente, cuando haya correlación significativa el numero de componentes útiles será mucho menor que el número de variables originales



```{r}



compuesto=as.factor(letters[1:12])
tress=c(16,15,14,15,14,14,17,16,15,17,18,18)
tress50=c(62,60,59,61,60,59,63,62,60,63,62,64)
cuat=c(67,69,68,71,70,69,68,69,72,69,68,67)
cuat50=c(27,31,31,31,30,30,29,28,30,27,28,29)

y=data.frame(tress,tress50,cuat,cuat50)

##Componentes principales

y=data.frame(scale(tress),scale(tress50),scale(cuat),scale(cuat50))
modelo<-princomp(y)
summary(modelo)
modelo
modelo$loadings
modelo$scores

screeplot(modelo)
plot(modelo)
plot(modelo$scores[,1],modelo$scores[,2])
abline(h=0)
abline(v=0)
##
par(mfrow=c(1,1))
biplot(modelo,col=c(2,4))

```

Siendo así las cuatro componentes principales corresponden a:

$\Large Z_1=0.547X_1+0.546X_2-0.4X_3-0.493X_4$ explicando el 72.01% de la varianza

$\Large Z_2=0.238X_1+0.3X_2-0.913X_3-0.145X_4$ explicando el 16.13% de la varianza


$\Large Z_3=0.395X_1+0.324X_2+0.856X_4$ explicando el 9.74% de la varianza

$\Large Z_4=0.7X_1-0.712X_2$ explicando el 2.1% de la varianza

Donde $X_1, X_2, X_3, X_4$ corresponden a las intensidades relativas estandarizadas a 300,350, 400 y 450 nm

## **INTERPRETACIÓN DE LOS COMPONENTES**

### Componentes de tamaño y forma

- Cuando existe una alta correlación positiva entre todas las variables, el primer componente principal tiene todas sus coordenadas del mismo signo y puede interpretarse como un promedio ponderado de todas las variables, interpretadóse como un **factor global de tamaño**. 

- Los restantes componentes se interpretan como **factores de forma** y con coordenadas positivas y negativas, que implica que contraponen unos grupos de variables frente a otros. 


- Se debe observar en cada componente cual tiene mayor valor

- Las coordenadas de una componente principal pueden agruparse según el signo, pueden omitirse aquellas que presentan valores por debajo de 0.1

- ** ¿Cuántas componentes elegir?** Seleccionar componentes hasta cubrir una proporción determinada de varianza, como el 80% o el 90%. Esta regla es arbitraria y debe aplicarse con cierto cuidado. Es posible que un único componente de tamaño recoja el 90% de la variabilidad y sin embargo pueden existir otros componentes que sean muy adecuados para explicar la forma de las variables.

- Es importante recordar que las covarianzas (o correlaciones) miden únicamente las relaciones lineales entre las variables. Cuando entre ellas existan relaciones fuertes no lineales el análisis de componentes principales puede dar una información muy parcial de las variables.

## **Otro ejemplo**



Se realizar un análisis de componentes principales sobre los resultados obtenidos en la competición de heptatlon femenino en los juegos de seul 1988, estos datos se encuentran en el paquete HSAUR2, y corresponden a los datos de 25 atletas sobre 8 variables.

- 100 m vallas (hurdles)
- Salto de altura (highjump)
- Lanzamiento de peso (shot)
- 200 m lisos (run200m)
- Salto de longitud (longjump)
- Lanzamiento de javalina (javelin)
- 800m (run800m)
- puntaje (score)

1. Instalar el paquete HSAUR2


2. Obtener los datos

```{r}
library("HSAUR2")
data.frame= heptathlon

```

3. recodificamos las pruebas relativas a las 3 carreras, vallas, 200m y 800m, restando el mayor valor en cada carrera, cada uno de los tiempos de los 35 atletas

```{r}
heptathlon$hurdles=max(heptathlon$hurdles)-heptathlon$hurdles
heptathlon$run200m=max(heptathlon$run200m)-heptathlon$run200m
heptathlon$run800m=max(heptathlon$run800m)-heptathlon$run800m


```


4. Realizar un diagrama de dispersión y calcular la matriz de correlaciones 


```{r}

plot(heptathlon[,-8])
round(cor(heptathlon[,-8]),2)
```

- ¿Qué observa? 
- ¿Entre que variables existe una correlación alta? 
- ¿Entre que variables existe una corelación débil?


5. Realicemos un análisis boxplot 


```{r}


boxplot(heptathlon[,-8])

boxplot(heptathlon$score)



```



- ¿Observa la existencia de puntos atípicos?
- De encontrar puntos atípicos que propone para solucionarlo?
- A que participante pertenece la observación atípica, porque tiene ese valor tan pequeño?

6. Vuelva a estimar la matriz de correlaciones, sin el punto atípico


```{r}
hep=heptathlon[-grep("PNG",rownames(heptathlon)),]
hep

plot(hep)
round(cor(heptathlon[,-8]),2)

```

- ¿Qué observa en cuanto a los valores de las correlaciones?

7. Al estar los resultados de las 7 pruebas en diversas escalas(metros,segundos), se deben normalizar las variables.

```{r}
hep1=scale(hep)

hep1
```

8. Con los datos normalizados podemos realizar un análisis cluster

```{r}
hep1=scale(hep)
hc <- hclust(dist(hep1[,-8]), "ave")

dend1 <- as.dendrogram(hc)

plot(dend1)


```


9. Análisis de componentes principales


```{r}
library("HSAUR2")


hep=heptathlon[-grep("PNG",rownames(heptathlon)),]
hep
hep1=scale(hep)


modelo<-princomp(hep1[,-8])
summary(modelo)
modelo
modelo$loadings


# modelo$scores PUNTAJES OBTENIDOS POR LAS VARIABLES EN CADA UNO DE LAS COMPOMPONENTES

```

Para efectos de escritura las variables fueron bautizadas así


|Variable|Traducción|Representación|
|--------|---------------|------------|
|hurdles |Barreras       |$\Large X_1$|
|highjump|Salto de altura|$\Large X_2$|
|shot    |           Tiro|$\Large X_3$|
|run200m |Corrida 200 m  |$\Large X_4$|
|longjump|Salto largo    |$\Large X_5$|
|Javelin |Javalina       |$\Large X_6$|
|run800m |Corrida 800m   |$\Large X_7$|
|Score   |Puntaje        |$\Large X_8$|





Las componentes principales estimadas corresponden a:

Componente 1:

$\large Z_1=0.45X_1+0.315X_2+0.4X_3+0.43X_4+0.45X_5+0.24X_6+0.3X_7$ explicando el 61.76% de la varianza
Esta componente es una media de todas las medidas obtenidas en heptátlon.

```{r}
barplot(modelo$loadings[1:7,1])

```

Componente 2:
$\large Z_2=-0.65X_2-0.18X_4-0.32X_6+0.657X_7$ explicando el 12.84% de la varianza
Esta componente contrapone el valor de la corrida de 800m con el salto de altura, la corrida de 200m y la javalina.
```{r}
barplot(modelo$loadings[1:7,2])
```



Componente 3:
$\large Z_3=0.174X_1+0.21X_2+0.153X_3-0.13X_4+0.27X_5-.881X_6-0.193X_7$ explicando el 11.85% de la varianza
Esta componente contrapone la javalina y la corrida de 800m con el resto de las variables


Componente 4:
$\large Z_4=-0.55X_2+0.548X_3+0.231X_4-0.574X_7$ explicando el 6.67% de la varianza

Componente 5:
$\large Z_5=0.2X_1-0.67X_3+0.62X_4+0.122X_5-0.32X_7$ explicando el 4.26% de la varianza

Componente 6:
$\large Z_6=0.847X_1-0.333X_4-0.383X_5$ explicando el 1.62% de la varianza

Componente 7:
$\large Z_7=-0.33X_2-0.23X_3-0.47X_4+0.75X_5+0.211X_7$ explicando el 0.9% de la varianza




10.Los gráficos resultantes corresponden a:


```{r }



screeplot(modelo)

plot(modelo$scores[,1],modelo$scores[,2])
abline(h=0)
abline(v=0)
##
par(mfrow=c(1,1))
biplot(modelo,col=c(2,4),cex=0.7)


```



10. Compare los resultados obtenidos


