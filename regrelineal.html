<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Regresión lineal</title>

<script src="site_libs/header-attrs-2.14/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/flatly.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />
<link href="site_libs/ionicons-2.0.1/css/ionicons.min.css" rel="stylesheet" />
<link rel="icon" type="image/png" href="images/favicon.png" />

<script type="text/javascript" src="js/rmarkdown.js"></script>

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-88209726-1', 'auto');
  ga('send', 'pageview');
</script>


<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}

.tocify-subheader {
  display: inline;
}
.tocify-subheader .tocify-item {
  font-size: 0.95em;
}

</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Estadística ITM</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="pagin1.html">
    <span class="fa fa-line-chart"></span>
     
    Est Básica
  </a>
</li>
<li>
  <a href="inf.html">
    <span class="fa fa-bar-chart-o"></span>
     
    Est inferencial
  </a>
</li>
<li>
  <a href="pagin2.html">
    <span class="fa fa-bar-chart-o"></span>
     
    Diseño de exp
  </a>
</li>
<li>
  <a href="pagin3.html">
    <span class="fa fa-pie-chart"></span>
     
    Análisis multivariado
  </a>
</li>
<li>
  <a href="about.html">
    <span class="fa fa-puzzle-piece"></span>
     
    Semillero de R
  </a>
</li>
<li>
  <a href="https://www.itm.edu.co">
    <span class="ion ion-university"></span>
     
  </a>
</li>
<li>
  <a href="https://github.com/estadisticaITM">
    <span class="fa fa-github"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore"><strong>Regresión lineal</strong></h1>

</div>


<div id="gráfico-de-dispersión" class="section level2">
<h2><strong>Gráfico de dispersión</strong></h2>
<p>Diagrama matemático que utiliza las coordenadas cartesianas para
mostrar los valores de dos variables cuantitativas, de la forma (x,y),
aunque también se puede incluir una variable cualitativa. Sirve para la
detección de puntos atípicos.</p>
<p>En el siguiente diagrama se ilustra la presión atmosférica en
relación a la temperatura</p>
<pre class="r"><code>plot(pressure)</code></pre>
<p><img src="regrelineal_files/figure-html/pressure-1.png" width="672" /></p>
<p>En el siguiente diagrama se ilustra el ancho y el largo de la hoja en
relación al tipo de planta.</p>
<pre class="r"><code>library(ggplot2)
p &lt;- ggplot(iris, aes(x = Petal.Length, y = Petal.Width, colour = Species))

p &lt;- p + geom_point()
p</code></pre>
<p><img src="regrelineal_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<p><strong>Actividad</strong></p>
<p>Elabore en su cuaderno un gráfico de dispersión de los siguientes
datos, identificando con colores diferentes el tipo de tapa.</p>
<table>
<thead>
<tr class="header">
<th>Hojas</th>
<th>Peso</th>
<th>Tipo de tapa</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>885</td>
<td>800</td>
<td>dura</td>
</tr>
<tr class="even">
<td>1016</td>
<td>950</td>
<td>dura</td>
</tr>
<tr class="odd">
<td>1125</td>
<td>1050</td>
<td>dura</td>
</tr>
<tr class="even">
<td>239</td>
<td>350</td>
<td>dura</td>
</tr>
<tr class="odd">
<td>701</td>
<td>750</td>
<td>dura</td>
</tr>
<tr class="even">
<td>641</td>
<td>600</td>
<td>dura</td>
</tr>
<tr class="odd">
<td>1228</td>
<td>1075</td>
<td>dura</td>
</tr>
<tr class="even">
<td>412</td>
<td>250</td>
<td>blanda</td>
</tr>
<tr class="odd">
<td>953</td>
<td>700</td>
<td>blanda</td>
</tr>
<tr class="even">
<td>929</td>
<td>650</td>
<td>blanda</td>
</tr>
<tr class="odd">
<td>1492</td>
<td>975</td>
<td>blanda</td>
</tr>
<tr class="even">
<td>419</td>
<td>350</td>
<td>blanda</td>
</tr>
<tr class="odd">
<td>1010</td>
<td>950</td>
<td>blanda</td>
</tr>
<tr class="even">
<td>595</td>
<td>425</td>
<td>blanda</td>
</tr>
<tr class="odd">
<td>1034</td>
<td>725</td>
<td>blanda</td>
</tr>
</tbody>
</table>
</div>
<div id="regresión-lineal-simple" class="section level2">
<h2><strong>Regresión lineal simple</strong></h2>
<p>Permite establecer asociaciones entre variables de interés, entre las
cuáles la relación usual no es necesariamente de causa efecto. El
objetivo es obtener estimaciones razonables de Y para distintos valores
de X a partir de una muestra de n pares de valores (x1, y1), . . . ,(xn,
yn).</p>
<p>El modelo más simple de regresión corresponde a: <span
class="math display">\[\Large y_i=\beta_0 +\beta_1
X_i+\varepsilon_i\]</span></p>
<p>Donde:</p>
<p><span class="math inline">\(\Large y_i\)</span>Es la variable
respuesta o dependiente para la i-ésima observación<br />
</p>
<p><span class="math inline">\(\Large \beta_0\)</span> Intercepto<br />
</p>
<p><span class="math inline">\(\Large \beta_1\)</span> Pendiente<br />
</p>
<p><span class="math inline">\(\Large X_i\)</span> Variable predictora
independiente para la i-ésima observación<br />
</p>
<p><span class="math inline">\(\Large \varepsilon_i\)</span> Error
aleatorio para la i-ésima observación<br />
</p>
<p><span class="math display">\[\Large \varepsilon_i \sim N
(0,\sigma^2)\]</span></p>
<p><strong>Objetivos de la regresión lineal</strong></p>
<ul>
<li><p>Construir un modelo que describa el efecto o relación entre una
variable X sobre otra variable Y.</p></li>
<li><p>Obtener estimaciones puntuales de los parámetros de dicho
modelo.</p></li>
<li><p>Estimar el valor promedio de Y para un valor de X</p></li>
<li><p>Predecir futuros de la variable respuesta Y</p></li>
</ul>
<p><strong>Ejemplos</strong></p>
<ul>
<li><p>Estudiar cómo influye la estatura del padre sobre la estatura del
hijo.</p></li>
<li><p>Estimar el precio de una vivienda en función de su área.</p></li>
<li><p>Aproximar la calificación obtenida en una materia según el numero
de horas de estudio semanal.</p></li>
</ul>
<div id="estimador-de-mínimos-cuadrados" class="section level3">
<h3>Estimador de mínimos cuadrados</h3>
<p>Gauss propuso en 1809 el método de mínimos cuadrados para obtener los
valores <span class="math inline">\(\hat{\beta_0}, \hat
{\beta_1}\)</span> que mejor se ajustan a los datos:</p>
<p><span class="math display">\[\Large
y_i=\beta_0+\beta_1x_i+\varepsilon_i\]</span></p>
<p>El método consiste en minimizar la suma de los cuadrados de las
distancias verticales entre los datos y las estimaciones, es decir,
minimizar la suma de los residuos al cuadrado:</p>
<p><span class="math display">\[\Large \sum_{i=1}^n(y_i-\hat{y_i})^2=
\sum_{i=1}^n (y_i-(\hat{\beta_0}+ \hat{\beta_1}x_i))^2\]</span></p>
<p>el resultado que se obtiene es:</p>
<p><span class="math display">\[\Large
\hat{\beta_1}=\frac{S_{xy}}{S_{xx}}=\frac{cov(x,y)}{S_{xx}}=\frac{\sum_{i=1}^{n}(x_i-\bar{x})(y_i-\bar{y})}{\sum_{i=1}^{n}(x_i-\bar{x})^2}\]</span></p>
<p>A las cantidades <span class="math inline">\(\Large S_{xx}\)</span> y
<span class="math inline">\(\Large S_{xy}\)</span> se les conoce como
suma corregida de cuadrados y suma corregida de productos cruzados de x
y y, respectivamente <span class="math display">\[\Large
\hat{\beta_0}=\bar{y}-\hat{\beta_1}\bar{x}\]</span></p>
<p><img src="regrelineal_files/figure-html/unnamed-chunk-2-1.png" width="672" style="display: block; margin: auto 0 auto auto;" />
<strong>Significado de <span class="math inline">\(\beta_0\)</span> y
<span class="math inline">\(\beta_1\)</span></strong></p>
<ul>
<li><p><span class="math inline">\(\Large \beta_0\)</span> es el
intercepto</p></li>
<li><p><span class="math inline">\(\Large \beta_1\)</span> es el valor
de la pendiente, es decir que por cada unidad que aumente la variable
independiente, la variable dependiente aumenta <span
class="math inline">\(\beta_1\)</span> unidades</p></li>
</ul>
</div>
<div id="residuales" class="section level3">
<h3>Residuales</h3>
<p>La diferencia de cada valor <span class="math inline">\(y_i\)</span>
de la variable respuesta y su estimación <span
class="math inline">\(\hat{y_i}\)</span> se llama residuo. <span
class="math display">\[\Large e_i= y_i- \hat{y_i}\]</span></p>
<p><img src="regrelineal_files/figure-html/unnamed-chunk-3-1.png" width="672" style="display: block; margin: auto 0 auto auto;" /></p>
</div>
</div>
<div id="medidas-de-dependencia-lineal" class="section level2">
<h2><strong>Medidas de dependencia lineal</strong></h2>
<div id="covarianza" class="section level3">
<h3>Covarianza</h3>
<p>La covarianza indica el grado de variación conjunta de dos variables
aleatorias respecto a sus medias</p>
<p><span class="math display">\[\Large
cov(x,y)=\frac{\sum_{i=1}^{n}(x_i-\bar{x})(y_i-\bar{y})}{(n-1)}\]</span>
- Si hay relación lineal positiva, la covarianza será positiva y
grande.</p>
<ul>
<li><p>Si hay relación lineal negativa, la covarianza será negativa y
grande en valor absoluto.</p></li>
<li><p>Si no hay relación entre las variables la covarianza será próxima
a cero.</p></li>
<li><p>La covarianza depende de las unidades de medida de las
variables.</p></li>
</ul>
</div>
<div id="coeficiente-de-correlación" class="section level3">
<h3>Coeficiente de correlación</h3>
<p>Indica la fuerza y la dirección de una relación lineal y
proporcionalidad entre dos variables cuantitativas estadísticas.</p>
<p><span class="math display">\[\Large
cor(x,y)=\frac{\sum_{i=1}^{n}(x_i-\bar{x})(y_i-\bar{y})}
{\sqrt{\sum_{i=1}^{n}(x_i-\bar{x})^2\sum_{i=1}^{n}(y_i-\bar{y})^2
}}\]</span></p>
<p><strong>Características del coeficiente de correlación</strong></p>
<ul>
<li><p>Rango entre -1 y 1</p></li>
<li><p>Valores cercanos a -1 la relación es fuertemente
negativa.</p></li>
<li><p>Valores cercanos a 1 la relación es fuertemente
positiva.</p></li>
<li><p>Valores cercanos a 0 la relación es débil, es decir no hay una
relación lineal</p></li>
</ul>
<table>
<thead>
<tr class="header">
<th align="center">Rangos de correlación (r)</th>
<th align="center">Grado de asociación</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">(0,0.2)</td>
<td align="center">Débil, sin relación</td>
</tr>
<tr class="even">
<td align="center">(0.2,0.4)</td>
<td align="center">Baja</td>
</tr>
<tr class="odd">
<td align="center">(0.4,0.6)</td>
<td align="center">Moderada</td>
</tr>
<tr class="even">
<td align="center">(0.6,0.8)</td>
<td align="center">Fuerte</td>
</tr>
<tr class="odd">
<td align="center">(0.8,1)</td>
<td align="center">Muy fuerte</td>
</tr>
</tbody>
</table>
<p><img src="imagen/cor.png" width="726" style="display: block; margin: auto;" /></p>
<p><strong>Prueba de significancia de la correlación</strong></p>
<p>Podemos chequear la significancia de la correlación a través del
siguiente juego de hipótesis.</p>
<p><span class="math display">\[\Large H_0:  r=0\]</span> <span
class="math display">\[\Large H_1:  r\not=0\]</span></p>
<p>En R usamos la función cor.test() para estudiar la significación
estadística del coeficiente y concluir sobre la posible existencia de
relación lineal entre las variables.</p>
<p><strong>Ejemplo</strong> Retomando el ejemplo de las flores, la base
de datos iris contiene diferentes variables cuantitativas, largo y ancho
del sépalo y largo y ancho del pétalo, asi como de las especies</p>
<p><img src="imagen/iris.png" width="534" style="display: block; margin: auto;" /></p>
<pre class="r"><code>head(iris)
#&gt;   Sepal.Length Sepal.Width Petal.Length Petal.Width Species
#&gt; 1          5.1         3.5          1.4         0.2  setosa
#&gt; 2          4.9         3.0          1.4         0.2  setosa
#&gt; 3          4.7         3.2          1.3         0.2  setosa
#&gt; 4          4.6         3.1          1.5         0.2  setosa
#&gt; 5          5.0         3.6          1.4         0.2  setosa
#&gt; 6          5.4         3.9          1.7         0.4  setosa

library(PerformanceAnalytics)
#&gt; Loading required package: xts
#&gt; Loading required package: zoo
#&gt; 
#&gt; Attaching package: &#39;zoo&#39;
#&gt; The following objects are masked from &#39;package:base&#39;:
#&gt; 
#&gt;     as.Date, as.Date.numeric
#&gt; 
#&gt; Attaching package: &#39;PerformanceAnalytics&#39;
#&gt; The following object is masked from &#39;package:graphics&#39;:
#&gt; 
#&gt;     legend
library(ppcor)
#&gt; Loading required package: MASS
#matriz de correlaciones
pcor(iris[1:4])
#&gt; $estimate
#&gt;              Sepal.Length Sepal.Width Petal.Length Petal.Width
#&gt; Sepal.Length    1.0000000   0.6285707    0.7190656  -0.3396174
#&gt; Sepal.Width     0.6285707   1.0000000   -0.6152919   0.3526260
#&gt; Petal.Length    0.7190656  -0.6152919    1.0000000   0.8707698
#&gt; Petal.Width    -0.3396174   0.3526260    0.8707698   1.0000000
#&gt; 
#&gt; $p.value
#&gt;              Sepal.Length  Sepal.Width Petal.Length  Petal.Width
#&gt; Sepal.Length 0.000000e+00 1.199846e-17 7.656980e-25 2.412876e-05
#&gt; Sepal.Width  1.199846e-17 0.000000e+00 8.753029e-17 1.104958e-05
#&gt; Petal.Length 7.656980e-25 8.753029e-17 0.000000e+00 7.332477e-47
#&gt; Petal.Width  2.412876e-05 1.104958e-05 7.332477e-47 0.000000e+00
#&gt; 
#&gt; $statistic
#&gt;              Sepal.Length Sepal.Width Petal.Length Petal.Width
#&gt; Sepal.Length     0.000000    9.765380    12.502483   -4.362929
#&gt; Sepal.Width      9.765380    0.000000    -9.431189    4.553279
#&gt; Petal.Length    12.502483   -9.431189     0.000000   21.398708
#&gt; Petal.Width     -4.362929    4.553279    21.398708    0.000000
#&gt; 
#&gt; $n
#&gt; [1] 150
#&gt; 
#&gt; $gp
#&gt; [1] 2
#&gt; 
#&gt; $method
#&gt; [1] &quot;pearson&quot;

#matriz con grafico de dispersión 
chart.Correlation(iris[1:4], histogram = T, pch = 19,col=as.factor(iris$Species))</code></pre>
<p><img src="regrelineal_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<pre class="r"><code># install.packages(&quot;GGally&quot;)
library(GGally)
#&gt; Registered S3 method overwritten by &#39;GGally&#39;:
#&gt;   method from   
#&gt;   +.gg   ggplot2

ggpairs(iris, columns = 1:4, aes(color = Species, alpha = 0.5),
        lower = list(continuous = &quot;smooth&quot;)) </code></pre>
<p><img src="regrelineal_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
</div>
<div id="medida-de-bondad-de-ajuste-r2" class="section level3">
<h3>Medida de bondad de ajuste <span
class="math inline">\(R^2\)</span></h3>
<p>Mide la proporción de la variabilidad total observada en la respuesta
que es explicada por la asociación lineal. Por ser una proporción, esta
cantidad varía entre 0 y 1, siendo igual a 0 cuando todos los
coeficientes de regresión ajustados son iguales a cero, y es igual a 1
si todas las observaciones caen sobre la superficie de regresión
ajustada. Definido como:</p>
<p><span class="math display">\[\Large
R^2=1-\frac{SSE}{SST}=1-\frac{\sum_{i=1}^n
(y_i-\hat{y_i})^2}{\sum_{i=1}^n (y_i-\bar{y_i})^2}\]</span> Donde</p>
<p>SSE: es la suma de cuadrados del error</p>
<p>SST: suma de cuadrados totales</p>
</div>
<div id="error-de-pronóstico-medio-mape" class="section level3">
<h3>Error de pronóstico medio MAPE</h3>
<p>Es importante evaluar la capacidad predictiva del modelo. Esta medida
compara promedia la diferencia entre los valores observados con los
pronosticados. Dado por la fórmula:</p>
<p><span class="math display">\[\Large MAPE=\frac{\sum_{i=1}^n
|\frac{y_i-\hat{y_i}}{y_i}|}{n}\]</span></p>
<p><strong>Cómo obtener un modelo de regresión lineal simple en la
calculadora</strong></p>
<iframe width="280" height="160" src="https://www.youtube.com/embed/4_WO31Dapv0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
</iframe>
</div>
</div>
<div id="test-lineal-general" class="section level2">
<h2><strong>Test lineal general</strong></h2>
<p>La varianza de los términos de error <span
class="math inline">\(\varepsilon_i\)</span>, es decir, <span
class="math inline">\(V[\varepsilon_i]=\sigma^2\)</span>, da un
indicador de la variabilidad de las distribuciones de probabilidad de Y
para los distintos valores de X. En este caso la suma cuadrática de
errores o residuales es:</p>
<p><span class="math display">\[\Large
SSE=\sum_{i=1}^{n}(y_i-\hat{y_i})^2=\sum_{i=1}^n e^2_i\]</span> La SSE
tiene asociada n−2 grados de libertad (gl), pues se pierden 2 (gl) al
estimar <span class="math inline">\(\beta_0\)</span> y <span
class="math inline">\(\beta_1\)</span>, para obtener a <span
class="math inline">\(\hat{y_i}\)</span>, de lo anterior se obtiene la
media cuadática de errores dada por:</p>
<p><span class="math display">\[\Large
MSE=\frac{SSE}{n-2}=\frac{\sum_{i=1}^{n}(y_i-\hat{y_i})^2}{n-2}=\frac{\sum_{i=1}^n
e^2_i}{n-2}\]</span></p>
<p>Se puede demostrar que MSE, es un estimador insesgado de <span
class="math inline">\(\Large \sigma^2\)</span> para el modelo de RLS, es
decir que:</p>
<p><span class="math display">\[\Large \sigma^2=MSE\]</span> Además
<span class="math display">\[\Large E(MSE)=\sigma\]</span></p>
<p><strong>Suma total de cuadrados</strong></p>
<p>La medida de variación de y alrededor de la la media muestral <span
class="math inline">\(\bar{y}\)</span> es: <span
class="math display">\[\Large
SST=\sum_{i=1}^n(Y_i-\bar{Y})^2\]</span></p>
<p><strong>Suma cuadrática de regresión</strong></p>
<p>La diferencia entre la SST y la SSE se denota por:</p>
<p><span class="math display">\[\Large
SSR=\sum_{i=1}^n(\hat{Y_i}-\bar{Y})^2\]</span></p>
<p>La SSR es una medida de la parte de la variabilidad de las
observaciones <span class="math inline">\(y_i\)</span>, la cual está
asociada con la línea de regresión ajustada.</p>
<p>De lo anterior, se obtiene la identidad fundamental del análisis de
varianza, la cual está dada por:</p>
<p><span class="math display">\[\Large SST = SSR + SSE\]</span></p>
<p>Aquí, SST: Variabilidad muestral total y tiene n−1 grados de
libertad.</p>
<p>SSR: Variabilidad explicada por el modelo o por las variables
regresoras X y tiene 1 grado de libertad.</p>
<p>SSE: Variabilidad no explicada por el modelo o error y tiene n−2
grados de libertad.</p>
<p><strong>Medias cuadráticas</strong></p>
<p>Las medias cuadráticas se obtienen, como las SS divididas por sus
respectivos grados de libertad, es decir que:</p>
<p><span class="math inline">\(\Large MST=\frac{SST}{n-1}\)</span>:
Cuadrado medio total</p>
<p><span class="math inline">\(\Large
MSR=\frac{SSR}{1}\)</span>:Cuadrado medio de la regresión</p>
<p><span class="math inline">\(\Large MSE=\frac{SSE}{n-2}\)</span>:
Cuadrado medio del error</p>
<p>Tabla de resumen del análisis de varianza</p>
<table>
<colgroup>
<col width="12%" />
<col width="24%" />
<col width="23%" />
<col width="24%" />
<col width="15%" />
</colgroup>
<thead>
<tr class="header">
<th>Factor</th>
<th>Grados de libertad</th>
<th>Suma de cuadrados</th>
<th>Medias cuadráticas</th>
<th>Estadístico</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Regresión</td>
<td>1</td>
<td>SSR</td>
<td>MSR</td>
<td>Fc</td>
</tr>
<tr class="even">
<td>Error</td>
<td>n-2</td>
<td>SSE</td>
<td>MSE</td>
<td></td>
</tr>
<tr class="odd">
<td>Total</td>
<td>n-1</td>
<td>SST</td>
<td>MST</td>
<td></td>
</tr>
</tbody>
</table>
<div id="prueba-de-significancia-de-la-regresión"
class="section level3">
<h3>Prueba de significancia de la regresión</h3>
<p>Considere las siguientes afirmaciones, las cuales son llamadas
pruebas de hipótesis o prueba de significancia de la regresión:</p>
<p>Hipótesis nula:</p>
<p><span class="math inline">\(\Large H_0: \beta_i=0\)</span> el
parámetro no es significativo</p>
<p>Hipótesis alternativa:</p>
<p><span class="math inline">\(\Large H_1: \beta_i \not= 0\)</span>: el
parámeto es significativo</p>
<p>El estadístico de prueba corresponde a</p>
<p><span class="math display">\[\Large F_c=\frac{MSR}{MSE}\sim
F_{(1,n-2)}\]</span></p>
</div>
</div>
<div id="análisis-de-residuales-para-la-validación-de-los-supuestos"
class="section level2">
<h2><strong>Análisis de residuales para la validación de los
supuestos</strong></h2>
<p>A través del análisis de residuales del modelo es posible detectar la
linealidad entre las variables X e Y, la media cero, varianza constante,
incorrelación, y normalidad.</p>
<div id="normalidad-en-los-residuales" class="section level3">
<h3>Normalidad en los residuales</h3>
<p>Se puede evaluar mediante el gráfico qqplot, en el cual los puntos
residuales deben estar alineados con la diagonal, dicha normalidad
también se puede evaluar con la prueba de normalidad de shapiro- wilk,
con el juego de hipótesis:</p>
<p><span class="math inline">\(H_o:\)</span>Los residuos son
normales</p>
<p><span class="math inline">\(H_1:\)</span>Los residuos no son
normales</p>
</div>
<div id="varianza-constante" class="section level3">
<h3>Varianza constante</h3>
<p>Mediante gráficos de residuales vs. respuesta ajustada y
vs. predictora X. Los residuos están distribuidos alrededor del cero y
el gráfico no presenta ninguna tendencia, entonces el modelo se
considera adecuado.</p>
<ul>
<li><p>Si se observa una tendencia, estaríamos violando el supuesto de
linealidad,</p></li>
<li><p>Si se observa una nube de puntos en forma de embudo, podemos
tener problemas con el supuesto de homogeneidad de varianzas, también
conocido como supuesto de homocedasticidad.</p></li>
</ul>
<p><img src="imagen/residuals.png" width="348" style="display: block; margin: auto;" /></p>
<p><strong>Otros diagnósticos</strong></p>
<p>Además de la validación de supuestos debemos chequear la presencia
de:</p>
<ul>
<li>Observaciones atípicas</li>
<li>Puntos de balanceo</li>
<li>Observaciones influyentes</li>
</ul>
<p>Que corresponden a observaciones alejadas del resto de la muestra,
que afectan los coeficientes de regresión estimados <span
class="math inline">\(\beta_0, \beta_1\)</span>, y las medidas de bondad
de ajuste como o sı el <span class="math inline">\(R^2\)</span>.</p>
<p>Para detectar estas observaciones atípicas construimos residuales
escalados, los residuales divididos por una estimación de su error
estándar.</p>
</div>
</div>
<div id="residuales-escalados" class="section level2">
<h2><strong>Residuales escalados</strong></h2>
<div id="residuales-estandarizados-d_i" class="section level3">
<h3>Residuales estandarizados <span
class="math inline">\(d_i\)</span></h3>
<p>El MSE aproxima la varianza de un residual, por tanto los residuales
se dividen por su desviación estándar para obtener los residuales
estandarizados, los cuales tienen media cero y varianza aproximada de
1:</p>
<p><span class="math display">\[\large d_i=\frac{\hat
\varepsilon_i}{\sqrt{MSE}}\]</span></p>
<p>Un <span class="math inline">\(d_i\)</span> grande <span
class="math inline">\((|di| &gt; 3)\)</span> es indicio de una
observación atípica potencial.</p>
</div>
<div id="residuales-estudentizados-r_i" class="section level3">
<h3>Residuales estudentizados <span
class="math inline">\(r_i\)</span></h3>
<p>Si estandarizamos un residual usando su varianza exacta, obtenemos un
residual estudentizado</p>
<p><span class="math display">\[\large r_i=\frac{\hat
\varepsilon_i}{\sqrt{MSE(1-h_{ii})}}\]</span> Donde <span
class="math inline">\(h_{ii}\)</span> es una medida del lugar o
ubicación del i-ésimo punto residual, conocida como leverage.</p>
<p>Se considera potencialmente atípica aquella observación con <span
class="math inline">\(r_i\)</span> grande <span
class="math inline">\((|ri| &gt; 3)\)</span></p>
<hr />
<p><strong>En R</strong></p>
<p>Sea <em>modelo</em> un objeto de regresión del tipo lm(), las medidas
de observaciones influenciales y de balanceo pueden obtenerse mediante
la siguiente función:</p>
<p>influence.measures(modelo)</p>
<p>Los residuales estandarizados y los estudentizados pueden obtenerse,
respectivamente,mediante las funciones:</p>
<p>rstandard(modelo)</p>
<p>rstudent(modelo)</p>
<hr />
<p><strong>Ejemplo</strong></p>
<p>Los siguientes datos proveen las velocidades en metros por segundo y
las distancias necesarias para frenar en metros</p>
<pre class="r"><code>head(cars)
#&gt;   speed dist
#&gt; 1     4    2
#&gt; 2     4   10
#&gt; 3     7    4
#&gt; 4     7   22
#&gt; 5     8   16
#&gt; 6     9   10</code></pre>
<p>En este caso ¿Cuál es la variable dependiente e independiente?</p>
<pre class="r"><code>plot(cars$speed,cars$dist)</code></pre>
<p><img src="regrelineal_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<p>Para este modelo el modelo de regresión lineal simple es:</p>
<p><span class="math display">\[\Large \hat{y}=-17.57+3.93x\]</span>
Donde</p>
<ul>
<li><p>X representa la velocidad en metros por segundo</p></li>
<li><p>y es la distancia de frenado en metros</p></li>
<li><p>Por cada unidad que aumenta la velocidad la distancia de frenado
aumenta 3.93 unidades</p></li>
</ul>
<p><strong>Resultados del modelo en R</strong></p>
<pre class="r"><code>
plot(cars$speed,cars$dist)</code></pre>
<p><img src="regrelineal_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<pre class="r"><code>cor.test(cars$speed,cars$dist)
#&gt; 
#&gt;  Pearson&#39;s product-moment correlation
#&gt; 
#&gt; data:  cars$speed and cars$dist
#&gt; t = 9.464, df = 48, p-value = 1.49e-12
#&gt; alternative hypothesis: true correlation is not equal to 0
#&gt; 95 percent confidence interval:
#&gt;  0.6816422 0.8862036
#&gt; sample estimates:
#&gt;       cor 
#&gt; 0.8068949
md=lm(cars$dist~cars$speed)
summary(md)
#&gt; 
#&gt; Call:
#&gt; lm(formula = cars$dist ~ cars$speed)
#&gt; 
#&gt; Residuals:
#&gt;     Min      1Q  Median      3Q     Max 
#&gt; -29.069  -9.525  -2.272   9.215  43.201 
#&gt; 
#&gt; Coefficients:
#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    
#&gt; (Intercept) -17.5791     6.7584  -2.601   0.0123 *  
#&gt; cars$speed    3.9324     0.4155   9.464 1.49e-12 ***
#&gt; ---
#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
#&gt; 
#&gt; Residual standard error: 15.38 on 48 degrees of freedom
#&gt; Multiple R-squared:  0.6511, Adjusted R-squared:  0.6438 
#&gt; F-statistic: 89.57 on 1 and 48 DF,  p-value: 1.49e-12
j=fitted(md)
plot(cars$speed,j, col=2, lwd=2)</code></pre>
<p><img src="regrelineal_files/figure-html/unnamed-chunk-11-2.png" width="672" /></p>
<p><strong>anova del modelo</strong></p>
<pre class="r"><code>md=lm(cars$dist~cars$speed)
anova(md)
#&gt; Analysis of Variance Table
#&gt; 
#&gt; Response: cars$dist
#&gt;            Df Sum Sq Mean Sq F value   Pr(&gt;F)    
#&gt; cars$speed  1  21186 21185.5  89.567 1.49e-12 ***
#&gt; Residuals  48  11354   236.5                     
#&gt; ---
#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

y=influence.measures(md)
head(y$infmat)
#&gt;        dfb.1_    dfb.crs$       dffit    cov.r       cook.d        hat
#&gt; 1  0.09440188 -0.08624563  0.09490289 1.174881 0.0045923121 0.11486131
#&gt; 2  0.29242487 -0.26715961  0.29397684 1.145655 0.0435139907 0.11486131
#&gt; 3 -0.10749794  0.09369281 -0.11039550 1.115801 0.0062023503 0.07150365
#&gt; 4  0.21897614 -0.19085472  0.22487854 1.092584 0.0254673384 0.07150365
#&gt; 5  0.03407516 -0.02901384  0.03553887 1.108612 0.0006446705 0.05997080
#&gt; 6 -0.11100703  0.09174024 -0.11851708 1.085395 0.0071319931 0.04989781
head(rstandard(md))
#&gt;          1          2          3          4          5          6 
#&gt;  0.2660415  0.8189327 -0.4013462  0.8132663  0.1421624 -0.5211526
head(rstudent(md))
#&gt;          1          2          3          4          5          6 
#&gt;  0.2634500  0.8160784 -0.3978115  0.8103526  0.1407033 -0.5171605</code></pre>
<p><strong>Análisis de residuales</strong></p>
<pre class="r"><code>md=lm(cars$dist~cars$speed)
rr=residuals(md)
par(mfrow=c(2,2))
plot(md)</code></pre>
<p><img src="regrelineal_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
<pre class="r"><code>shapiro.test(rr)
#&gt; 
#&gt;  Shapiro-Wilk normality test
#&gt; 
#&gt; data:  rr
#&gt; W = 0.94509, p-value = 0.02152</code></pre>
</div>
</div>
<div id="test-de-carencia-de-ajuste" class="section level2">
<h2><strong>Test de carencia de ajuste</strong></h2>
<p>Sirve para Verificar si el modelo lineal ajusta adecuadamente a los
datos. El test asume que los valores de Y dado X son:</p>
<ul>
<li>Independientes,<br />
</li>
<li>Se distribuyen en forma normal</li>
<li>Tienen varianza constante</li>
</ul>
<p>Esta prueba <em>requiere que en uno o más valores de X haya más de
una observación de Y</em>. Los ensayos repetidos de manera independiente
para el mismo nivel de la variable predictora son denominados
replicaciones.</p>
<p>Para explicar en qué consiste esta prueba, es necesario modificar la
notación usada de la siguiente manera, asumiendo que tenemos réplicas de
la respuesta en un valor o nivel dado de X:</p>
<p><span class="math inline">\(Y_{ij}\)</span> La respuesta i-ésima en
el j –ésimo nivel de X.</p>
<p><span class="math inline">\(X_j\)</span> El j-ésimo nivel de valores
de X, supondremos j=1, 2,…, k</p>
<p><span class="math inline">\(n_j\)</span> Número de observaciones de Y
tomadas en el j-esimo nivel de X.</p>
<p>Se define primero un modelo lineal general (<strong>modelo
completo</strong>) que corresponde a</p>
<p><span class="math display">\[
Y_{ij}=\mu_j+\varepsilon_{ij}\]</span></p>
<p>donde <span class="math inline">\(\mu_j=E(y_{ij})\)</span>, es decir,
es la media de la variable respuesta en el j-ésimo nivel de X.</p>
<p>Para el anterior modelo, los estimadores de máxima verosimilitud
corresponden a <span class="math inline">\(\hat \mu=\bar Y_j\)</span>,
es decir, la media muestral de Y en el nivel j de X. Esta cantidad
también corresponde al valor predicho para Y en el nivel j de X. Por
tanto, la suma de cuadrados del error del modelo general o <strong>suma
de cuadrados del error puro</strong> cuyos grados de libertad son n-k,
es dada por:</p>
<p><span
class="math display">\[SSPE=\sum_{j=1}^k\sum_{i=1}^{n_j}({Y_{ij}-\bar
Y_j})^2\]</span> Se define ahora el <strong>modelo lineal
reducido</strong> para la hipótesis nula de la prueba, el cual, para el
caso de la regresión lineal es <span
class="math inline">\(E(Y|X)=\beta_0+\beta_1 X\)</span> luego la prueba
formula que:</p>
<p><span class="math display">\[H_0=E(Y|X)=\beta_0+\beta_1 X \]</span>
<span class="math display">\[H_1=E(Y|X)\neq \beta_0+\beta_1 X
\]</span></p>
<p>La suma de cuadrados del error:</p>
<p><span
class="math display">\[SSE:\sum_{i=1}^{n}\sum_{j=1}^{k}(y_{ij}-\hat{y_j})^2\]</span>
se puede descomponer en:</p>
<p><span class="math display">\[SSE=SSPE+SSLOF\]</span></p>
<p>suma de cuadrados del error=suma de cuadrados del error puro + suma
de cuadrados de carencia de ajuste</p>
<p><span class="math display">\[SSLOF=SSE-SSPE\]</span></p>
<p>El estadístico de prueba es:</p>
<p><span
class="math display">\[F_0=\frac{SSLOF/(k-2)}{SSPE/(n-k)}\]</span></p>
<p>En la tabla ANOVA puede presentarse el test de carencia de ajuste
descomponiendo el SSE del modelo:</p>
<table>
<colgroup>
<col width="22%" />
<col width="21%" />
<col width="20%" />
<col width="21%" />
<col width="13%" />
</colgroup>
<thead>
<tr class="header">
<th>Fuente de variación</th>
<th>Grados de libertad</th>
<th>Suma de cuadrados</th>
<th>Medias cuadráticas</th>
<th>Estadístico</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Regresión</td>
<td>1</td>
<td>SSR</td>
<td>MSR</td>
<td>Fc</td>
</tr>
<tr class="even">
<td>Error</td>
<td>n-2</td>
<td>SSE</td>
<td>MSE</td>
<td></td>
</tr>
<tr class="odd">
<td>carencia de ajuste</td>
<td>k-2</td>
<td>SSLOF</td>
<td>MSLOF</td>
<td>FO</td>
</tr>
<tr class="even">
<td>Error puro</td>
<td>n-k</td>
<td>SSPE</td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>Total</td>
<td>n-1</td>
<td>SST</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>En general, la prueba de carencia de ajuste puede aplicarse a otras
funciones de regresión, sólo se requiere modificar los grados de
libertad del SSLOF, que en general corresponden a k-p , donde p es el
número de parámetros en la función de regresión. Para el caso específico
de la regresión lineal simple, p=2.</p>
<p><strong>Ejemplo</strong></p>
<p>Los siguientes datos se recolectaron con el fin de determinar la
relación existente entre el peso corporal del ganado vacuno (X) y la
rapidez de eliminación metabólica/peso corporal (Y). Los datos que
aparecen a continuación son el resultado de varias realizaciones del
experimento, en distintos niveles del peso.</p>
<pre class="r"><code>
peso=c(110,110,110,230,230,230,360,360,360,360,505,505,505,505)
elimina=c(235,198,173,174,149,124,115,130,102,95,122,112,98,96)

datos=data.frame(peso, elimina)


#ajusta el modelo lineal

regre=lm(elimina~peso)
summary(regre)
#&gt; 
#&gt; Call:
#&gt; lm(formula = elimina ~ peso)
#&gt; 
#&gt; Residuals:
#&gt;     Min      1Q  Median      3Q     Max 
#&gt; -34.553 -13.595   2.138  14.381  48.185 
#&gt; 
#&gt; Coefficients:
#&gt;              Estimate Std. Error t value Pr(&gt;|t|)    
#&gt; (Intercept) 212.72093   15.78406   13.48 1.31e-08 ***
#&gt; peso         -0.23551    0.04486   -5.25 0.000204 ***
#&gt; ---
#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
#&gt; 
#&gt; Residual standard error: 24.56 on 12 degrees of freedom
#&gt; Multiple R-squared:  0.6967, Adjusted R-squared:  0.6714 
#&gt; F-statistic: 27.57 on 1 and 12 DF,  p-value: 0.0002043
anova(regre)
#&gt; Analysis of Variance Table
#&gt; 
#&gt; Response: elimina
#&gt;           Df Sum Sq Mean Sq F value    Pr(&gt;F)    
#&gt; peso       1  16634 16634.2  27.567 0.0002043 ***
#&gt; Residuals 12   7241   603.4                      
#&gt; ---
#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1


plot(peso,elimina)
abline(a=212.72,b=-0.23,col=2)</code></pre>
<p><img src="regrelineal_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<pre class="r"><code>

## residuales del modelo

res=residuals(regre)
shapiro.test(res)
#&gt; 
#&gt;  Shapiro-Wilk normality test
#&gt; 
#&gt; data:  res
#&gt; W = 0.97124, p-value = 0.8928


#prueba de carencia de ajuste

regres1=lm(elimina~peso) #Ajusta modelo de regresión y da el error total SSE
regres2=lm(elimina~factor(peso)) #Ajusta modelo lineal general o completo y da su error puro
#SSPE
anova(regres1,regres2) #Compara los dos modelos anteriores y obtenemos el SSLOF, los grados
#&gt; Analysis of Variance Table
#&gt; 
#&gt; Model 1: elimina ~ peso
#&gt; Model 2: elimina ~ factor(peso)
#&gt;   Res.Df  RSS Df Sum of Sq     F  Pr(&gt;F)  
#&gt; 1     12 7241                             
#&gt; 2     10 4361  2      2880 3.302 0.07924 .
#&gt; ---
#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
#de libertad correspondientes,
</code></pre>
<p>Observe que la variable explicatoria X fue observada en cuatro
niveles: 110, 230, 360 y 505, es decir, tenemos réplicas de la variable
respuesta en al menos un nivel de X.</p>
<ol style="list-style-type: decimal">
<li>Indique qué información nos proporciona el análisis del gráfico de Y
vs. X acerca de:</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li><p>El tipo de relación funcional entre Y vs. X (¿lineal o no
lineal?)</p></li>
<li><p>El comportamiento de la varianza de Y en cada nivel de X
observado ¿Es constante o no? ¿Si no es constante, cómo cambia?</p></li>
</ol>
<ol start="2" style="list-style-type: decimal">
<li>Ajuste el modelo de regresión lineal simple y determine lo
siguiente</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li><p>Interprete los valores ajustados de los parámetros.</p></li>
<li><p>Realice la prueba de significancia de la regresión (mediante la
tabla ANOVA)</p></li>
<li><p>Realice los test de significancia de cada parámetros (pruebas
t).</p></li>
</ol>
<ol start="3" style="list-style-type: decimal">
<li>Calcule los residuales y responda lo siguiente:</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li><p>De acuerdo a los gráficos de residuales, determine si el supuesto
de varianza constante para los respectivos errores se cumple o
no.</p></li>
<li><p>Ahora realice los test de normalidad sobre los errores del
modelo, use e interprete los resultados del test de Shapiro Wilk y el
gráfico de probabilidad.</p></li>
</ol>
<ol start="4" style="list-style-type: decimal">
<li>Considere de nuevo los gráficos de residuales vs. X, calcule la
ANOVA para el test de carencia de ajuste del modelo y determine si</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li><p>¿Hay carencia de ajuste del modelo postulado para la respectiva
respuesta media? (Formule completamente el test de hipótesis, el
estadístico de prueba y los resultados)</p></li>
<li><p>Caso que exista carencia de ajuste ¿Qué modelos serían más
apropiados? ¿Por qué?</p></li>
</ol>
</div>
<div id="transformaciones" class="section level2">
<h2><strong>Transformaciones</strong></h2>
<p>En el caso de que los errores no resulten normales o la varianza no
sea constante, se pueden realizar transformaciones sobre la variable
respuesta y/o sobre las variables predictoras, como por ejemplo:</p>
<p>Modelo 1: <span class="math display">\[log(Y_i)=\beta_0*+\beta_1
X_i+\varepsilon_i*\]</span> Modelo 2: <span
class="math display">\[log(Y_i)=\beta_0*+\beta_1
log(X_i)+\varepsilon_i*\]</span> Modelo 2: <span
class="math display">\[log(Y_i)=\beta_0*+\beta_1
log(X_i)+\varepsilon_i*\]</span> Modelo 3: <span
class="math display">\[Y_i=\beta_0*+\beta_1
log(X_i)+\varepsilon_i*\]</span> Modelo 4: <span
class="math display">\[log(Y_i)=\beta_0*+\beta_1
(1/X_i)+\varepsilon_i*\]</span> Modelo 5: <span
class="math display">\[log(Y_i)=\beta_0*+\beta_1
(1/X_i)+\varepsilon_i*\]</span> el logaritmo de la variable
respuesta.</p>
<p>Se debe tener cuidado cuando se transforma la variable respuesta, ya
que pueden resultar en nuevas variables carentes de interpretación
práctica según el fenómeno o contexto al cual pertenece la variable
respuesta.</p>
<p>Si las desviaciones respecto al supuesto de normalidad son severas, y
ninguna transformación resulta útil y/o interpretable, existe otra
alternativa, los llamados modelos lineales generalizados con los cuales
se pueden modelar respuestas que no se distribuyen normales; sin
embargo, tales modelos están más allá del alcance de este curso.</p>
</div>
<div id="regresión-lineal-múltiple" class="section level2">
<h2><strong>Regresión lineal múltiple</strong></h2>
<p>Se desea modelar la variabilidad total de una variable respuesta de
interés, en función de relaciones lineales con dos o más variables
predictoras, cuantitativas y cualitatiivas, formuladas simultáneamente
en un único modelo.</p>
<p>Las variables predictoras pueden ser:</p>
<ul>
<li><p>Cuantitativas, caso en el cual se supone se miden sin error (o el
error es despreciable).</p></li>
<li><p>Cualitativas o categóricas, en este caso su manejo en el modelo
se realiza a través de la definición de variables indicadoras, las
cuales toman valores de 0 ó 1.</p></li>
</ul>
<p>Suponemos en principio que las variables predictoras guardan poca
asociación lineal entre sí, es decir, cada variable predictora aporta
información independiente de las demás predictoras presentes en el
modelo (hasta cierto grado, la información aportada por cada una no es
redundante). La ecuación del modelo de regresión en este caso es:</p>
<p><span class="math display">\[\Large
y_i=\beta_0+\beta_1x_{i1}+\beta_2x_{i2}+...+\beta_kx_{ik}\varepsilon_i\]</span></p>
</div>
<div id="regresión-lineal-con-efectos-de-interacción"
class="section level2">
<h2><strong>Regresión lineal con efectos de interacción</strong></h2>
<p>Cuando los efectos de una variable predictora depende de los niveles
de otras variables predictoras incluidas en el modelo.</p>
<p>Por ejemplo, suponga un modelo de regresión con las variables
predictoras<span class="math inline">\(X_1\)</span> y <span
class="math inline">\(X_2\)</span>, que incluye tanto los efectos
principales como el de interacción de estas dos variables. Este modelo
corresponde a:</p>
<p><span class="math display">\[\large Y_i=\beta_0+\beta_1
X_{i1}+\beta_2 X_{i2}+\beta_3X_{1}X_2+\varepsilon_i\]</span></p>
<p>El término de interacción es representado por <span
class="math inline">\(\beta_3X_{1}X_2\)</span>. Para expresar el
anterior modelo en términos del modelo lineal general, definimos
simplemente <span class="math inline">\(X_3=X_{1}X_2\)</span> y
rescribimos el modelo como:</p>
<p><span class="math display">\[\large Y_i=\beta_0+\beta_1
X_{i1}+\beta_2 X_{i2}+\beta_3X_{3}+\varepsilon_i\]</span></p>
</div>
<div id="regresión-lineal-con-variables-indicadoras"
class="section level2">
<h2><strong>Regresión lineal con variables indicadoras</strong></h2>
<p>Suponga que en un modelo de regresión para el gasto mensual por
familia en actividades recreativas, se tiene entre las variables
predictoras el estrato socioeconómico, definido en cinco niveles, luego,
para cada nivel se define una variable indicadora de la siguiente
forma:</p>
<p>Estrato 1: <span class="math display">\[ \Large  I_1 =\left\lbrace
\begin{array}{rcl}
            {1\quad familia \quad estrato \quad 1}
         \\
            {0 \quad En \quad otro \quad caso  }
         \end{array}  \right. \]</span></p>
<p>Estrato 2:</p>
<p><span class="math display">\[ \Large
           I_2 =\left\lbrace   \begin{array}{rcl}
            {1\quad familia \quad estrato \quad 2}
            \\
            {0 \quad En \quad otro \quad caso  }
         \end{array}  \right.     \]</span></p>
<p>Estrato 3:</p>
<p><span class="math display">\[ \Large  I_3
=\left\lbrace   \begin{array}{rcl}
            {1\quad familia \quad estrato \quad 3}
         \\
            {0 \quad En \quad otro \quad caso  }
         \end{array}  \right.  \]</span></p>
<p>Estrato 4:</p>
<p><span class="math display">\[    \Large     I_4
=\left\lbrace   \begin{array}{rcl}
            {1\quad familia \quad estrato \quad 4}
         \\
            {0 \quad En \quad otro \quad caso  }
         \end{array}  \right.    \]</span></p>
<p>En general, una variable cualitativa con c clases se representa
mediante c -1 variables indicadoras, puesto que cuando en una
observación dada, todas las c -1 primeras indicadoras son iguales a
cero, entonces la variable cualitativa se haya en su última clase. En el
ejemplo anterior basta definir las primeras cuatro indicadoras.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/eG5tI6aYgos" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
</iframe>
<p><strong>Casos de regresión lineal con variables
indicadoras</strong></p>
<p>Se desea modelar por regresión lineal la relación de una variable
respuesta cuantitativa <span class="math inline">\(Y\)</span> vs. <span
class="math inline">\(X_1\)</span>, siendo <span
class="math inline">\(X_1\)</span> cuantitativa, en presencia de una
variable categórica <span class="math inline">\(X_2\)</span>. Es decir,
se quiere determinar si la relación lineal entre <span
class="math inline">\(Y\)</span> vs. <span
class="math inline">\(X_1\)</span> depende de la variable categórica
<span class="math inline">\(X_2\)</span>. Asumiendo que <span
class="math inline">\(X_2\)</span> es observada en c categorías.</p>
<p>Podemos considerar las dos siguientes situaciones:</p>
<div id="caso-1-intercepto-y-pendiente-diferente"
class="section level3">
<h3>Caso 1 Intercepto y pendiente diferente</h3>
<p>El efecto promedio de <span class="math inline">\(X_1\)</span> sobre
la respuesta <span class="math inline">\(Y\)</span> cambia según la
categoría en que <span class="math inline">\(X_2\)</span> sea observada,
para lo cual es necesario considerar la interacción entre <span
class="math inline">\(X_1\)</span> y <span
class="math inline">\(X_2\)</span> en el modelo de regresión, y sólo
utilizamos c−1 de las posibles variables indicadoras de las categorías
de la variable <span class="math inline">\(X_2\)</span>, quedando el
modelo:</p>
<p><span class="math display">\[\large y=\beta_0+ \beta_1X_1+
\overbrace{\beta_2I_1+\beta_3I_2+...\beta_cI_{c-1}}^{Aporte\ variable\
cualitativa\ con\ c-1\
niveles}+\underbrace{\beta_{1,1}X_1I_1+\beta_{1,2}X_1I_2+...+\beta_{1,c-1}X_1I_{c-1}}_{Efecto\
interacción}+\varepsilon_i\]</span></p>
<p>Observe que la ecuación anterior define c rectas de regresión simple
de Y vs <span class="math inline">\(X_1\)</span>, una en cada categoría
de la variable cualitativa X2, así:</p>
<ul>
<li><p>Si <span class="math inline">\(I_1=1\)</span>, entonces el resto
de indicadoras son iguales a cero y obtenemos, <span
class="math display">\[\large Y=(\beta_0
+\beta_2)+(\beta_1+\beta_{1,1})X_1+\varepsilon\]</span></p></li>
<li><p>Si <span class="math inline">\(I_2=1\)</span>, entonces el resto
de indicadoras son iguales a cero y obtenemos, <span
class="math display">\[\large Y=(\beta_0
+\beta_3)+(\beta_1+\beta_{1,2})X_1+\varepsilon\]</span></p></li>
<li><p>Finalmente, si <span class="math inline">\(I_1 = I_2 = · · ·
I_{c−1} = 0\)</span>, necesariamente, la indicadora <span
class="math inline">\(I_c\)</span> no incluida en el modelo, debe ser
igual a 1, así, cuando todas la indicadoras del modelo son
simultáneamente cero, obtenemos la recta de regresión de Y vs. <span
class="math inline">\(X_1\)</span>, en la categoría c de la variable
categórica X2, de la forma:</p></li>
</ul>
<p><span class="math display">\[\large
Y_i=\beta_0+\beta_1X_1+\varepsilon_i\]</span></p>
</div>
<div id="caso-2-intercepto-aleatorio" class="section level3">
<h3>Caso 2 Intercepto aleatorio</h3>
<p>El efecto promedio de <span class="math inline">\(X_1\)</span> sobre
la respuesta Y es el mismo en todas las categorías de <span
class="math inline">\(X_2\)</span> pero la media general de Y no es
igual en todas las categorías. El modelo a considerar está dado por:</p>
<p><span class="math display">\[\large Y=\beta_0
+\beta_1X_1+\beta_2I_2+\beta_3I_3+
...\beta_cI_{c−1}+\varepsilon_i\]</span></p>
<p>donde el efecto promedio de <span class="math inline">\(X_1\)</span>
sobre la respuesta es el mismo sin importar la categoría en que sea
observada <span class="math inline">\(X_2\)</span>, sin embargo la media
de Y no es la misma en todas las categorías, dado que las c ecuaciones
resultantes, serían las de c rectas paralelas, que pueden diferir en el
intercepto,</p>
<ul>
<li><p>Si <span class="math inline">\(I_1=1\)</span>, entonces el resto
de indicadoras son iguales a cero y obtenemos, <span
class="math display">\[\large
Y=(\beta_0+\beta_2)+\beta_1X_1+\varepsilon_i\]</span></p></li>
<li><p>Si <span class="math inline">\(I_2=1\)</span>, entonces el resto
de indicadoras son iguales a cero y obtenemos, <span
class="math display">\[\large Y=(\beta_0
+\beta_3)+\beta_1X_1+\varepsilon\]</span></p></li>
<li><p>Cuando <span class="math inline">\(I_1 = I_2 = · · · I_{c−1} =
0\)</span>, es decir, <span class="math inline">\(I_c\)</span> = 1,
tenemos</p></li>
</ul>
<p><span class="math display">\[\large Y_i=\beta_0
+\beta_1X_1+\varepsilon_i\]</span></p>
<p><strong>Ejemplo 1 Modelo de circunferencia de los
arboles</strong></p>
<p><strong>Modelo de regresión lineal simple</strong></p>
<p>La siguiente base de datos relaciona 7 medidas del crecimiento de 5
tipos de arboles en el tiempo en meses y el diámetro en mm.</p>
<pre class="r"><code>head (Orange)
#&gt; Grouped Data: circumference ~ age | Tree
#&gt;   Tree  age circumference
#&gt; 1    1  118            30
#&gt; 2    1  484            58
#&gt; 3    1  664            87
#&gt; 4    1 1004           115
#&gt; 5    1 1231           120
#&gt; 6    1 1372           142</code></pre>
<p>El ajuste del modelo de regresión lineal simple corresponde a:</p>
<pre class="r"><code>model=lm(Orange$circumference~Orange$age)
summary(model)
#&gt; 
#&gt; Call:
#&gt; lm(formula = Orange$circumference ~ Orange$age)
#&gt; 
#&gt; Residuals:
#&gt;     Min      1Q  Median      3Q     Max 
#&gt; -46.310 -14.946  -0.076  19.697  45.111 
#&gt; 
#&gt; Coefficients:
#&gt;              Estimate Std. Error t value Pr(&gt;|t|)    
#&gt; (Intercept) 17.399650   8.622660   2.018   0.0518 .  
#&gt; Orange$age   0.106770   0.008277  12.900 1.93e-14 ***
#&gt; ---
#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
#&gt; 
#&gt; Residual standard error: 23.74 on 33 degrees of freedom
#&gt; Multiple R-squared:  0.8345, Adjusted R-squared:  0.8295 
#&gt; F-statistic: 166.4 on 1 and 33 DF,  p-value: 1.931e-14</code></pre>
<p>La ecuación del modelo de regresión general es:</p>
<p><span class="math display">\[\Large \hat y_i=17.4+0.1x_{i}\]</span>
Donde</p>
<p><span class="math inline">\(y_i\)</span> es la variable respuesta</p>
<p><span class="math inline">\(x_i\)</span> es la edad del árbol, por
cada unidad que aumente en edad el árbol, el diametro de la
circunferencia aumenta 0.1.</p>
<p>El diagrama de dispersión con la linea de regresión ajustada
corresponde a:</p>
<pre class="r"><code>model=lm(Orange$circumference~Orange$age)
plot(Orange$age,Orange$circumference,lwd=3)
yest=fitted(model)
lines(Orange$age,yest,col=2)
abline(coef(model))</code></pre>
<p><img src="regrelineal_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<pre class="r"><code>
par(mfrow=c(2,2))
plot(model)</code></pre>
<p><img src="regrelineal_files/figure-html/unnamed-chunk-17-2.png" width="672" /></p>
<pre class="r"><code>shapiro.test(residuals(model))
#&gt; 
#&gt;  Shapiro-Wilk normality test
#&gt; 
#&gt; data:  residuals(model)
#&gt; W = 0.97289, p-value = 0.5273</code></pre>
<p><strong>Significado de los parámetros estimados</strong></p>
<p>El intercepto es la respuesta media observada en el crecimiento de
los arboles.</p>
<p>La péndiente indica que por cada mes que pasa la circunferencia del
arbol aumenta 0.1 unidades</p>
<p><strong>Modelo de regresión lineal de intercepto aleatorio con la
misma pendiente:</strong></p>
<p>El modelo de regresión lineal con factores corresponde a</p>
<pre class="r"><code>model=lm(Orange$circumference~Orange$age+as.factor(Orange$Tree))
summary(model)
#&gt; 
#&gt; Call:
#&gt; lm(formula = Orange$circumference ~ Orange$age + as.factor(Orange$Tree))
#&gt; 
#&gt; Residuals:
#&gt;     Min      1Q  Median      3Q     Max 
#&gt; -30.505  -8.790   3.737   7.650  21.859 
#&gt; 
#&gt; Coefficients:
#&gt;                           Estimate Std. Error t value Pr(&gt;|t|)    
#&gt; (Intercept)              17.399650   5.543461   3.139  0.00388 ** 
#&gt; Orange$age                0.106770   0.005321  20.066  &lt; 2e-16 ***
#&gt; as.factor(Orange$Tree).L 39.935049   5.768048   6.923 1.31e-07 ***
#&gt; as.factor(Orange$Tree).Q  2.519892   5.768048   0.437  0.66544    
#&gt; as.factor(Orange$Tree).C -8.267097   5.768048  -1.433  0.16248    
#&gt; as.factor(Orange$Tree)^4 -4.695541   5.768048  -0.814  0.42224    
#&gt; ---
#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
#&gt; 
#&gt; Residual standard error: 15.26 on 29 degrees of freedom
#&gt; Multiple R-squared:  0.9399, Adjusted R-squared:  0.9295 
#&gt; F-statistic:  90.7 on 5 and 29 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>La recta general del modelo es:</p>
<p><span class="math display">\[\Large \hat
y_i=17.4+0.1x_{i}+39.93arbol2_i+2.51arbol3_i-8.26arbol4_i-4.69arbol5_i\]</span></p>
<p>Las rectas ajustadas para cada árbol son:</p>
<p>Arbol 1:</p>
<p><span class="math display">\[\Large \hat
y_i=17.4+0.1x_{i}\]</span></p>
<p>Arbol 2: <span class="math display">\[\Large \hat
y_i=57.33+0.1x_{i}\]</span></p>
<p>Arbol 3: <span class="math display">\[\Large \hat
y_i=19.92+0.1x_{i}\]</span></p>
<p>Arbol 4: <span class="math display">\[\Large \hat
y_i=9.14+0.1x_{i}\]</span></p>
<p>Arbol 5: <span class="math display">\[\Large \hat
y_i=12.71+0.1x_{i}\]</span></p>
<p>El diagrama de dispersión discriminando por los niveles de la
variables factor es:</p>
<pre class="r"><code>plot(Orange$age,Orange$circumference,col=Orange$Tree,lwd=3)
abline(a=17.4,b=0.1,col=1,lwd=3)
abline(a=57.33,b=0.1,col=2,lwd=3)
abline(a=19.92,b=0.1,col=3,lwd=3)
abline(a=9.14,b=0.1,col=4,lwd=3)
abline(a=12.71,b=0.1,col=5,lwd=3)</code></pre>
<p><img src="regrelineal_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
<p>Con base en la tabla ANOVA, y bajo los supuestos de los errores, se
realiza el test de significancia de la regresión el cual se enuncia de
la siguiente manera:</p>
<p><span class="math inline">\(H_0= \beta_1=\beta_2=...\beta_k\)</span>
El modelo de regresión no es significativo.</p>
<p><span class="math inline">\(H_1=Algún\ \beta_k \not=0\)</span> Existe
una relación de regresión significativa con al menos una de las
variables.</p>
<p>Es decir, se prueba que existe una relación de regresión, sin embargo
esto no garantiza que el modelo resulte útil para hacer
predicciones.</p>
<pre class="r"><code>model=lm(Orange$circumference~Orange$age+as.factor(Orange$Tree))
anova(model)
#&gt; Analysis of Variance Table
#&gt; 
#&gt; Response: Orange$circumference
#&gt;                        Df Sum Sq Mean Sq F value    Pr(&gt;F)    
#&gt; Orange$age              1  93772   93772 402.639 &lt; 2.2e-16 ***
#&gt; as.factor(Orange$Tree)  4  11841    2960  12.711 4.289e-06 ***
#&gt; Residuals              29   6754     233                      
#&gt; ---
#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p><strong>Modelo de regresión lineal con pendiente e intercepto
diferentes</strong></p>
<p>El modelo de regresión lineal con factores corresponde a</p>
<pre class="r"><code>model=lm(Orange$circumference~Orange$age*as.factor(Orange$Tree))
summary(model)
#&gt; 
#&gt; Call:
#&gt; lm(formula = Orange$circumference ~ Orange$age * as.factor(Orange$Tree))
#&gt; 
#&gt; Residuals:
#&gt;     Min      1Q  Median      3Q     Max 
#&gt; -18.061  -6.639  -1.482   8.069  16.649 
#&gt; 
#&gt; Coefficients:
#&gt;                                       Estimate Std. Error t value Pr(&gt;|t|)    
#&gt; (Intercept)                          17.399650   3.782659   4.600 0.000105 ***
#&gt; Orange$age                            0.106770   0.003631  29.406  &lt; 2e-16 ***
#&gt; as.factor(Orange$Tree).L             -4.303473   8.458282  -0.509 0.615362    
#&gt; as.factor(Orange$Tree).Q              1.541262   8.458282   0.182 0.856880    
#&gt; as.factor(Orange$Tree).C              1.387598   8.458282   0.164 0.871009    
#&gt; as.factor(Orange$Tree)^4            -10.900936   8.458282  -1.289 0.209271    
#&gt; Orange$age:as.factor(Orange$Tree).L   0.047974   0.008119   5.909 3.63e-06 ***
#&gt; Orange$age:as.factor(Orange$Tree).Q   0.001061   0.008119   0.131 0.897047    
#&gt; Orange$age:as.factor(Orange$Tree).C  -0.010470   0.008119  -1.290 0.209002    
#&gt; Orange$age:as.factor(Orange$Tree)^4   0.006729   0.008119   0.829 0.415032    
#&gt; ---
#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
#&gt; 
#&gt; Residual standard error: 10.41 on 25 degrees of freedom
#&gt; Multiple R-squared:  0.9759, Adjusted R-squared:  0.9672 
#&gt; F-statistic: 112.4 on 9 and 25 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>La recta general del modelo es:</p>
<p><span class="math display">\[\Large \hat
y_i=17.4+0.1x_{i}-4.3arbol_2+1.51arbol_3+1.4arbol_4-10.9arbol_5+
0.05arbol_2*x_i+0.001arbol_3*x_i-0.01arbol_4*x_i+0.006arbol_5*x_i\]</span></p>
<p>Las rectas ajustadas para cada árbol son:</p>
<p>Arbol 1:</p>
<p><span class="math display">\[\Large \hat
y_i=17.4+0.1x_{i}\]</span></p>
<p>Arbol 2: <span class="math display">\[\Large \hat
y_i=13.1+0.15x_{i}\]</span></p>
<p>Arbol 3: <span class="math display">\[\Large \hat
y_i=18.9+0.101x_{i}\]</span></p>
<p>Arbol 4: <span class="math display">\[\Large \hat
y_i=18.8+0.1x_{i}\]</span></p>
<p>Arbol 5: <span class="math display">\[\Large \hat
y_i=6.5+0.106x_{i}\]</span></p>
<p>El diagrama de dispersión discriminando por los niveles de la
variables factor es:</p>
<pre class="r"><code>plot(Orange$age,Orange$circumference,col=Orange$Tree,lwd=3)
abline(a=17.4,b=0.1,col=1,lwd=3)
abline(a=13.1,b=0.15,col=2,lwd=3)
abline(a=18.9,b=0.1,col=3,lwd=3)
abline(a=18.8,b=0.1,col=4,lwd=3)
abline(a=6.1,b=0.1,col=5,lwd=3)</code></pre>
<p><img src="regrelineal_files/figure-html/unnamed-chunk-22-1.png" width="672" /></p>
<p>Con base en la tabla ANOVA, y bajo los supuestos de los errores, se
realiza el test de significancia de la regresión el cual se enuncia de
la siguiente manera:</p>
<p><span class="math inline">\(H_0= \beta_1=\beta_2=...\beta_k\)</span>
El modelo de regresión no es significativo.</p>
<p><span class="math inline">\(H_1=Algún\ \beta_k \not=0\)</span> Existe
una relación de regresión significativa con al menos una de las
variables.</p>
<p>Es decir, se prueba que existe una relación de regresión, sin embargo
esto no garantiza que el modelo resulte útil para hacer
predicciones.</p>
<pre class="r"><code>model=lm(Orange$circumference~Orange$age*as.factor(Orange$Tree))
anova(model)
#&gt; Analysis of Variance Table
#&gt; 
#&gt; Response: Orange$circumference
#&gt;                                   Df Sum Sq Mean Sq  F value    Pr(&gt;F)    
#&gt; Orange$age                         1  93772   93772 864.7348 &lt; 2.2e-16 ***
#&gt; as.factor(Orange$Tree)             4  11841    2960  27.2983 8.428e-09 ***
#&gt; Orange$age:as.factor(Orange$Tree)  4   4043    1011   9.3206 9.402e-05 ***
#&gt; Residuals                         25   2711     108                       
#&gt; ---
#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p><strong>Ejemplo 2</strong></p>
<p><strong>Modelo de pendiente e intercepto diferentes</strong></p>
<p>Se tienen los datos de las ventas y publicidad invertidos en cada una
de las secciones</p>
<pre class="r"><code>Seccion=c(rep(&quot;A&quot;,5),rep(&quot;B&quot;,5),rep(&quot;C&quot;,5))
Publicidad=c(5.2,5.9,7.7,7.9,9.4,8.2,9,9.1,10.5,10.5,10,10.3,12.1,12.7,13.6)
Ventas=c(9,10,12,12,14,13,13,12,13,14,18,19,20,21,22)
datos=data.frame(Seccion,Publicidad,Ventas)
###GRAFICANDO VENTAS VS. PUBLICIDAD SEG´UN SECCION###
attach(datos)
#&gt; The following objects are masked _by_ .GlobalEnv:
#&gt; 
#&gt;     Publicidad, Seccion, Ventas
plot(Publicidad,Ventas,pch=1:3,col=1:3,cex=2,cex.lab=1.5)
legend(&quot;topleft&quot;,legend=c(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;),pch=c(1:3),col=c(1:3),cex=2)


#USANDO POR DEFECTO COMO SECCIÓN REFERENCIA LA A
###MODELO GENERAL: RECTAS DIFERENTES TANTO EN PENDIENTE COMO EN INTERCEPTO###
#Con interacción entre la variable publicidad y sección
modelo1=lm(Ventas~Publicidad*Seccion)
summary(modelo1)
#&gt; 
#&gt; Call:
#&gt; lm(formula = Ventas ~ Publicidad * Seccion)
#&gt; 
#&gt; Residuals:
#&gt;      Min       1Q   Median       3Q      Max 
#&gt; -0.87683 -0.22516  0.04366  0.14985  0.64418 
#&gt; 
#&gt; Coefficients:
#&gt;                     Estimate Std. Error t value Pr(&gt;|t|)    
#&gt; (Intercept)           3.0318     1.0346   2.930   0.0167 *  
#&gt; Publicidad            1.1590     0.1403   8.262 1.71e-05 ***
#&gt; SeccionB              6.7317     2.4423   2.756   0.0222 *  
#&gt; SeccionC              5.2429     2.0724   2.530   0.0322 *  
#&gt; Publicidad:SeccionB  -0.8169     0.2718  -3.005   0.0148 *  
#&gt; Publicidad:SeccionC  -0.1603     0.2068  -0.775   0.4581    
#&gt; ---
#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
#&gt; 
#&gt; Residual standard error: 0.4709 on 9 degrees of freedom
#&gt; Multiple R-squared:  0.9916, Adjusted R-squared:  0.9869 
#&gt; F-statistic: 211.4 on 5 and 9 DF,  p-value: 4.782e-09
confint(modelo1)
#&gt;                          2.5 %     97.5 %
#&gt; (Intercept)          0.6913867  5.3721561
#&gt; Publicidad           0.8416690  1.4763999
#&gt; SeccionB             1.2067246 12.2566144
#&gt; SeccionC             0.5547971  9.9309735
#&gt; Publicidad:SeccionB -1.4317793 -0.2020276
#&gt; Publicidad:SeccionC -0.6280374  0.3074717
anova(modelo1)
#&gt; Analysis of Variance Table
#&gt; 
#&gt; Response: Ventas
#&gt;                    Df  Sum Sq Mean Sq  F value    Pr(&gt;F)    
#&gt; Publicidad          1 193.859 193.859 874.1066 2.829e-10 ***
#&gt; Seccion             2  38.523  19.261  86.8493 1.307e-06 ***
#&gt; Publicidad:Seccion  2   2.023   1.011   4.5601   0.04289 *  
#&gt; Residuals           9   1.996   0.222                       
#&gt; ---
#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
#recta para la sección a
abline(a=3.03,b=1.16,col=1,pch=1,lwd=2)
# Recta para la sección b
abline(a=9.76,b=0.35,col=2,pch=2,lwd=2)
#Recta para la sección c
abline(a=8.27,b=1,col=3,pch=3,lwd=2)</code></pre>
<p><img src="regrelineal_files/figure-html/unnamed-chunk-24-1.png" width="672" /></p>
<p><strong>MODELO CON INTERCEPTO diferente</strong></p>
<pre class="r"><code>###MODELO CON RECTAS DIFERENTES SOLO EN EL INTERCEPTO###
modelo2=lm(Ventas~Publicidad+Seccion)
summary(modelo2)
#&gt; 
#&gt; Call:
#&gt; lm(formula = Ventas ~ Publicidad + Seccion)
#&gt; 
#&gt; Residuals:
#&gt;      Min       1Q   Median       3Q      Max 
#&gt; -1.00202 -0.33520 -0.00202  0.29767  1.21398 
#&gt; 
#&gt; Coefficients:
#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    
#&gt; (Intercept)   4.4437     0.9142   4.861 0.000502 ***
#&gt; Publicidad    0.9635     0.1210   7.966 6.80e-06 ***
#&gt; SeccionB     -0.5582     0.4686  -1.191 0.258600    
#&gt; SeccionC      4.2451     0.6671   6.363 5.34e-05 ***
#&gt; ---
#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
#&gt; 
#&gt; Residual standard error: 0.6044 on 11 degrees of freedom
#&gt; Multiple R-squared:  0.983,  Adjusted R-squared:  0.9784 
#&gt; F-statistic:   212 on 3 and 11 DF,  p-value: 5.186e-10
anova(modelo2)
#&gt; Analysis of Variance Table
#&gt; 
#&gt; Response: Ventas
#&gt;            Df  Sum Sq Mean Sq F value    Pr(&gt;F)    
#&gt; Publicidad  1 193.859 193.859 530.631 1.168e-10 ***
#&gt; Seccion     2  38.523  19.261  52.722 2.312e-06 ***
#&gt; Residuals  11   4.019   0.365                      
#&gt; ---
#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
confint(modelo2)
#&gt;                  2.5 %    97.5 %
#&gt; (Intercept)  2.4316194 6.4557425
#&gt; Publicidad   0.6972616 1.2296965
#&gt; SeccionB    -1.5894689 0.4730825
#&gt; SeccionC     2.7767893 5.7133597
plot(Publicidad,Ventas,pch=1:3,col=1:3,cex=2,cex.lab=1.5)
legend(&quot;topleft&quot;,legend=c(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;),pch=c(1:3),col=c(1:3),cex=2)</code></pre>
<p><img src="regrelineal_files/figure-html/unnamed-chunk-25-1.png" width="672" /></p>
</div>
</div>
<div id="regresión-lineal-con-variables-continuas"
class="section level2">
<h2><strong>Regresión lineal con variables continuas</strong></h2>
<div id="procedimientos-para-la-selección-de-variables-significativas"
class="section level3">
<h3>Procedimientos para la selección de variables significativas**</h3>
<p>Básicamente, existen tres procedimientos de selección automática, los
cuales son computacionalmente menos costosos que el procedimiento de
selección basado en ajustar todas las regresiones posibles, y operan en
forma secuencial:</p>
<ul>
<li><p><strong>Forward o selección hacia delante</strong> Agrega
variables, una por vez, buscando reducir en forma significativa la suma
de cuadrados de los errores.</p></li>
<li><p><strong>Backward o selección hacia atrás</strong> El método
backward, parte del modelo con todas las variables y elimina
secuencialmente de a una variable, buscando reducir el SSE.</p></li>
<li><p><strong>Stepwise, una combinación de los dos anteriores</strong>
La variable que se elimina en cada paso, es aquella que no resulta
significativa en presencia de las demás variables del modelo de
regresión que se tiene en ese momento. El algoritmo se detiene cuando
todas las variables que aún permanecen en el modelo son significativas
en presencia de las demás.</p></li>
</ul>
<p><strong>Ejemplo</strong></p>
<p>Para estimar la producción en madera de un bosque se suele realizar
un muestreo previo en el que se toman una serie de mediciones no
destructivas. Disponemos de mediciones para 20 árboles, así como el
volumen de madera que producen una vez cortados. Las variables
observadas son:</p>
<p>HT = altura en pies</p>
<p>DBH = diámetro del tronco a 4 pies de altura (en pulgadas)</p>
<p>D16 = diámetro del tronco a 16 pies de altura (en pulgadas)</p>
<p>VOL = volumen de madera obtenida (en pies cúbicos).</p>
<p>El objetivo del análisis es determinar cuál es la relación entre
dichas medidas y el volumen de madera, con el fin de poder predecir este
último en función de las primeras</p>
<pre class="r"><code>DBH &lt;- c(10.2,13.72,15.43,14.37,15,15.02,15.12,15.24,15.24,15.28, 13.78,15.67,15.67,15.98,16.5,16.87,17.26,17.28,17.87,19.13)
D16 &lt;-c(9.3,12.1,13.3,13.4,14.2,12.8,14,13.5,14,13.8,13.6,14, 13.7,13.9,14.9,14.9,14.3,14.3,16.9,17.3)
HT &lt;-c(89,90.07,95.08,98.03,99,91.05,105.6,100.8,94,93.09,89, 102,99,89.02,95.09,95.02,91.02,98.06,96.01,101)
VOL &lt;-c(25.93,45.87,56.2,58.6,63.36,46.35,68.99,62.91,58.13, 59.79,56.2,66.16,62.18,57.01,65.62,65.03,66.74,73.38,82.87,95.71)
bosque&lt;-data.frame(VOL=VOL,DBH=DBH,D16=D16,HT=HT)
plot(bosque)</code></pre>
<p><img src="regrelineal_files/figure-html/unnamed-chunk-26-1.png" width="672" /></p>
<pre class="r"><code>###correlaciones entre variables
#install.packages(ppcor)
library(PerformanceAnalytics)
library(ppcor)
pcor(bosque)
#&gt; $estimate
#&gt;           VOL        DBH        D16         HT
#&gt; VOL 1.0000000  0.3683119  0.7627127  0.7285511
#&gt; DBH 0.3683119  1.0000000  0.2686789 -0.3107753
#&gt; D16 0.7627127  0.2686789  1.0000000 -0.4513110
#&gt; HT  0.7285511 -0.3107753 -0.4513110  1.0000000
#&gt; 
#&gt; $p.value
#&gt;              VOL       DBH          D16           HT
#&gt; VOL 0.0000000000 0.1326107 0.0002324675 0.0006056469
#&gt; DBH 0.1326107400 0.0000000 0.2810102724 0.2094003059
#&gt; D16 0.0002324675 0.2810103 0.0000000000 0.0601150552
#&gt; HT  0.0006056469 0.2094003 0.0601150552 0.0000000000
#&gt; 
#&gt; $statistic
#&gt;          VOL       DBH       D16        HT
#&gt; VOL 0.000000  1.584644  4.717295  4.254366
#&gt; DBH 1.584644  0.000000  1.115742 -1.307862
#&gt; D16 4.717295  1.115742  0.000000 -2.022984
#&gt; HT  4.254366 -1.307862 -2.022984  0.000000
#&gt; 
#&gt; $n
#&gt; [1] 20
#&gt; 
#&gt; $gp
#&gt; [1] 2
#&gt; 
#&gt; $method
#&gt; [1] &quot;pearson&quot;
chart.Correlation(bosque, histogram = F, pch = 19)</code></pre>
<p><img src="regrelineal_files/figure-html/unnamed-chunk-26-2.png" width="672" /></p>
<p>El modelo inicial ajustado corresponde a:</p>
<pre class="r"><code>m1=lm(VOL~D16+HT+DBH)
summary(m1)
#&gt; 
#&gt; Call:
#&gt; lm(formula = VOL ~ D16 + HT + DBH)
#&gt; 
#&gt; Residuals:
#&gt;     Min      1Q  Median      3Q     Max 
#&gt; -5.2548 -1.6765 -0.1277  1.5232  4.9990 
#&gt; 
#&gt; Coefficients:
#&gt;              Estimate Std. Error t value Pr(&gt;|t|)    
#&gt; (Intercept) -108.5758    14.1422  -7.677 9.42e-07 ***
#&gt; D16            5.6714     1.2023   4.717 0.000232 ***
#&gt; HT             0.6938     0.1631   4.254 0.000606 ***
#&gt; DBH            1.6258     1.0259   1.585 0.132611    
#&gt; ---
#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
#&gt; 
#&gt; Residual standard error: 3.095 on 16 degrees of freedom
#&gt; Multiple R-squared:  0.9591, Adjusted R-squared:  0.9514 
#&gt; F-statistic: 124.9 on 3 and 16 DF,  p-value: 2.587e-11
anova(m1)
#&gt; Analysis of Variance Table
#&gt; 
#&gt; Response: VOL
#&gt;           Df Sum Sq Mean Sq  F value    Pr(&gt;F)    
#&gt; D16        1 3401.3  3401.3 354.9987 2.396e-12 ***
#&gt; HT         1  165.7   165.7  17.2890 0.0007408 ***
#&gt; DBH        1   24.1    24.1   2.5111 0.1326107    
#&gt; Residuals 16  153.3     9.6                       
#&gt; ---
#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Al quitar la variable no significativa del modelo queda:</p>
<pre class="r"><code>m1=lm(VOL~D16+HT)
summary(m1)
#&gt; 
#&gt; Call:
#&gt; lm(formula = VOL ~ D16 + HT)
#&gt; 
#&gt; Residuals:
#&gt;     Min      1Q  Median      3Q     Max 
#&gt; -4.2309 -1.8386 -0.4012  1.0922  6.9373 
#&gt; 
#&gt; Coefficients:
#&gt;              Estimate Std. Error t value Pr(&gt;|t|)    
#&gt; (Intercept) -105.9027    14.6520  -7.228 1.41e-06 ***
#&gt; D16            7.4128     0.5088  14.568 4.92e-11 ***
#&gt; HT             0.6765     0.1698   3.985 0.000959 ***
#&gt; ---
#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
#&gt; 
#&gt; Residual standard error: 3.23 on 17 degrees of freedom
#&gt; Multiple R-squared:  0.9526, Adjusted R-squared:  0.9471 
#&gt; F-statistic: 170.9 on 2 and 17 DF,  p-value: 5.515e-12
par(mfrow=c(2,2))
plot(m1)</code></pre>
<p><img src="regrelineal_files/figure-html/unnamed-chunk-28-1.png" width="672" /></p>
<p>El modelo ajustado corresponde a:</p>
<p><span class="math display">\[\hat
y=-105.9027+7.41D16+0.67HT\]</span></p>
<p>Al evaluar la significancia de los parámetros del modelo se
tiene:</p>
<pre class="r"><code>
library(car)
#&gt; Loading required package: carData
#library(rgl)
library(perturbR)
library(leaps)
library(scatterplot3d)

anova(m1)
#&gt; Analysis of Variance Table
#&gt; 
#&gt; Response: VOL
#&gt;           Df Sum Sq Mean Sq F value    Pr(&gt;F)    
#&gt; D16        1 3401.3  3401.3 326.019  1.58e-12 ***
#&gt; HT         1  165.7   165.7  15.878 0.0009585 ***
#&gt; Residuals 17  177.4    10.4                      
#&gt; ---
#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
##se hace uso de la siguiente función creada para estimar el aporte de los coeficientes estandarizados
miscoeficientes=function(modeloreg,datosreg){
  coefi=coef(modeloreg)
  datos2=as.data.frame(scale(datosreg))
  coef.std=c(0,coef(lm(update(formula(modeloreg),~.+0),datos2)))
  limites=confint(modeloreg,level=0.95)
  vifs=c(0,vif(modeloreg))
  resul=data.frame(Estimacin=coefi,Limites=limites,Vif=vifs,Coef.Std=coef.std)
  cat(&quot;Coeficientes estimados, sus I.C, Vifs y Coeficientes estimados estandarizados&quot;,&quot;\n&quot;)
  resul
}


m1=lm(VOL~D16+HT+DBH)

summary(m1)
#&gt; 
#&gt; Call:
#&gt; lm(formula = VOL ~ D16 + HT + DBH)
#&gt; 
#&gt; Residuals:
#&gt;     Min      1Q  Median      3Q     Max 
#&gt; -5.2548 -1.6765 -0.1277  1.5232  4.9990 
#&gt; 
#&gt; Coefficients:
#&gt;              Estimate Std. Error t value Pr(&gt;|t|)    
#&gt; (Intercept) -108.5758    14.1422  -7.677 9.42e-07 ***
#&gt; D16            5.6714     1.2023   4.717 0.000232 ***
#&gt; HT             0.6938     0.1631   4.254 0.000606 ***
#&gt; DBH            1.6258     1.0259   1.585 0.132611    
#&gt; ---
#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
#&gt; 
#&gt; Residual standard error: 3.095 on 16 degrees of freedom
#&gt; Multiple R-squared:  0.9591, Adjusted R-squared:  0.9514 
#&gt; F-statistic: 124.9 on 3 and 16 DF,  p-value: 2.587e-11
miscoeficientes(m1,bosque)
#&gt; Coeficientes estimados, sus I.C, Vifs y Coeficientes estimados estandarizados
#&gt;                Estimacin Limites.2.5.. Limites.97.5..      Vif  Coef.Std
#&gt; (Intercept) -108.5758465  -138.5559230     -78.595770 0.000000 0.0000000
#&gt; D16            5.6713954     3.1227268       8.220064 7.470209 0.6522030
#&gt; HT             0.6937702     0.3480719       1.039469 1.234397 0.2391034
#&gt; DBH            1.6257654    -0.5491507       3.800682 7.087104 0.2133976</code></pre>
<p>Examinando los valores en la columna “Standarized Estimate”, vemos
que aparentemente, D16 tiene mayor peso (en términos absolutos) sobre el
volumen de madera en función de las variables estandarizadas: el
promedio del volumen de madera estandarizado aumenta en 0.65 unidades al
aumentar una unidad el diametro a los 16 pies de altura, al mantener
fijo los resultados de las otras tres pruebas. La segunda variable con
mayor peso es la altura HT. La altura a 4 pies de altura no tiene efecto
significativo sobre el volumen de madera.</p>
<p>###<strong>COMPARACIÓN DE EFECTOS PARCIALES DE LAS VARIABLES
EXPLICATORIAS Y MULTICOLINEALIDAD</strong></p>
<p>Considere el MRLM</p>
<p><span class="math display">\[\large
Y_i=\beta_0+\beta_1X_{i1}+\beta_2X_{i2}+...+\beta_kX_{ik}+\varepsilon_i\]</span></p>
<p>Si las variables explicatorias no están en una misma escala de
medida, no podemos determinar cuál tiene mayor o menor efecto parcial
sobre la respuesta promedio, en presencia de las demás, esto es, la
magnitud de <span class="math inline">\(\beta_j\)</span>􀟚􀯝 refleja las
unidades de la variable <span class="math inline">\(X_j\)</span>.</p>
<p>Para hacer comparaciones en forma directa de los coeficientes de
regresión se recurre al uso de variables escalonadas, tanto la respuesta
como las explicatorias.</p>
<p><strong>Escalonamiento normal unitario</strong></p>
<p>Cada variable es escalonada restando su media muestral y dividiendo
esta diferencia por la desviación estándar muestral de la variable, es
decir:</p>
<p><span class="math display">\[\large Y_i^*=\frac{Y_i-\bar
Y}{\sum_{i=1}^n (Y_i-\bar Y)^2/(n-1)} \]</span></p>
<p><span class="math display">\[\large X_i^*=\frac{X_i-\bar
X}{\sum_{i=1}^n (X_i-\bar X)^2/(n-1)} \]</span></p>
<p>Ajustamos el modelo de regresión sin intercepto <span
class="math display">\[\large
Y_i^*=\beta_1X_{i1}^*+\beta_2X_{i2}^*+...+\beta_kX_{ik}^*+\varepsilon_i
\]</span> Los coeficientes de regresión estandarizados <span
class="math inline">\(\beta_j^*\)</span> pueden ser comparados
directamente teniendo en cuenta que siguen siendo coeficientes de
regresión parcial, es decir, mide el efecto de <span
class="math inline">\(X_J\)</span> dado que las demás variables
explicatorias están en el modelo, además, los <span
class="math inline">\(\beta_j\)</span> pueden servir para determinar la
importancia relativa de <span class="math inline">\(X_j\)</span> en
presencia de las demás variables, en la muestra o conjunto de datos
particular considerado para el ajuste.</p>
<p>NOTA: Hay que tener cuidado al interpretar y comparar los
coeficientes estandarizados pues en presencia de multicolinealidad
nuestras conclusiones pueden ser erradas.</p>
<p>DEFINICIÓN: Multicolinealidad es la existencia de dependencia casi
lineal entre variables explicatorias en el MRLM.</p>
<p>Si existiera dependencia lineal exacta entre dos o más variables
explicatorias, la matrix XtX seria singular y por tanto no podríamos
hallar los estimadores de mínimos cuadrados!.</p>
</div>
</div>

<br>
<hr>
<p><center>Copyright &copy; 2019, webpage made with Rmarkdown.</center></p>
<hr>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3,h4,h5",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = false;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
