<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Pruebas no paramétricas</title>

<script src="site_libs/header-attrs-2.14/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/flatly.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />
<link href="site_libs/ionicons-2.0.1/css/ionicons.min.css" rel="stylesheet" />
<link rel="icon" type="image/png" href="images/favicon.png" />

<script type="text/javascript" src="js/rmarkdown.js"></script>

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-88209726-1', 'auto');
  ga('send', 'pageview');
</script>


<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}

.tocify-subheader {
  display: inline;
}
.tocify-subheader .tocify-item {
  font-size: 0.95em;
}

</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Estadística ITM</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="pagin1.html">
    <span class="fa fa-line-chart"></span>
     
    Est Básica
  </a>
</li>
<li>
  <a href="inf.html">
    <span class="fa fa-bar-chart-o"></span>
     
    Est inferencial
  </a>
</li>
<li>
  <a href="medi.html">
    <span class="fa fa-puzzle-piece"></span>
     
    Metrología
  </a>
</li>
<li>
  <a href="https://www.itm.edu.co">
    <span class="ion ion-university"></span>
     
  </a>
</li>
<li>
  <a href="https://github.com/estadisticaITM">
    <span class="fa fa-github"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Pruebas no paramétricas</h1>

</div>


<div id="graficos-para-analizar-la-distribución-de-los-datos"
class="section level1">
<h1>Graficos para analizar la distribución de los datos</h1>
<p>Gran parte de los modelos estadísticos consideran que las
observaciones provienen de poblaciones normales. En muchas situaciones
este supuesto no se cumple. A continuación se mencionan algunos gráficos
utilizados para analizar la distribución de los datos, además de la
detección de puntos atípicos.</p>
<p>En metrología los datos atípicos son llamados valores aberrantes,
conocidos como las observaciones que se desvían significativamente de la
tendencia general de los datos o que están considerablemente alejados de
otros valores de la muestra. La detección y gestión de valores
aberrantes es importante en metrología para garantizar la precisión y
fiabilidad de las mediciones. Los valores aberrantes pueden sesgar los
resultados del análisis y afectar la toma de decisiones basada en los
datos.</p>
<div id="gráfico-de-densidad" class="section level2">
<h2>Gráfico de densidad</h2>
<p>Visualiza la distribución de datos en un intervalo continuo. Este
gráfico es una variación de un histograma, donde el concepto de
frecuencia relativa se cambia por el de probabilidad, la suma de todas
la superficie será 1.</p>
<p>Los picos ayudan a mostrar dónde los valores se concentran en el
intervalo, a su vez permite comparar la densidad de una variable
continua en relación a los niveles de factor de una variable
cualitativa.</p>
<p><strong>Ejemplo</strong></p>
<p>El acceso al agua potable es esencial para la salud, un derecho
humano básico y un componente de una política eficaz de protección de la
salud. Esto es importante como cuestión de salud y desarrollo a nivel
nacional, regional y local. En algunas regiones, se ha demostrado que
las inversiones en abastecimiento de agua y saneamiento pueden generar
un beneficio económico neto, ya que las reducciones de los efectos
adversos para la salud y los costos de atención médica superan los
costos de llevar a cabo las intervenciones.</p>
<p>El PH es un parámetro importante para evaluar el equilibrio
ácido-base del agua. La OMS ha recomendado un límite máximo permitido de
pH de 6,5 a 8,5.</p>
<p>Se tienen los datos del ph del agua dependiendo de si el agua es
potable o no, 632 datos de agua potable y 632 de agua no potable, se
desea comparar su distribución.</p>
<pre class="r"><code>library(ggplot2)

head(no)</code></pre>
<pre><code>## [1]  3.7  8.1  8.3  9.1  5.6 10.2</code></pre>
<pre class="r"><code>head(si)</code></pre>
<pre><code>## [1] 9.4 9.0 6.8 7.2 7.7 8.3</code></pre>
<pre class="r"><code># datos 

par(mfrow=c(1,2))
tmp &lt;- rbind(data.frame(origen = &quot;no&quot;, dato = no), 
             data.frame(origen = &quot;si&quot;, dato = si))
ggplot(tmp, aes(x =dato, fill = origen)) +
  geom_density(alpha = 0.3)</code></pre>
<p><img src="pruebas_no_paramétricas_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<pre class="r"><code>hist(no, xlab = &quot;PH agua no potable&quot;, ylab = &quot;Frecuencia&quot;, las=1, main = &quot;&quot;, col = &quot;gray&quot;)

hist(si, xlab = &quot;PH agua potable&quot;, ylab = &quot;Frecuencia&quot;, las=1, main = &quot;&quot;, col = &quot;gray&quot;)</code></pre>
<p><img src="pruebas_no_paramétricas_files/figure-html/unnamed-chunk-2-2.png" width="672" /></p>
</div>
<div id="grafico-cuantil-cuantil" class="section level2">
<h2>Grafico cuantil cuantil</h2>
<p>Los gráficos cuantil cuantil son una ayuda para explorar si un
conjunto de datos proviene de una población con cierta distribución.</p>
<iframe width="280" height="160" src="https://www.youtube.com/embed/kx_o9rnI4DE" title="QQplot" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen>
</iframe>
<p>La función <strong>qqnorm</strong> sirve para explorar la normalidad
de una muestra, generalmente va acompañada de una linea recta de
referencia, que se estima con la función <strong>qqline</strong>.</p>
<p>La función <strong>qqplot</strong> sirve para crear el gráfico
cuantil cuantil para cualquier distribución, requiere los cuantiles de
la distribución candidata.</p>
<p><strong>Ejemplo de los datos de agua potable</strong></p>
<pre class="r"><code>par(mfrow=c(1, 2))

qqnorm(y=si, main=&#39;PH agua potable&#39;, ylab=&#39;Cuantiles muestrales&#39;,
       xlab=&#39;Cuantiles teóricos&#39;, las=1)
qqline(y=si, col=&#39;blue&#39;, lwd=2, lty=2)

qqnorm(y=no, main=&#39;PH agua no potable&#39;, ylab=&#39;Cuantiles muestrales&#39;,
       xlab=&#39;Cuantiles teóricos&#39;, las=1)
qqline(y=no, col=&#39;blue&#39;, lwd=2, lty=2)</code></pre>
<p><img src="pruebas_no_paramétricas_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
</div>
<div id="boxplot" class="section level2">
<h2>Boxplot</h2>
<p>El boxplot es una herramienta de análisis que resalta las principales
características de un conjunto de datos, los números usados para
construirlo son:</p>
<ul>
<li>Valor mínimo</li>
<li>Los cuartiles <span class="math inline">\(Q_1,Q_2,Q_3\)</span></li>
<li>Valor máximo</li>
</ul>
<p><img src="imagen/boxplot.png" width="294" style="display: block; margin: auto;" /></p>
<p>Cada sección contiene el 25% de los datos. La caja muestra la mitad
de los datos, es decir el 50% de ellos, contiene la información entre el
3 cuartil y el primer cuartil.</p>
<ul>
<li><p>Sirve para realizar comparaciones de una variable cuantitativa,
en relación a los niveles de una variable cualitativa.</p></li>
<li><p>Es posible observar la dispersión de cada caja, mientras mas
larga, más dispersión.</p></li>
<li><p>Permite observar puntos atípicos,los cuales no están contenidos
dentro de la caja, ni en sus bigotes.</p></li>
</ul>
<p><strong>Ejemplo</strong></p>
<p>construir un boxplot con los datos del ph del agua según su
potabilidad, Qué infiere?</p>
<pre class="r"><code>boxplot(no,si)
abline(h=6.5,col=2)
abline(h=8.5,col=2)</code></pre>
<p><img src="pruebas_no_paramétricas_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
</div>
</div>
<div
id="pruebas-de-bondad-de-ajuste-para-distribuciones-de-probabilidad"
class="section level1">
<h1>Pruebas de bondad de ajuste para distribuciones de probabilidad</h1>
<iframe width="280" height="160" src="https://www.youtube.com/embed/U8ZpUT1c8A4" title="¿Qué es una prueba de bondad de ajuste?" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen>
</iframe>
<div id="pruebas-de-normalidad" class="section level2">
<h2>Pruebas de normalidad</h2>
<p>La hipotesis nula y alternativa de normalidad son las siguientes:</p>
<p><span class="math display">\[H_0:  \quad Los\quad datos\quad se\quad
distribuyen \quad normal\]</span></p>
<p><span class="math display">\[H_1:  \quad Los\quad datos\quad no \quad
se\quad distribuyen \quad normal\]</span> Existen diferentes pruebas
para evaluar la normalidad, todas son de fácil implementación en R.</p>
<ul>
<li><strong>Prueba Shapiro-Wilk</strong></li>
</ul>
<p>En R se usa la función <strong>shapiro.test</strong>, se usa cuando
la muestra es como máximo de tamaño 50. Es más potente que la prueba de
K-S.</p>
<ul>
<li><p>Prueba Anderson-Darling con la función ad.test del paquete
nortest.</p></li>
<li><p>Prueba Cramer-von Mises con la función cvm.test del paquete
nortest.</p></li>
<li><p>Prueba Lilliefors (Kolmogorov-Smirnov) con la función lillie.test
del paquete nortest.</p></li>
<li><p>Prueba Pearson chi-square con la función pearson.test del paquete
nortest.</p></li>
<li><p>Prueba Shapiro-Francia con la función sf.test del paquete
nortest.</p></li>
</ul>
<p><strong>Ejemplo en R probando normalidad en los datos de potabilidad
del agua</strong></p>
<p>Para los datos del ph del agua, se desea probar mediante una prueba
estadística si los datos se distribuyen de forma normal</p>
<pre class="r"><code>shapiro.test(no)</code></pre>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  no
## W = 0.99749, p-value = 0.4571</code></pre>
<pre class="r"><code>shapiro.test(si)</code></pre>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  si
## W = 0.9852, p-value = 5.12e-06</code></pre>
<p><strong>Otro Ejemplo en R</strong></p>
<p>Se necesita verificar si es correcto suponer que el volumen de
llenado (en onzas) de una máquina dispensadora de jugos sigue una
distribución normal, por lo que se toman 25 botellas de forma aleatoria.
Los datos del volumen de llenado obtenidos de la muestra se encuentran
almacenados en el vector volumen.</p>
<p><strong>Hipótesis</strong></p>
<p><span class="math inline">\(H_0:\)</span> el volumen de llenado (en
onzas) sigue una distribución normal.</p>
<p><span class="math inline">\(H_1:\)</span> el volumen de llenado (en
onzas) no sigue una distribución normal.</p>
<p>Nivel de significancia: 0.05 (Hipotético).</p>
<p><strong>Analisis descriptivo</strong></p>
<pre class="r"><code>library(nortest)
volumen &lt;-c(8.39,12.14,11.80,12.04,7.34,12.62,11.51,12.47,11.08,14.32,11.33,11.56, 12.79,11.72,12.84,11.73,12.1,11.88,11.95,10.84,11.79,13.21,12.56,12.55,12.80)

mean(volumen)</code></pre>
<pre><code>## [1] 11.8144</code></pre>
<pre class="r"><code>sd(volumen)</code></pre>
<pre><code>## [1] 1.4036</code></pre>
<pre class="r"><code>require(car)</code></pre>
<pre><code>## Loading required package: car</code></pre>
<pre><code>## Loading required package: carData</code></pre>
<pre class="r"><code>library(MASS)
par(mfrow=c(1,4))
hist(volumen, xlab = &quot;Volumen de llenado&quot;, ylab = &quot;Frecuencia&quot;, las=1, main = &quot;&quot;, col = &quot;gray&quot;)

plot(density(volumen), xlab = &quot;Volumen de llenado&quot;, ylab = &quot;Densidad&quot;, las=1, main = &quot;&quot;)

qqPlot(volumen, xlab=&quot;Cuantiles teóricos&quot;, ylab=&quot;Cuantiles muestrales&quot;, las=1,main=&quot;&quot;)</code></pre>
<pre><code>## [1] 5 1</code></pre>
<pre class="r"><code>boxplot(volumen)</code></pre>
<p><img src="pruebas_no_paramétricas_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<pre class="r"><code>ks.test(volumen, &quot;pnorm&quot;, mean =11.81, sd=1.4)</code></pre>
<pre><code>## 
##  One-sample Kolmogorov-Smirnov test
## 
## data:  volumen
## D = 0.21516, p-value = 0.1703
## alternative hypothesis: two-sided</code></pre>
<pre class="r"><code>shapiro.test(volumen)</code></pre>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  volumen
## W = 0.8161, p-value = 0.0004272</code></pre>
<pre class="r"><code>ad.test(volumen)</code></pre>
<pre><code>## 
##  Anderson-Darling normality test
## 
## data:  volumen
## A = 1.6505, p-value = 0.0002268</code></pre>
<pre class="r"><code>cvm.test(volumen)</code></pre>
<pre><code>## 
##  Cramer-von Mises normality test
## 
## data:  volumen
## W = 0.27431, p-value = 0.0005727</code></pre>
<pre class="r"><code>sf.test(volumen)</code></pre>
<pre><code>## 
##  Shapiro-Francia normality test
## 
## data:  volumen
## W = 0.79487, p-value = 0.0004128</code></pre>
</div>
<div id="pruebas-para-otras-distribuciones" class="section level2">
<h2>Pruebas para otras distribuciones</h2>
<p>Una alternativa a la no normalidad de los datos, es proceder a
implementar pruebas no paramétricas, para evaluar si los datos se
ajustan a una distribución hipotética.</p>
<p><strong>Pruebas de hipótesis</strong></p>
<p><span class="math inline">\(H_0:\)</span> Los datos analizados siguen
una distribución M.</p>
<p><span class="math inline">\(H_1:\)</span> Los datos analizados no
siguen una distribución M</p>
<div id="test-de-kolmogorov-smirnov-k-s" class="section level3">
<h3>Test de Kolmogorov-Smirnov K-S</h3>
<p>Se emplea para saber si una distribución de probabilidad acumulada
difiere de una distribución hipotética, por lo general la distribución
normal, la uniforme, la de Poisson o la exponencial. Es decir permite
contrastar si un conjunto de datos muestrales proviene de un tipo de
distribución.</p>
<p><strong>Estadístico</strong></p>
<p>Cuando K-S se aplica para contrastar la hipótesis de normalidad de la
población, el estadístico de prueba es la máxima diferencia entre las
funciones de distribución de probabilidad muestral y la teórica:</p>
<p><span class="math display">\[D=max|F_n-F_0(x)|\]</span></p>
<p>Siendo <span class="math inline">\(F_n(x)\)</span> la función de
distribución muestral y <span class="math inline">\(F_0(x)\)</span> es
la función teórica (normal) especificada en la hipotesis nula <span
class="math inline">\(H_0\)</span></p>
<p><strong>Ejemplo probando la distribución exponencial</strong></p>
<p>Celia quiere medir el tiempo de atención a los usuarios. Se
seleccionaron 20 personas y los tiempos de atención en minutos.</p>
<pre class="r"><code>require(car)
tiempo&lt;-c(3.69, 39.50,  4.43,  2.70,  9.11, 10.21, 10.44,  2.57,  5.68,  0.80,12.63,  2.35, 25.47, 8.07,  0.96,  0.21, 12.06, 10.79,  6.58, 13.06)

par(mfrow=c(1,4))
hist(tiempo, xlab = &quot;Tiempo&quot;, ylab = &quot;Frecuencia&quot;, las=1, main = &quot;&quot;, col = &quot;gray&quot;)
qqPlot(tiempo, col = &quot;gray&quot;, ylab=&quot;Tiempo&quot;)</code></pre>
<pre><code>## [1]  2 13</code></pre>
<pre class="r"><code>plot(density(tiempo), xlab = &quot;Tiempo&quot;, ylab = &quot;Densidad&quot;, las=1, main = &quot;&quot;)
boxplot(tiempo, xlab = &quot;Tiempo&quot;, ylab = &quot;Densidad&quot;, las=1, main = &quot;&quot;)</code></pre>
<p><img src="pruebas_no_paramétricas_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>Se procede a revisar el ajuste con respecto a una distribución
exponencial con un α=0.05</p>
<p>Sea X el tiempo entre llegadas a Celia Express.</p>
<p><span class="math display">\[H_0:X∼exp\]</span></p>
<p><span class="math display">\[H_1:X≁exp\]</span></p>
<p>La siguiente función ayuda a estimar los parámetros del modelo</p>
<pre class="r"><code>library(MASS)
Ajustex &lt;- fitdistr(tiempo,&quot;exponential&quot;)
Ajustex</code></pre>
<pre><code>##       rate   
##   0.11030831 
##  (0.02466569)</code></pre>
<pre class="r"><code>Ks&lt;- ks.test(tiempo, &quot;pexp&quot;, rate=Ajustex$estimate[1])
Ks</code></pre>
<pre><code>## 
##  One-sample Kolmogorov-Smirnov test
## 
## data:  tiempo
## D = 0.13678, p-value = 0.8006
## alternative hypothesis: two-sided</code></pre>
<p>Según las pruebas realizadas, no se rechaza la hipótesis nula y por
tanto, se asume la distribución exponencial.</p>
<p><strong>Ejemplo comparando dos distribuciones</strong></p>
<p>Se desea saber si los datos de potabilidad de agua (potable y no
potable) siguen la misma distribución de probabilidad.</p>
<p><span class="math display">\[H_0:X_{si}∼X_{no}\]</span></p>
<p><span class="math display">\[H_1:X_{si}≁X_{no}\]</span></p>
<pre class="r"><code>par(mfrow=c(1,2))
hist(si)
hist(no)</code></pre>
<p><img src="pruebas_no_paramétricas_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<pre class="r"><code>ks.test(si, no)</code></pre>
<pre><code>## Warning in ks.test(si, no): p-value will be approximate in the presence of ties</code></pre>
<pre><code>## 
##  Two-sample Kolmogorov-Smirnov test
## 
## data:  si and no
## D = 0.058544, p-value = 0.2289
## alternative hypothesis: two-sided</code></pre>
</div>
<div id="prueba-chi-cuadrado" class="section level3">
<h3>Prueba Chi cuadrado</h3>
<p>Tiene diferentes usos entre los que se encuentran</p>
<ul>
<li>Determinar si una variable categórica sigue o no, una distribución
hipotética, como la binomial o la poisson.</li>
</ul>
<p><strong>El juego de hipótesis es:</strong></p>
<p><span class="math inline">\(H_0:\)</span> Los datos analizados siguen
una distribución M.</p>
<p><span class="math inline">\(H_1:\)</span> Los datos analizados no
siguen una distribución M</p>
<p><strong>Grados de libertad</strong></p>
<p><span class="math display">\[gl=\quad  k \quad
observaciones-\quad  t\quad  parametros \quad  estimados\quad
-1\]</span></p>
<ul>
<li>Evaluar si una variable es independiente de la otra: Dos variables
aleatorias X e Y son llamadas independientes, si la distribución de
probabilidad de una de las variables no es afectada por la presencia de
la otra.</li>
</ul>
<p><strong>El juego de hipótesis es:</strong></p>
<p><span class="math inline">\(H_o:\)</span> Las variables son
independientes, una variable no varía entre los distintos niveles de la
otra variable. <span class="math inline">\(H_a:\)</span> Las variables
son dependientes, una variable varía entre los distintos niveles de la
otra variable.</p>
<p><strong>Grados de libertad</strong></p>
<p><span class="math display">\[df=(columnas−1)*(filas−1)\]</span></p>
<ul>
<li>Comparar si dos distribuciones de probabilidad se desempeñan de las
misma manera</li>
</ul>
<p><strong>El juego de hipótesis es:</strong></p>
<p><span class="math inline">\(H_o:\)</span> la distribución de
probabilidad de x es similar a y.</p>
<p><span class="math inline">\(H_a:\)</span> la distribución de
probabilidad de x no es similar a y.</p>
<p>En todos los casos el <strong>estadístico</strong> corresponde a:</p>
<p><span class="math display">\[ \large \chi^2=\sum_{i,j}^n \frac
{(o_{ij}-e_{ij})^2}{e_{ij}}\]</span></p>
<p>Asuma que <span class="math inline">\(Oij\)</span> es la frecuencia
observada de eventos que pertenecen a ambos, la i−ésima categoría de X y
la j−ésima categoría de Y. Además, suponga que <span
class="math inline">\(e_{ij}\)</span> son las correspondientes
frecuencias esperadas si X e Y son independientes.</p>
<p><strong>Videos ejemplo</strong></p>
<p><strong>Prueba chi cuadrado para la independencia de dos
distribuciones</strong></p>
<iframe width="280" height="160" src="https://www.youtube.com/embed/tWfNv_z_bB0" title="Prueba chi cuadrada para tablas de contingencia" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen>
</iframe>
<p><strong>Prueba de bondad de ajuste para la distribución de
probabilidad binomial</strong></p>
<iframe width="280" height="160" src="https://www.youtube.com/embed/DXKn_0ceN-8" title="Prueba de bondad de ajuste caso binomial" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen>
</iframe>
<p><strong>Prueba de bondad de ajuste para la distribución de
probabilidad poisson</strong></p>
<iframe width="280" height="160" src="https://www.youtube.com/embed/2USOJ5qTVsE" title="Prueba de bondad de ajuste caso Poisson" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen>
</iframe>
<p><strong>Ejemplo</strong> En un supermercado se está estudiando el
comportamiento del número de personas que llegan cada hora. Se
analizaron 20 horas, cuyos datos se consignan a continuación:</p>
<p><strong>Análisis exploratorio</strong> Se analiza los gráficos para
determinar una distribución hipotética.</p>
<pre class="r"><code>personas&lt;-c(13, 14, 14, 19, 17, 14, 13,  9, 16, 16,13, 13, 15, 13,  7, 14, 14, 13, 20, 15)

mean(personas)</code></pre>
<pre><code>## [1] 14.1</code></pre>
<pre class="r"><code>par(mfrow=c(1,2))
hist(personas, xlab = &quot;personas&quot;, ylab = &quot;Frecuencia&quot;, las=1, main = &quot;&quot;, col = &quot;gray&quot;)
plot(density(personas), xlab = &quot;personas&quot;, ylab = &quot;Densidad&quot;, las=1, main = &quot;&quot;)</code></pre>
<p><img src="pruebas_no_paramétricas_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<p>En este caso, la variable de interés registra un número de eventos
por unidad de tiempo, por lo que se sugiere analizar el ajuste a una
distribución poisson. Se muestra la respectiva prueba de hipótesis. Sea
X el número de clientes que visitan Celia Express.</p>
<p><span class="math inline">\(H_0:X_i∼Poisson\)</span></p>
<p><span class="math inline">\(H_1:X_i≁Poisson\)</span></p>
<p><strong>Manualmente</strong></p>
<p>Los valores se agrupan en una tabla de frecuencias</p>
<table>
<thead>
<tr class="header">
<th align="center">Clientes/hora</th>
<th align="center">Frec obs</th>
<th align="center">prob</th>
<th align="center">frec esp</th>
<th align="center">(obs-esp)^2/esp</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">9</td>
<td align="center">2</td>
<td align="center">0.048</td>
<td align="center">0.96</td>
<td align="center">1.1</td>
</tr>
<tr class="even">
<td align="center">13</td>
<td align="center">6</td>
<td align="center">0.106</td>
<td align="center">2.12</td>
<td align="center">7.1</td>
</tr>
<tr class="odd">
<td align="center">14</td>
<td align="center">5</td>
<td align="center">0.105</td>
<td align="center">2.12</td>
<td align="center">3.9</td>
</tr>
<tr class="even">
<td align="center">15</td>
<td align="center">2</td>
<td align="center">0.098</td>
<td align="center">1.97</td>
<td align="center">0</td>
</tr>
<tr class="odd">
<td align="center">16</td>
<td align="center">2</td>
<td align="center">0.085</td>
<td align="center">1.72</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td align="center">17</td>
<td align="center">3</td>
<td align="center">0.07</td>
<td align="center">1.41</td>
<td align="center">1.8</td>
</tr>
<tr class="odd">
<td align="center">total</td>
<td align="center">20</td>
<td align="center"></td>
<td align="center"></td>
<td align="center">13.9</td>
</tr>
</tbody>
</table>
<p>el valor del promedio <span class="math inline">\(\lambda\)</span> se
estima asi: <span
class="math display">\[\lambda=\frac{(9*2)+(13*6)+(14*5)+(15*2)+(16*2)+(17*3)}{20}=13.95\]</span></p>
<p>A partir de este valor se estima la probabilidad de cada uno de ellos
según la distribución de probabilidad poisson</p>
<p><span
class="math display">\[p(x=9)=\frac{e^{-\lambda}\lambda^x}{x!}=\frac{e^{-13.95}13.95^9}{9!}=0.048\]</span></p>
<p>La frecuencia esperada se obtiene de multiplicar cada valor de
probabilidad por 20.</p>
<p>El valor del estadístico es 13.9 los grados de libertad de la
distribución está dado por: gl=observaciones- k (parámetros
estimados)-1</p>
<p><span class="math display">\[P(\chi^2_4&gt;13.9)=0.0075 \]</span>
rechaza la hipotesis nula y se concluye que los datos no se distribuye
poisson</p>
<p><strong>En Rstudio</strong></p>
<p>Para estimar los parámetros de una distribución de probabilidad
discreta (poisson y binomial), se requiere la función goodfit del
paquete vcd. Esta función también realiza la prueba de bondad de ajuste
y sus argumentos son: variable de interés, tipo de distribución y
método. Se usará el test de Chi-cuadradado a través del argumento
“MinChisq”</p>
<pre class="r"><code>require(vcd)</code></pre>
<pre><code>## Loading required package: vcd</code></pre>
<pre><code>## Loading required package: grid</code></pre>
<pre class="r"><code>gf&lt;-goodfit(personas, type = &quot;poisson&quot;, method = &quot;MinChisq&quot;)
gf$par</code></pre>
<pre><code>## $lambda
## [1] 13.60833</code></pre>
<pre class="r"><code>summary(gf)</code></pre>
<pre><code>## Warning in summary.goodfit(gf): Chi-squared approximation may be incorrect</code></pre>
<pre><code>## 
##   Goodness-of-fit test for poisson distribution
## 
##              X^2 df  P(&gt; X^2)
## Pearson 19.30042 19 0.4377217</code></pre>
<pre class="r"><code>chisq.test(personas)</code></pre>
<pre><code>## 
##  Chi-squared test for given probabilities
## 
## data:  personas
## X-squared = 11.333, df = 19, p-value = 0.9121</code></pre>
<p><strong>Ejemplo Comparación de distribuciones</strong></p>
<p>Retomando el ejemplo de el ph de agua potable y no potable</p>
<p><span class="math inline">\(H_0:X_{si}∼y_{no}\)</span></p>
<p><span class="math inline">\(H_1:X_{si}≁y_{no}\)</span></p>
<pre class="r"><code>chisq.test(no,si)</code></pre>
<pre><code>## Warning in chisq.test(no, si): Chi-squared approximation may be incorrect</code></pre>
<pre><code>## 
##  Pearson&#39;s Chi-squared test
## 
## data:  no and si
## X-squared = 6298.3, df = 6318, p-value = 0.5672</code></pre>
<p><strong>Ejemplo en R:</strong></p>
<p>Se usan los datos de la base survey de la librería MASS de R, que
corresponden a 237 observaciones provenientes de una encuesta a
estudiantes de estadística de una Universidad en Australia.</p>
<ol style="list-style-type: decimal">
<li>Valide la hipótesis de si el hábito de fumar es independiente del
nivel de ejercicios de los estudiantes usando un nivel de significancia
del 0.05.</li>
</ol>
<p><strong>El juego de hipotesis es:</strong></p>
<p><span class="math inline">\(H_o:\)</span> El hábito de fumar es
independiente de hacer ejercicio</p>
<p><span class="math inline">\(H_a:\)</span> El hábito de fumar es
dependiente de hacer ejercicio</p>
<pre class="r"><code>## Para inst lar librerías use

# install.packages(&quot;MASS&quot;)

## Para llamar la librería
library(MASS)
library(DT)

## se usan las variables
## FUMA (Smoke) con los niveles: Heavy, Regul, Occas y Never 
## EJERCICIO (Exer) con los niveles: Freq, Some, y None
##se tabulan

tbl=table(survey$Smoke,survey$Exer)
tbl</code></pre>
<pre><code>##        
##         Freq None Some
##   Heavy    7    1    3
##   Never   87   18   84
##   Occas   12    3    4
##   Regul    9    1    7</code></pre>
<pre class="r"><code>chisq.test(tbl)</code></pre>
<pre><code>## Warning in chisq.test(tbl): Chi-squared approximation may be incorrect</code></pre>
<pre><code>## 
##  Pearson&#39;s Chi-squared test
## 
## data:  tbl
## X-squared = 5.4885, df = 6, p-value = 0.4828</code></pre>
<pre class="r"><code>#Note que aparece un mensaje de alerta. Esto es debido a que en algunas celdas las
#frecuencias son muy pequeñas. Podemos solucionar esto agrupando algunas columnas.

ctbl = cbind(tbl[,&quot;Freq&quot;], tbl[,&quot;None&quot;] + tbl[,&quot;Some&quot;])
ctbl</code></pre>
<pre><code>##       [,1] [,2]
## Heavy    7    4
## Never   87  102
## Occas   12    7
## Regul    9    8</code></pre>
<pre class="r"><code>chisq.test(ctbl)</code></pre>
<pre><code>## 
##  Pearson&#39;s Chi-squared test
## 
## data:  ctbl
## X-squared = 3.2328, df = 3, p-value = 0.3571</code></pre>
<pre class="r"><code>mosaicplot(ctbl,
  main = &quot;Mosaic plot&quot;,
  color = TRUE
)</code></pre>
<p><img src="pruebas_no_paramétricas_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
<p><strong>fuerza de asociación</strong></p>
<pre class="r"><code>library(vcd)
assocstats(x = tbl)</code></pre>
<pre><code>##                     X^2 df P(&gt; X^2)
## Likelihood Ratio 5.8015  6  0.44579
## Pearson          5.4885  6  0.48284
## 
## Phi-Coefficient   : NA 
## Contingency Coeff.: 0.151 
## Cramer&#39;s V        : 0.108</code></pre>
</div>
</div>
</div>
<div id="pruebas-de-independencia-de-las-distribuciones"
class="section level1">
<h1>Pruebas de independencia de las distribuciones</h1>
<p>Se utilizan cuando se quiere estudiar si existe asociación entre dos
variables cualitativas, es decir, si las proporciones de una variable
son diferentes dependiendo del valor que adquiera la otra variable.</p>
<p>Existen dos tipos de pruebas de independencia, la prueba chi cuadrado
y la prueba exacta de fisher. La prueba de Chi-cuadrado se utiliza
cuando la muestra es suficientemente grande. La prueba exacta de Fisher
se utiliza cuando la muestra es pequeña.</p>
<p>La prueba de Chi-cuadrado no es adecuada cuando los valores esperados
en una de las celdas de la tabla de contingencia son menores a 5; en
este caso, se prefiere la prueba exacta de Fisher (McCrum-Gardner, 2008;
Bower, 2003).</p>
<p><strong>El juego de hipótesis es:</strong></p>
<p><span class="math inline">\(H_o:\)</span> Las variables son
independientes, una variable no varía entre los distintos niveles de la
otra variable.</p>
<p><span class="math inline">\(H_a:\)</span> Las variables son
dependientes, una variable varía entre los distintos niveles de la otra
variable.</p>
<p><strong>Fuerza de asociación entre variables cualitativas (tamaño del
efecto)</strong></p>
<p>Dado que las pruebas contrastan si las variables están relacionadas,
al tamaño del efecto se le conoce como fuerza de asociación. Existen
múltiples medidas de asociación, entre las que destacan phi o Cramer’s
V. Los límites empleados para su clasificación son:</p>
<p><strong>Test exacto de fisher</strong></p>
<p>Se aplica para comparar dos variables categóricas con dos niveles
cada una (tabla 2x2), está diseñado para situaciones en las que las
frecuencias marginales de filas y columnas (los totales de cada fila y
columna) son fijas, se conocen de antemano. Esta condición es relevante
en los experimentos biológicos ya que no es común poder cumplirla. Si
esta condición no se satisface el test de Fisher deja de ser exacto, por
lo general pasando a ser más conservativo.</p>
<p><strong>Ejemplo de experimentos con y sin frecuencias marginales
fijas:</strong></p>
<p><strong>Frecuencias marginales fijas:</strong></p>
<p>Supóngase que se quiere saber si la preferencia que tienen dos
especies de pájaros (estorninos y gorriones) para refugiarse en casetas
artificiales es diferente dependiendo del material de fabricación
(madera o metal). Para ellos se disponen en una pajarera 5 casetas de
metal y 5 de madera y se sueltan en el interior de la jaula 4 gorriones
y 6 estorninos. En este experimento se sabe que las frecuencias
marginales van a ser 5, 5, 4, 6 lo que no se sabe es como se van a
distribuir las observaciones dentro de la tabla.</p>
<table>
<thead>
<tr class="header">
<th align="center">Pájaro</th>
<th align="center">Metal</th>
<th align="center">Madera</th>
<th align="center">total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Gorrión</td>
<td align="center">?</td>
<td align="center">?</td>
<td align="center">4</td>
</tr>
<tr class="even">
<td align="center">Estornino</td>
<td align="center">?</td>
<td align="center">?</td>
<td align="center">6</td>
</tr>
<tr class="odd">
<td align="center">Total</td>
<td align="center">5</td>
<td align="center">5</td>
<td align="center">10</td>
</tr>
</tbody>
</table>
<p><strong>Frecuencias marginales no fijas:</strong></p>
<p>Supóngase que se quiere determinar si un fármaco acelera la
cicatrización. Para ello se selecciona a 50 pacientes que se reparten
aleatoriamente en dos grupos iguales (tratamiento y placebo), tras una
semana de tratamiento se determina si la cicatrización ha finalizado (si
/ no). En este caso las frecuencias marginales de los tratamientos son
fijas, 25 para cada grupo, sin embargo no se sabe cuántos en cada grupo
van a haber cicatrizado o no, por lo que las frecuencias marginales del
resultado de cicatrización no son fijas.</p>
<table>
<thead>
<tr class="header">
<th align="center">Tratamiento</th>
<th align="center">cicatrizado</th>
<th align="center">No cicatrizado</th>
<th align="center">total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">placebo</td>
<td align="center">?</td>
<td align="center">?</td>
<td align="center">25</td>
</tr>
<tr class="even">
<td align="center">Tratamiento</td>
<td align="center">?</td>
<td align="center">?</td>
<td align="center">25</td>
</tr>
<tr class="odd">
<td align="center">Total</td>
<td align="center">?</td>
<td align="center">?</td>
<td align="center">50</td>
</tr>
</tbody>
</table>
<p><strong>Condiciones del test</strong></p>
<ul>
<li><p>Independencia,las observaciones de la muestra deben ser
independientes unas de otras.</p></li>
<li><p>Muestreo aleatorio.</p></li>
<li><p>Tamaño de la muestra &lt; 10% población.</p></li>
<li><p>Cada observación contribuye únicamente a uno de los
niveles.</p></li>
<li><p>Las frecuencias marginales de columnas y filas tienen que ser
fijas. Si esta condición no se cumple, el test de Fisher deja de ser
exacto.</p></li>
</ul>
<p><strong>Cálculo del p-value</strong></p>
<p>El test exacto de Fisher se basa en la distribución hipergeométrica,
que permite calcular la probabilidad exacta de obtener una determinada
distribución de eventos dentro de una tabla. Supóngase la siguiente
tabla de contingencia:</p>
<table>
<thead>
<tr class="header">
<th align="center">Niveles</th>
<th align="center">Nivel A1</th>
<th align="center">Nivel A2</th>
<th align="center">total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Nivel B1</td>
<td align="center">a</td>
<td align="center">b</td>
<td align="center">a+b</td>
</tr>
<tr class="even">
<td align="center">Nivel B2</td>
<td align="center">c</td>
<td align="center">d</td>
<td align="center">c+d</td>
</tr>
<tr class="odd">
<td align="center">Total</td>
<td align="center">a+c</td>
<td align="center">b+d</td>
<td align="center">n</td>
</tr>
</tbody>
</table>
<p>n=a+b+c+d</p>
<p><span class="math display">\[p=  \frac{{a+b\choose a}\,{c+d\choose
c}}{{n\choose a+c}}=
\frac{(a+b)!(c+d)!(a+c)!(b+d)!}{a!b!c!d!n!}\]</span> El test de Fisher
calcula las probabilidades de todas las posibles tablas y suma las de
aquellas tablas que tengan probabilidades menores o iguales que la tabla
observada, generando así el p-value de dos colas.</p>
<p><strong>Ejemplo</strong> Se quiere estudiar si la reacción alérgica a
un compuesto y una determinada mutación en un gen están relacionados.
Para ello se realiza un test alérgico sobre un grupo de individuos
seleccionados al azar y se genotipa el estado del gen de interés ¿Existe
un diferencia significativa en la incidencia de la mutación entre los
alérgicos y no alérgicos?</p>
<pre class="r"><code>datos &lt;- data.frame( sujeto = c(&quot;No alérgico&quot;, &quot;No alérgico&quot;, &quot;No alérgico&quot;,&quot;No alérgico&quot;,&quot;alérgico&quot;,&quot;No alérgico&quot;,&quot;No alérgico&quot;, &quot;alérgico&quot;, &quot;alérgico&quot;,&quot;No alérgico&quot;,&quot;alérgico&quot;, &quot;alérgico&quot;,&quot;alérgico&quot;, &quot;alérgico&quot;, &quot;alérgico&quot;,&quot;No alérgico&quot;, &quot;No alérgico&quot;, &quot;No alérgico&quot;,&quot;No alérgico&quot;,&quot;alérgico&quot;, &quot;alérgico&quot;,&quot;alérgico&quot;, &quot;alérgico&quot;, &quot;No alérgico&quot;,&quot;alérgico&quot;, &quot;No alérgico&quot;, &quot;No alérgico&quot;,&quot;alérgico&quot;,&quot;alérgico&quot;, &quot;alérgico&quot;),

                  
mutacion = c(FALSE,FALSE,FALSE,FALSE,TRUE,FALSE,FALSE, FALSE, TRUE,TRUE,TRUE,TRUE,TRUE,TRUE, FALSE,FALSE,TRUE,FALSE,TRUE, FALSE,TRUE,FALSE,FALSE, FALSE, TRUE, FALSE, FALSE, TRUE, FALSE, TRUE))
head(datos)</code></pre>
<pre><code>##        sujeto mutacion
## 1 No alérgico    FALSE
## 2 No alérgico    FALSE
## 3 No alérgico    FALSE
## 4 No alérgico    FALSE
## 5    alérgico     TRUE
## 6 No alérgico    FALSE</code></pre>
<p><strong>El juego de hipotesis es:</strong></p>
<p><span class="math inline">\(H_o:\)</span> La alergia es independiente
de la presencia del gen</p>
<p><span class="math inline">\(H_a:\)</span> La alergia es dependiente
de la presencia del gen</p>
<p><strong>La tabla de frecuencias es</strong></p>
<p>El test de Fisher trabaja con frecuencia de eventos, por lo tanto con
tablas de contingencia en las que se sumariza el número de eventos de
cada tipo.</p>
<pre class="r"><code>tabla &lt;- table(datos$sujeto, datos$mutacion, dnn = c(&quot;Sujeto&quot;, &quot;Estado gen&quot;))
tabla</code></pre>
<pre><code>##              Estado gen
## Sujeto        FALSE TRUE
##   alérgico        6   10
##   No alérgico    11    3</code></pre>
<pre class="r"><code>fisher.test(x = tabla, alternative = &quot;two.sided&quot;)</code></pre>
<pre><code>## 
##  Fisher&#39;s Exact Test for Count Data
## 
## data:  tabla
## p-value = 0.03293
## alternative hypothesis: true odds ratio is not equal to 1
## 95 percent confidence interval:
##  0.02195148 1.03427479
## sample estimates:
## odds ratio 
##  0.1749975</code></pre>
<p><strong>Fuerza de asociación</strong></p>
<pre class="r"><code>library(vcd)
assocstats(x = tabla)</code></pre>
<pre><code>##                     X^2 df P(&gt; X^2)
## Likelihood Ratio 5.3356  1 0.020894
## Pearson          5.1293  1 0.023525
## 
## Phi-Coefficient   : 0.413 
## Contingency Coeff.: 0.382 
## Cramer&#39;s V        : 0.413</code></pre>
<p>En este ejemplo no se satisface la condición de frecuencias
marginales fijas y por lo tanto el test de Fisher no es exacto. Aun así,
hay evidencias para rechazar la H0 y considerar que las dos variables sí
están relacionadas. El tamaño de la fuerza de asociación (tamaño de
efecto) cuantificado por phi o Cramer’s V es mediano.</p>
<pre class="r"><code>mosaicplot(tabla,
  main = &quot;Mosaic plot&quot;,
  color = TRUE
)</code></pre>
<p><img src="pruebas_no_paramétricas_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
</div>
<div id="prueba-para-la-diferencias-entre-dos-poblaciones"
class="section level1">
<h1>Prueba para la diferencias entre dos poblaciones</h1>
<div id="t-test-paramétrica-en-rstudio" class="section level2">
<h2>t-test paramétrica en Rstudio</h2>
<p>Permite contrastar la hipótesis nula de que las medias de dos
poblaciones son iguales, frente a la hipótesis alternativa de que no lo
son.</p>
<p><span class="math display">\[H_0:μ_A=μ_B\]</span> <span
class="math display">\[H_a:μ_A≠μ_B\]</span></p>
<p>Otra forma equivalente de definir estas hipótesis es:</p>
<p><span class="math display">\[H_0:μ_A−μ_B=0\]</span> <span
class="math display">\[H_a:μ_A−μ_B≠0\]</span></p>
<p><strong>Condiciones:</strong></p>
<ul>
<li><p>Las observaciones tienen que ser independientes</p></li>
<li><p>Las poblaciones que se comparan tienen que seguir una
distribución normal.</p></li>
<li><p>Igualdad de varianza (homocedasticidad)</p></li>
</ul>
<p><strong>Ejemplo</strong></p>
<p><strong>1. prueba para una muestra</strong></p>
<p>El contenido de siete contenedores similares de ácido sulfúrico son
9.8, 10.2, 10.4, 9.8, 10.0, 10.2, y 9.6 litros. Encuentre un intervalo
de confianza del 95% para la media de todos los contenedores si se
supone una distribución aproximadamente normal.</p>
<pre class="r"><code>T&lt;-c(9.8, 10.2, 10.4, 9.8, 10.0, 10.2, 9.6)
t.test(T,conf.level=0.95)</code></pre>
<pre><code>## 
##  One Sample t-test
## 
## data:  T
## t = 93.541, df = 6, p-value = 1.006e-10
## alternative hypothesis: true mean is not equal to 0
## 95 percent confidence interval:
##   9.738414 10.261586
## sample estimates:
## mean of x 
##        10</code></pre>
<p><strong>2. prueba para dos muestras</strong></p>
<p>Una operación de montaje en una fábrica manufacturera requiere
aproximadamente un período de entrenamiento de un mes para que un nuevo
operario alcance la máxima eficiencia. Se sugirió un nuevo método para
el entrenamiento y se realizó una prueba para comparar el método nuevo
con el método estándar. Se entrenaron dos grupos de 9 nuevos empleados
durante un período de un mes; un grupo utilizó el método estándar y el
otro grupo usó el método nuevo. Se midió el tiempo en minutos que
necesito cada empleado en armar cierto dispositivo al final del período
de entrenamiento; los resultados obtenidos fueron:</p>
<table>
<thead>
<tr class="header">
<th>Método estándar</th>
<th>32</th>
<th>37</th>
<th>35</th>
<th>28</th>
<th>41</th>
<th>44</th>
<th>35</th>
<th>31</th>
<th>34</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Método nuevo</td>
<td>35</td>
<td>31</td>
<td>29</td>
<td>25</td>
<td>34</td>
<td>40</td>
<td>27</td>
<td>32</td>
<td>31</td>
</tr>
</tbody>
</table>
<p>Admitiendo que el tiempo de armado utilizado en ambos métodos son
variables aleatorias independientes y distribuidas normalmente: ¿Tiene
igual varianza? compruebelo a través de un intervalo de confianza para
la razón de varianzas con un nivel de confianza del 90%</p>
<p><strong>2. prueba de igualdad de varianzas</strong></p>
<pre class="r"><code>E&lt;-c(32,37,35,28,41,44,35,31,34)
N&lt;-c(35,31,29,25,34,40,27,32,31)
var.test(E,N, alternative = c(&quot;two.sided&quot;),
         conf.level = 0.9) </code></pre>
<pre><code>## 
##  F test to compare two variances
## 
## data:  E and N
## F = 1.2205, num df = 8, denom df = 8, p-value = 0.7849
## alternative hypothesis: true ratio of variances is not equal to 1
## 90 percent confidence interval:
##  0.3550003 4.1962955
## sample estimates:
## ratio of variances 
##           1.220527</code></pre>
<pre class="r"><code>var(E)</code></pre>
<pre><code>## [1] 24.44444</code></pre>
<pre class="r"><code>var(N)</code></pre>
<pre><code>## [1] 20.02778</code></pre>
<pre class="r"><code>qf(0.05,8,8)</code></pre>
<pre><code>## [1] 0.2908582</code></pre>
<p><strong>2. prueba de diferencias de medias globales y
pareadas</strong></p>
<p>¿Se puede aceptar la hipótesis de igualdad de tiempos de armado, en
función de los datos construya un IC con un nivel de confianza del
95%?</p>
<pre class="r"><code>E&lt;-c(32,37,35,28,41,44,35,31,34)
N&lt;-c(35,31,29,25,34,40,27,32,31)
t.test (E,N,paired=T,conf.level=0.95)</code></pre>
<pre><code>## Warning in if (paired) xok &lt;- yok &lt;- complete.cases(x, y) else {: la condición
## tiene longitud &gt; 1 y sólo el primer elemento será usado</code></pre>
<pre><code>## Warning in if (paired) {: la condición tiene longitud &gt; 1 y sólo el primer
## elemento será usado</code></pre>
<pre><code>## Warning in if (paired) &quot;Paired t-test&quot; else &quot;One Sample t-test&quot;: la condición
## tiene longitud &gt; 1 y sólo el primer elemento será usado</code></pre>
<pre><code>## Warning in if (paired) &quot;mean of the differences&quot; else &quot;mean of x&quot;: la condición
## tiene longitud &gt; 1 y sólo el primer elemento será usado</code></pre>
<pre><code>## 
##  Paired t-test
## 
## data:  E and N
## t = 2.9938, df = 8, p-value = 0.01723
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  0.8423999 6.4909334
## sample estimates:
## mean of the differences 
##                3.666667</code></pre>
<pre class="r"><code> t.test (E,N,paired=F,conf.level=0.95)</code></pre>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  E and N
## t = 1.6495, df = 15.844, p-value = 0.1187
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -1.049486  8.382820
## sample estimates:
## mean of x mean of y 
##  35.22222  31.55556</code></pre>
</div>
<div id="prueba-de-mann-whitney-wilcoxon" class="section level2">
<h2>Prueba de Mann-Whitney-wilcoxon</h2>
<ul>
<li><p>Identifica diferencias entre dos poblaciones basadas en el
análisis de <strong>dos muestras independientes</strong>.</p></li>
<li><p>Se usa cuando los conjuntos de datos no cumplen los requisitos de
la prueba de t-Student y la normal, (normalidad de los datos y tamaño de
muestra mayor a 30)</p></li>
<li><p>Se conoce con otros nombres: Mann–Whitney–Wilcoxon, Wilcoxon
rank-sum test y Wilcoxon–Mann–Whitney.</p></li>
<li><p>Juego de hipótesis es:</p></li>
</ul>
<p>Ho: Las muestras provienen de la misma población.</p>
<p>H1: Las muestras provienen de poblaciones diferentes.</p>
<p>si las dos muestras comparadas proceden de la misma población, al
juntar todas las observaciones y ordenarlas de menor a mayor, cabría
esperar que las observaciones de una y otra muestra estuviesen
intercaladas aleatoriamente.</p>
<pre class="r"><code>library(ggplot2)
set.seed(567)
datos &lt;- data.frame(muestra = rep(c(&quot;A&quot;, &quot;B&quot;), each = 10),
valor = rnorm(n = 20, mean = 10, sd = 5),
cordenada_y = rep(0, 20))

ggplot(data = datos, aes(x = valor, y = cordenada_y)) +
geom_point(aes(colour = muestra), size = 3) +
ylab(&quot;&quot;) + xlab(&quot;rango&quot;) +
theme_bw() +
theme(axis.text.y = element_blank()) + 
ggtitle(&quot;Muestras procedentes de la misma población&quot;)</code></pre>
<p><img src="pruebas_no_paramétricas_files/figure-html/unnamed-chunk-23-1.png" width="672" /></p>
<p>Por lo contrario, si una de las muestras pertenece a una población
con valores mayores o menores que la otra población, al ordenar las
observaciones, estas tenderán a agruparse de modo que las de una muestra
queden por encima de las de la otra.</p>
<pre class="r"><code>set.seed(567)
datos &lt;- data.frame(muestra = rep(c(&quot;A&quot;, &quot;B&quot;), each = 10),
valor = c(rnorm(n = 10, mean = 10, sd = 5), rnorm(n = 10, mean = 20, sd = 5)),
cordenada_y = rep(0, 20))

ggplot(data = datos, aes(x = valor, y = cordenada_y)) +
geom_point(aes(colour = muestra), size = 3) +
ylab(&quot;&quot;) + xlab(&quot;rango&quot;) +
theme_bw() +
theme(axis.text.y = element_blank()) + 
ggtitle(&quot;Muestras procedentes de distintas poblaciones&quot;)</code></pre>
<p><img src="pruebas_no_paramétricas_files/figure-html/unnamed-chunk-24-1.png" width="672" /></p>
<p><strong>Ejemplo Prueba de wilcoxon en R</strong></p>
<p>Los siguientes datos corresponden a constantes de permeabilidad de la
membrana chorioamnion en humanos (una membrana placentaria) medida a las
12 y 26 semanas de edad gestacional.</p>
<ol style="list-style-type: decimal">
<li>Realice un analisis descriptivo para verificar la normalidad en los
conjuntos de datos</li>
</ol>
<pre class="r"><code>require(car)
library(nortest)

c12=c(0.80, 0.83, 1.89, 1.04, 1.45, 1.38, 1.91, 1.64, 0.73, 1.46)
c26=c(1.15, 0.88, 0.90, 0.74, 1.21)

# Para la constante a las 12 semanas

par(mfrow=c(1,4))
hist(c12, xlab = &quot;Tiempo&quot;, ylab = &quot;Frecuencia&quot;, las=1, main = &quot;&quot;, col = &quot;gray&quot;)
qqPlot(c12, col = &quot;gray&quot;, ylab=&quot;Tiempo&quot;)</code></pre>
<pre><code>## [1] 7 9</code></pre>
<pre class="r"><code>plot(density(c12), xlab = &quot;Tiempo&quot;, ylab = &quot;Densidad&quot;, las=1, main = &quot;&quot;)
boxplot(c12,c26, xlab = &quot;Tiempo&quot;, ylab = &quot;Densidad&quot;, las=1, main = &quot;&quot;)</code></pre>
<p><img src="pruebas_no_paramétricas_files/figure-html/unnamed-chunk-25-1.png" width="672" /></p>
<pre class="r"><code># Para la constante a las 26 semanas

par(mfrow=c(1,4))
hist(c26, xlab = &quot;Tiempo&quot;, ylab = &quot;Frecuencia&quot;, las=1, main = &quot;&quot;, col = &quot;gray&quot;)
qqPlot(c26, col = &quot;gray&quot;, ylab=&quot;Tiempo&quot;)</code></pre>
<pre><code>## [1] 4 5</code></pre>
<pre class="r"><code>plot(density(c26), xlab = &quot;Tiempo&quot;, ylab = &quot;Densidad&quot;, las=1, main = &quot;&quot;)
boxplot(c12,c26, xlab = &quot;Tiempo&quot;, ylab = &quot;Densidad&quot;, las=1, main = &quot;&quot;)</code></pre>
<p><img src="pruebas_no_paramétricas_files/figure-html/unnamed-chunk-25-2.png" width="672" /></p>
<ol start="2" style="list-style-type: decimal">
<li>Pruebe mediante un juego de hipotesis y mediante la prueba de
shapiro wilk, la normalidad del conjunto de datos</li>
</ol>
<pre class="r"><code>library(nortest)

##PRUEBA DE NORMALIDAD
shapiro.test(c12)</code></pre>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  c12
## W = 0.91129, p-value = 0.29</code></pre>
<pre class="r"><code>shapiro.test(c26)</code></pre>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  c26
## W = 0.91538, p-value = 0.5006</code></pre>
<ol start="3" style="list-style-type: decimal">
<li>Pruebe la igualdad entre el conjunto de datos</li>
</ol>
<pre class="r"><code>wilcox.test(x = c12, y = c26, alternative = &quot;two.sided&quot;, mu = 0,
            paired = FALSE, conf.int = 0.95) </code></pre>
<pre><code>## 
##  Wilcoxon rank sum exact test
## 
## data:  c12 and c26
## W = 35, p-value = 0.2544
## alternative hypothesis: true location shift is not equal to 0
## 95 percent confidence interval:
##  -0.15  0.76
## sample estimates:
## difference in location 
##                  0.305</code></pre>
<pre class="r"><code>#prueba para saber si provienen de la misma distribución 
ks.test(c12,c26)</code></pre>
<pre><code>## 
##  Two-sample Kolmogorov-Smirnov test
## 
## data:  c12 and c26
## D = 0.6, p-value = 0.1658
## alternative hypothesis: two-sided</code></pre>
</div>
<div id="prueba-chi-cuadrado-1" class="section level2">
<h2>Prueba chi cuadrado</h2>
<p>Retomando el ejemplo de el ph de agua potable y no potable</p>
<p><span class="math inline">\(H_0:X_{si}∼y_{no}\)</span></p>
<p><span class="math inline">\(H_1:X_{si}≁y_{no}\)</span></p>
<pre class="r"><code>chisq.test(no,si)</code></pre>
<pre><code>## Warning in chisq.test(no, si): Chi-squared approximation may be incorrect</code></pre>
<pre><code>## 
##  Pearson&#39;s Chi-squared test
## 
## data:  no and si
## X-squared = 6298.3, df = 6318, p-value = 0.5672</code></pre>
<p><strong>Ejemplo en R</strong></p>
<p>Se mide las concentraciones de cortisol en dos grupos de mujeres
antes de dar a luz. Al grupo 1 se le practicó una cesárea de urgencias
después de inducido el parto. Las del grupo 2, dieron a luz mediante
operación cesárea o vía vaginal después de presentarse el trabajo de
parto expontáneamente.</p>
<ol style="list-style-type: decimal">
<li>Realice un analisis grafico para detectar si hay normalidad</li>
</ol>
<p>2.Verifique normalidad en los conjuntos de datos usando α = 0.05.</p>
<p>4.Compruebe que ambos grupos de datos provienen de la misma
distribución de probabilidad</p>
<p><span class="math display">\[H_0:grupo1∼grupo2\]</span></p>
<p><span class="math display">\[H_1:grupo1≁grupo2\]</span></p>
<pre class="r"><code>###Ingresamos los datos como vectores de los dos grupos de madres

grupo1=c(411,466,432,409,381,363,449,483,438,381)
grupo2=c(584,553,516,688,650,590,574,700,831,688,478,689)         

boxplot(grupo1,grupo2)</code></pre>
<p><img src="pruebas_no_paramétricas_files/figure-html/unnamed-chunk-29-1.png" width="672" /></p>
<pre class="r"><code>## Prueba de normalidad
shapiro.test(grupo1)</code></pre>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  grupo1
## W = 0.96658, p-value = 0.8575</code></pre>
<pre class="r"><code>shapiro.test(grupo2)</code></pre>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  grupo2
## W = 0.95245, p-value = 0.673</code></pre>
<pre class="r"><code>#prueba para saber si provienen de la misma distribución 
ks.test(grupo1,grupo2)</code></pre>
<pre><code>## Warning in ks.test(grupo1, grupo2): cannot compute exact p-value with ties</code></pre>
<pre><code>## 
##  Two-sample Kolmogorov-Smirnov test
## 
## data:  grupo1 and grupo2
## D = 0.91667, p-value = 0.0002089
## alternative hypothesis: two-sided</code></pre>
<pre class="r"><code>## Prueba de igualdad entre varinzas
var.test(grupo1,grupo2)</code></pre>
<pre><code>## 
##  F test to compare two variances
## 
## data:  grupo1 and grupo2
## F = 0.16182, num df = 9, denom df = 11, p-value = 0.0108
## alternative hypothesis: true ratio of variances is not equal to 1
## 95 percent confidence interval:
##  0.04510143 0.63304938
## sample estimates:
## ratio of variances 
##          0.1618194</code></pre>
<pre class="r"><code>## prueba de diferencias entre medias
t.test (grupo1,grupo2,paired=FALSE,conf.level=0.95)</code></pre>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  grupo1 and grupo2
## t = -6.7277, df = 14.996, p-value = 6.787e-06
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -272.7363 -141.4970
## sample estimates:
## mean of x mean of y 
##  421.3000  628.4167</code></pre>
</div>
</div>
<div id="conclusiones" class="section level1">
<h1>Conclusiones</h1>
<ul>
<li>La prueba chi cuadrado tiene 3 diferentes aplicaciones, entre ellos
se encuentran la Prueba de independencia, Prueba de bondad de ajuste y
de Comparación de distribuciones**</li>
</ul>
<div id="ejercicios-propuestos" class="section level2">
<h2>Ejercicios propuestos</h2>
<ol style="list-style-type: decimal">
<li></li>
</ol>
</div>
</div>

<br>
<hr>
<p><center>Copyright &copy; 2019, webpage made with Rmarkdown.</center></p>
<hr>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3,h4,h5",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = false;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
