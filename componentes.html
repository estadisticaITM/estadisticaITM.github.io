<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>COMPONENTES PRINCIPALES</title>

<script src="site_libs/header-attrs-2.14/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/flatly.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />
<link href="site_libs/ionicons-2.0.1/css/ionicons.min.css" rel="stylesheet" />
<link rel="icon" type="image/png" href="images/favicon.png" />

<script type="text/javascript" src="js/rmarkdown.js"></script>

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-88209726-1', 'auto');
  ga('send', 'pageview');
</script>


<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Estadística ITM</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="pagin1.html">
    <span class="fa fa-line-chart"></span>
     
    Est Básica
  </a>
</li>
<li>
  <a href="inf.html">
    <span class="fa fa-bar-chart-o"></span>
     
    Est inferencial
  </a>
</li>
<li>
  <a href="pagin2.html">
    <span class="fa fa-bar-chart-o"></span>
     
    Diseño de experimentos
  </a>
</li>
<li>
  <a href="pagin3.html">
    <span class="fa fa-pie-chart"></span>
     
    Análisis multivariado
  </a>
</li>
<li>
  <a href="about.html">
    <span class="fa fa-puzzle-piece"></span>
     
    Semillero de R
  </a>
</li>
<li>
  <a href="https://www.itm.edu.co">
    <span class="ion ion-university"></span>
     
  </a>
</li>
<li>
  <a href="https://github.com/estadisticaITM">
    <span class="fa fa-github"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">COMPONENTES PRINCIPALES</h1>

</div>


<ul>
<li><p>Un problema central en el análisis de datos multivariantes es la
reducción de la dimensionalidad</p></li>
<li><p>Es posible describir con precisión los valores de p variables por
un pequeño subconjunto r &lt; p de ellas, reduciendo la dimensión del
problema a costa de una pequeña pérdida de información.</p></li>
<li><p>Objetivo: dadas n observaciones de p variables, se analiza si es
posible representar adecuadamente esta información con un número menor
de variables construidas como combinaciones lineales de las
originales.</p></li>
</ul>
<p>Por ejemplo, con variables con alta dependencia es frecuente que un
pequeño número de nuevas variables (menos del 20% de las originales )
expliquen la mayor parte (más del 80%) de la variabilidad original.</p>
<p>Su utilidad es doble:</p>
<ol style="list-style-type: decimal">
<li><p>Permite representar óptimamente en un espacio de dimensión
pequeña, observaciones de un espacio general p-dimensional. Es el primer
paso para identificar posibles variables <strong>latentes</strong> o no
observadas, que están generando la variabilidad de los datos.</p></li>
<li><p>Permite transformar las variables originales correlacionadas, en
nuevas variables incorrelacionadas, facilitando la interpretación de los
datos.</p></li>
</ol>
<p>La primera componente tiene la mayor varianza posible para una
combinación lineal de las variables originales, la segunda componente
tiene la segunda mayor varianza posible para una combinación lineal pero
ortogonal a la primera componente, etc.</p>
<p>Antes de realizar un ACP se debe tomar la desición si trabajar con
los datos originales o se se debe estandarizar cada variable a una media
de cero y varianza unidad. Si las variables no se estandarizan y una
variable tiene una varianza mas grande, entonces esta variable
controlará la primera componente principal. la estandarización hace que
todas las variables tengan el mismo peso. La fórmula para realizar la
estandarización es</p>
<p><span class="math display">\[\Large X_i=\frac{x_i-\bar
x}{\sigma}\]</span></p>
<p>Donde:</p>
<ul>
<li><p><span class="math inline">\(\large X_i\)</span> es cada
observación</p></li>
<li><p><span class="math inline">\(\Large \bar x\)</span> es la media
del vector</p></li>
<li><p><span class="math inline">\(\Large \sigma\)</span> es la
desviación estándar del conjunto de datos</p></li>
</ul>
<p>sea x un vector aleatorio con k componentes <span
class="math inline">\(\Large E(x)=\mu\)</span> y <span
class="math inline">\(\large var-cov(x)=D(x)=\sum _x&gt;0\)</span>.</p>
<p>Hay un famoso teorema en álgebra lineal que nos permite factorizar
matrices simétricas, digamos <span
class="math inline">\(\sum\)</span>como:</p>
<p><span class="math display">\[\large \sum=\Gamma \Lambda
\Gamma&#39;  \]</span></p>
<p>Donde <span class="math inline">\(\Large \Lambda\)</span> es una
matriz diagonal con las raíces propias de <span
class="math inline">\(\Large \sum\)</span> y <span
class="math inline">\(\Large
\Gamma=[\gamma_1,\gamma_2,...,\gamma_k]\)</span> que contiene los
vectores propios de <span class="math inline">\(\Large \sum\)</span></p>
<p><span class="math display">\[\large \Lambda=
\left[ \begin{array}{cccc}
\lambda_1 &amp; 0  &amp; \cdots &amp; 0\\
0 &amp; \lambda_2  &amp; \cdots &amp; 0 \\
\vdots &amp; \vdots&amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; \lambda_k
\end{array}\right]\]</span></p>
<p>Donde <span class="math inline">\(\Large \lambda_1\geq \lambda_2
\geq\cdots \geq \lambda_k\)</span></p>
<p>Consideremos la transformación lineal:</p>
<p><span class="math display">\[\Large y=\Gamma (x-\mu)\]</span> La idea
es encontrar <span class="math inline">\(\Large y_k\)</span> componentes
principales que sean combinaciones lineales de las <span
class="math inline">\(\Large x_i\)</span> variables originales que
describen cada muestra, es decir:</p>
<p><span class="math display">\[\Large
y_1=\gamma_{11}x_1+\gamma_{12}x_2+\cdots+\gamma_{1k}x_k\]</span></p>
<p><span class="math display">\[\Large
y_2=\gamma_{21}x_1+\gamma_{22}x_2+\cdots+\gamma_{2k}x_k\]</span> <span
class="math display">\[\Large
y_k=\gamma_{k1}x_1+\gamma_{k2}x_2+\cdots+\gamma_{kk}x_k\]</span></p>
<p>Se define</p>
<p><span class="math display">\[ \Large y=\left
[\begin{array}{l}
y_1 \\
y_2\\
\vdots\\
y_k
\end{array}\right]=A&#39;(x-\mu)\]</span></p>
<p><span class="math display">\[\Large z_i=\frac{y_i}{\sqrt
\lambda_i}\]</span> con <span class="math inline">\(i=1,...k\)</span>
estas variables serán llamadas las componentes principales
estandarizadas de x. La varianza de <span
class="math inline">\(y_i\)</span> sería</p>
<p><span class="math display">\[\large var(y_i)=\gamma_i&#39;\sum
\gamma_i=\lambda_i\]</span> La covarianza de las variables sería:</p>
<p><span class="math display">\[\large cov(y_i,y_j)=\gamma_i&#39;\sum
\gamma_j=0\]</span></p>
<div id="cuántas-componentes-conservamos" class="section level2">
<h2><strong>¿Cuántas componentes conservamos?</strong></h2>
<p>Se recomienda tomar varios aspectos en cuenta:</p>
<ul>
<li><p>Objetivo de la reducción de dimensionalidad.</p></li>
<li><p>Si por ejemplo, pretendemos construir un indicador, obviamente el
número a retener es solo de una componente.</p></li>
<li><p>Si no es claro, entonces consideramos las primera j componentes
que posean el 80% de la variabilidad total.</p></li>
</ul>
</div>
<div id="videos" class="section level2">
<h2>Videos</h2>
<div id="explicación-de-componentes-principales-en-5-minutos"
class="section level3">
<h3>Explicación de componentes principales en 5 minutos</h3>
<iframe width="280" height="158" src="https://www.youtube.com/embed/HMOI_lkzW08" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
</iframe>
</div>
<div id="video-completo-de-componentes-principales"
class="section level3">
<h3>Video completo de componentes principales</h3>
<iframe width="280" height="158" src="https://www.youtube.com/embed/FgakZw6K1QQ" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
</iframe>
</div>
</div>
<div id="ejemplo" class="section level2">
<h2><strong>EJEMPLO</strong></h2>
<p>La siguiente base de datos proporciona las intensidades relativas de
emisión de fluoresencia a cuatro longitudes de ondas diferentes
(300,350,400,450) para 12 compuestos.</p>
<ol style="list-style-type: decimal">
<li>Realizar un análisis descriptivo y de conglomerados para detectar
posibles correlaciones.</li>
</ol>
<pre class="r"><code>compuesto=as.factor(letters[1:12])
tress=c(16,15,14,15,14,14,17,16,15,17,18,18)
tress50=c(62,60,59,61,60,59,63,62,60,63,62,64)
cuat=c(67,69,68,71,70,69,68,69,72,69,68,67)
cuat50=c(27,31,31,31,30,30,29,28,30,27,28,29)

y=data.frame(tress,tress50,cuat,cuat50)

y</code></pre>
<pre><code>##    tress tress50 cuat cuat50
## 1     16      62   67     27
## 2     15      60   69     31
## 3     14      59   68     31
## 4     15      61   71     31
## 5     14      60   70     30
## 6     14      59   69     30
## 7     17      63   68     29
## 8     16      62   69     28
## 9     15      60   72     30
## 10    17      63   69     27
## 11    18      62   68     28
## 12    18      64   67     29</code></pre>
<pre class="r"><code>cor(y)</code></pre>
<pre><code>##              tress    tress50       cuat     cuat50
## tress    1.0000000  0.9138115 -0.4983509 -0.6701031
## tress50  0.9138115  1.0000000 -0.4644110 -0.6922815
## cuat    -0.4983509 -0.4644110  1.0000000  0.4576692
## cuat50  -0.6701031 -0.6922815  0.4576692  1.0000000</code></pre>
<pre class="r"><code>plot(y)</code></pre>
<p><img src="componentes_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<pre class="r"><code>##conglomerados

y=data.frame(compuesto,tress,tress50,cuat,cuat50)
#matriz de dist
dist(y,method = &quot;euclidean&quot;)</code></pre>
<pre><code>## Warning in dist(y, method = &quot;euclidean&quot;): NAs introduced by coercion</code></pre>
<pre><code>##           1        2        3        4        5        6        7        8        9
## 2  5.590170                                                                        
## 3  6.123724 1.936492                                                               
## 4  6.519202 2.500000 4.183300                                                      
## 5  5.700877 1.936492 2.738613 2.236068                                             
## 6  5.700877 1.936492 1.581139 3.535534 1.581139                                    
## 7  2.958040 4.743416 6.020797 5.123475 5.361903 5.809475                           
## 8  2.500000 4.183300 5.361903 4.330127 4.031129 4.609772 2.236068                  
## 9  6.982120 3.535534 4.873397 1.936492 2.500000 3.708099 6.123724 4.743416         
## 10 2.738613 6.020797 7.245688 5.916080 5.916080 6.519202 2.500000 1.936492 6.224950
## 11 2.738613 5.361903 6.519202 5.916080 5.916080 6.123724 1.936492 2.500000 6.422616
## 12 3.872983 6.422616 7.582875 6.892024 7.245688 7.582875 1.936492 4.031129 7.984360
##          10       11
## 2                   
## 3                   
## 4                   
## 5                   
## 6                   
## 7                   
## 8                   
## 9                   
## 10                  
## 11 2.236068         
## 12 3.535534 2.738613</code></pre>
<pre class="r"><code>hc &lt;- hclust(dist(y), &quot;ave&quot;)</code></pre>
<pre><code>## Warning in dist(y): NAs introduced by coercion</code></pre>
<pre class="r"><code>dend1 &lt;- as.dendrogram(hc)

op &lt;- par(mfrow= c(2,2), mar = c(3,3,1,1))

plot(dend1)

plot(dend1, nodePar=list(pch = c(1,NA),cex=0.8),type = &quot;t&quot;, center=TRUE)

plot(dend1, edgePar=list(col = 1:2, lty = 2:3),edge.root = TRUE)

plot(dend1, nodePar=list(pch = 2:1,cex=.4*2:1,col = 2:3), horiz = TRUE)</code></pre>
<p><img src="componentes_files/figure-html/unnamed-chunk-1-2.png" width="672" /></p>
<ol start="2" style="list-style-type: decimal">
<li><strong>Modelo de componentes principales</strong></li>
</ol>
<ul>
<li><p>Para este ejemplo habrá cuatro componentes principales <span
class="math inline">\(Z_1, Z_2, Z_3, Z_4\)</span>, cada una de las
cuales será una combinación lineal de <span
class="math inline">\(X_1,X_2,X_3, X_4\)</span> las intensidades de
fluorescencia a las longitudes de onda proporcionadas.</p></li>
<li><p>Los coeficientes de las ecuaciones de componentes principales
están determinadas de manera que las nuevas variables, a diferencia de
las variables originales no se encuentren correlacionadas unas con
otras.</p></li>
<li><p>La generación de un nuevo conjunto de variables parece tener poco
sentido porque se generan otras 4 variables nuevas, en lugar de las 4
variables originales.</p></li>
<li><p>Las componentes principales también se eligen de manera que la
primera componente principal <span
class="math inline">\(Z_1\)</span>recoge la mayor parte de variación que
hay en el conjunto de datos, la segunda recoje la siguiente mayor parte
de la variación y así sucesivamente.</p></li>
<li><p>Por consiguiente, cuando haya correlación significativa el numero
de componentes útiles será mucho menor que el número de variables
originales</p></li>
</ul>
<pre class="r"><code>compuesto=as.factor(letters[1:12])
tress=c(16,15,14,15,14,14,17,16,15,17,18,18)
tress50=c(62,60,59,61,60,59,63,62,60,63,62,64)
cuat=c(67,69,68,71,70,69,68,69,72,69,68,67)
cuat50=c(27,31,31,31,30,30,29,28,30,27,28,29)

y=data.frame(tress,tress50,cuat,cuat50)

##Componentes principales

y=data.frame(scale(tress),scale(tress50),scale(cuat),scale(cuat50))
modelo&lt;-princomp(y)
summary(modelo)</code></pre>
<pre><code>## Importance of components:
##                           Comp.1    Comp.2     Comp.3     Comp.4
## Standard deviation     1.6250008 0.7690778 0.59767468 0.27810657
## Proportion of Variance 0.7201712 0.1613129 0.09742228 0.02109362
## Cumulative Proportion  0.7201712 0.8814841 0.97890638 1.00000000</code></pre>
<pre class="r"><code>modelo</code></pre>
<pre><code>## Call:
## princomp(x = y)
## 
## Standard deviations:
##    Comp.1    Comp.2    Comp.3    Comp.4 
## 1.6250008 0.7690778 0.5976747 0.2781066 
## 
##  4  variables and  12 observations.</code></pre>
<pre class="r"><code>modelo$loadings</code></pre>
<pre><code>## 
## Loadings:
##                Comp.1 Comp.2 Comp.3 Comp.4
## scale.tress.    0.547  0.238  0.395  0.699
## scale.tress50.  0.546  0.299  0.324 -0.712
## scale.cuat.    -0.400  0.913              
## scale.cuat50.  -0.493 -0.145  0.856       
## 
##                Comp.1 Comp.2 Comp.3 Comp.4
## SS loadings      1.00   1.00   1.00   1.00
## Proportion Var   0.25   0.25   0.25   0.25
## Cumulative Var   0.25   0.50   0.75   1.00</code></pre>
<pre class="r"><code>modelo$scores</code></pre>
<pre><code>##           Comp.1      Comp.2     Comp.3      Comp.4
##  [1,]  1.5952249 -0.76674361 -0.9919303 -0.18579179
##  [2,] -1.2910394 -0.46621077  0.5611308  0.12874234
##  [3,] -1.7229810 -1.41291035  0.1476040  0.05875581
##  [4,] -1.4929986  0.92687704  0.6602714 -0.24302724
##  [5,] -1.5928482  0.07815250 -0.3300050 -0.28009161
##  [6,] -1.6564717 -0.70849123 -0.4773996  0.12056591
##  [7,]  1.3629824 -0.01599411  0.5750957 -0.18164957
##  [8,]  0.7319674  0.34816951 -0.5116887 -0.16093806
##  [9,] -1.7556955  1.45109652 -0.1603809  0.24832833
## [10,]  1.7615838  0.78640005 -0.6266575 -0.08691731
## [11,]  1.7341863  0.06183714  0.0688296  0.75146211
## [12,]  2.3260895 -0.28218269  1.0851305 -0.16943893</code></pre>
<pre class="r"><code>screeplot(modelo)
plot(modelo)</code></pre>
<p><img src="componentes_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<pre class="r"><code>plot(modelo$scores[,1],modelo$scores[,2])
abline(h=0)
abline(v=0)</code></pre>
<p><img src="componentes_files/figure-html/unnamed-chunk-2-2.png" width="672" /></p>
<pre class="r"><code>##
par(mfrow=c(1,1))
biplot(modelo,col=c(2,4))</code></pre>
<p><img src="componentes_files/figure-html/unnamed-chunk-2-3.png" width="672" /></p>
<p>Siendo así las cuatro componentes principales corresponden a:</p>
<p><span class="math inline">\(\Large
Z_1=0.547X_1+0.546X_2-0.4X_3-0.493X_4\)</span> explicando el 72.01% de
la varianza</p>
<p><span class="math inline">\(\Large
Z_2=0.238X_1+0.3X_2-0.913X_3-0.145X_4\)</span> explicando el 16.13% de
la varianza</p>
<p><span class="math inline">\(\Large
Z_3=0.395X_1+0.324X_2+0.856X_4\)</span> explicando el 9.74% de la
varianza</p>
<p><span class="math inline">\(\Large Z_4=0.7X_1-0.712X_2\)</span>
explicando el 2.1% de la varianza</p>
<p>Donde <span class="math inline">\(X_1, X_2, X_3, X_4\)</span>
corresponden a las intensidades relativas estandarizadas a 300,350, 400
y 450 nm</p>
</div>
<div id="interpretación-de-los-componentes" class="section level2">
<h2><strong>INTERPRETACIÓN DE LOS COMPONENTES</strong></h2>
<div id="componentes-de-tamaño-y-forma" class="section level3">
<h3>Componentes de tamaño y forma</h3>
<ul>
<li><p>Cuando existe una alta correlación positiva entre todas las
variables, el primer componente principal tiene todas sus coordenadas
del mismo signo y puede interpretarse como un promedio ponderado de
todas las variables, interpretadóse como un <strong>factor global de
tamaño</strong>.</p></li>
<li><p>Los restantes componentes se interpretan como <strong>factores de
forma</strong> y con coordenadas positivas y negativas, que implica que
contraponen unos grupos de variables frente a otros.</p></li>
<li><p>Se debe observar en cada componente cual tiene mayor
valor</p></li>
<li><p>Las coordenadas de una componente principal pueden agruparse
según el signo, pueden omitirse aquellas que presentan valores por
debajo de 0.1</p></li>
<li><p>** ¿Cuántas componentes elegir?** Seleccionar componentes hasta
cubrir una proporción determinada de varianza, como el 80% o el 90%.
Esta regla es arbitraria y debe aplicarse con cierto cuidado. Es posible
que un único componente de tamaño recoja el 90% de la variabilidad y sin
embargo pueden existir otros componentes que sean muy adecuados para
explicar la forma de las variables.</p></li>
<li><p>Es importante recordar que las covarianzas (o correlaciones)
miden únicamente las relaciones lineales entre las variables. Cuando
entre ellas existan relaciones fuertes no lineales el análisis de
componentes principales puede dar una información muy parcial de las
variables.</p></li>
</ul>
</div>
</div>
<div id="otro-ejemplo" class="section level2">
<h2><strong>Otro ejemplo</strong></h2>
<p>Se realizar un análisis de componentes principales sobre los
resultados obtenidos en la competición de heptatlon femenino en los
juegos de seul 1988, estos datos se encuentran en el paquete HSAUR2, y
corresponden a los datos de 25 atletas sobre 8 variables.</p>
<ul>
<li>100 m vallas (hurdles)</li>
<li>Salto de altura (highjump)</li>
<li>Lanzamiento de peso (shot)</li>
<li>200 m lisos (run200m)</li>
<li>Salto de longitud (longjump)</li>
<li>Lanzamiento de javalina (javelin)</li>
<li>800m (run800m)</li>
<li>puntaje (score)</li>
</ul>
<ol style="list-style-type: decimal">
<li><p>Instalar el paquete HSAUR2</p></li>
<li><p>Obtener los datos</p></li>
</ol>
<pre class="r"><code>library(&quot;HSAUR2&quot;)</code></pre>
<pre><code>## Loading required package: tools</code></pre>
<pre class="r"><code>data.frame= heptathlon</code></pre>
<ol start="3" style="list-style-type: decimal">
<li>recodificamos las pruebas relativas a las 3 carreras, vallas, 200m y
800m, restando el mayor valor en cada carrera, cada uno de los tiempos
de los 35 atletas</li>
</ol>
<pre class="r"><code>heptathlon$hurdles=max(heptathlon$hurdles)-heptathlon$hurdles
heptathlon$run200m=max(heptathlon$run200m)-heptathlon$run200m
heptathlon$run800m=max(heptathlon$run800m)-heptathlon$run800m</code></pre>
<ol start="4" style="list-style-type: decimal">
<li>Realizar un diagrama de dispersión y calcular la matriz de
correlaciones</li>
</ol>
<pre class="r"><code>plot(heptathlon[,-8])</code></pre>
<p><img src="componentes_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<pre class="r"><code>round(cor(heptathlon[,-8]),2)</code></pre>
<pre><code>##          hurdles highjump shot run200m longjump javelin run800m
## hurdles     1.00     0.81 0.65    0.77     0.91    0.01    0.78
## highjump    0.81     1.00 0.44    0.49     0.78    0.00    0.59
## shot        0.65     0.44 1.00    0.68     0.74    0.27    0.42
## run200m     0.77     0.49 0.68    1.00     0.82    0.33    0.62
## longjump    0.91     0.78 0.74    0.82     1.00    0.07    0.70
## javelin     0.01     0.00 0.27    0.33     0.07    1.00   -0.02
## run800m     0.78     0.59 0.42    0.62     0.70   -0.02    1.00</code></pre>
<ul>
<li>¿Qué observa?</li>
<li>¿Entre que variables existe una correlación alta?</li>
<li>¿Entre que variables existe una corelación débil?</li>
</ul>
<ol start="5" style="list-style-type: decimal">
<li>Realicemos un análisis boxplot</li>
</ol>
<pre class="r"><code>boxplot(heptathlon[,-8])</code></pre>
<p><img src="componentes_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<pre class="r"><code>boxplot(heptathlon$score)</code></pre>
<p><img src="componentes_files/figure-html/unnamed-chunk-6-2.png" width="672" /></p>
<ul>
<li>¿Observa la existencia de puntos atípicos?</li>
<li>De encontrar puntos atípicos que propone para solucionarlo?</li>
<li>A que participante pertenece la observación atípica, porque tiene
ese valor tan pequeño?</li>
</ul>
<ol start="6" style="list-style-type: decimal">
<li>Vuelva a estimar la matriz de correlaciones, sin el punto
atípico</li>
</ol>
<pre class="r"><code>hep=heptathlon[-grep(&quot;PNG&quot;,rownames(heptathlon)),]
hep</code></pre>
<pre><code>##                     hurdles highjump  shot run200m longjump javelin run800m score
## Joyner-Kersee (USA)    3.73     1.86 15.80    4.05     7.27   45.66   34.92  7291
## John (GDR)             3.57     1.80 16.23    2.96     6.71   42.56   37.31  6897
## Behmer (GDR)           3.22     1.83 14.20    3.51     6.68   44.54   39.23  6858
## Sablovskaite (URS)     2.81     1.80 15.23    2.69     6.25   42.78   31.19  6540
## Choubenkova (URS)      2.91     1.74 14.76    2.68     6.32   47.46   35.53  6540
## Schulz (GDR)           2.67     1.83 13.50    1.96     6.33   42.82   37.64  6411
## Fleming (AUS)          3.04     1.80 12.88    3.02     6.37   40.28   30.89  6351
## Greiner (USA)          2.87     1.80 14.13    2.13     6.47   38.00   29.78  6297
## Lajbnerova (CZE)       2.79     1.83 14.28    1.75     6.11   42.20   27.38  6252
## Bouraga (URS)          3.17     1.77 12.62    3.02     6.28   39.06   28.69  6252
## Wijnsma (HOL)          2.67     1.86 13.01    1.58     6.34   37.86   31.94  6205
## Dimitrova (BUL)        3.18     1.80 12.88    3.02     6.37   40.28   30.89  6171
## Scheider (SWI)         2.57     1.86 11.58    1.74     6.05   47.50   28.50  6137
## Braun (FRG)            2.71     1.83 13.16    1.83     6.12   44.58   20.61  6109
## Ruotsalainen (FIN)     2.63     1.80 12.32    2.00     6.08   45.44   26.37  6101
## Yuping (CHN)           2.49     1.86 14.21    1.61     6.40   38.60   16.76  6087
## Hagger (GB)            2.95     1.80 12.75    1.14     6.34   35.76   24.95  5975
## Brown (USA)            2.35     1.83 12.69    1.78     6.13   44.34   17.00  5972
## Mulliner (GB)          2.03     1.71 12.68    1.69     6.10   37.76   25.41  5746
## Hautenauve (BEL)       2.38     1.77 11.81    1.00     5.99   35.68   29.53  5734
## Kytola (FIN)           2.11     1.77 11.66    0.92     5.75   39.48   30.08  5686
## Geremias (BRA)         2.19     1.71 12.95    1.11     5.50   39.64   19.41  5508
## Hui-Ing (TAI)          1.57     1.68 10.00    1.38     5.47   39.14   26.13  5290
## Jeong-Mi (KOR)         1.89     1.71 10.83    0.00     5.50   39.26   24.26  5289</code></pre>
<pre class="r"><code>plot(hep)</code></pre>
<p><img src="componentes_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<pre class="r"><code>round(cor(heptathlon[,-8]),2)</code></pre>
<pre><code>##          hurdles highjump shot run200m longjump javelin run800m
## hurdles     1.00     0.81 0.65    0.77     0.91    0.01    0.78
## highjump    0.81     1.00 0.44    0.49     0.78    0.00    0.59
## shot        0.65     0.44 1.00    0.68     0.74    0.27    0.42
## run200m     0.77     0.49 0.68    1.00     0.82    0.33    0.62
## longjump    0.91     0.78 0.74    0.82     1.00    0.07    0.70
## javelin     0.01     0.00 0.27    0.33     0.07    1.00   -0.02
## run800m     0.78     0.59 0.42    0.62     0.70   -0.02    1.00</code></pre>
<ul>
<li>¿Qué observa en cuanto a los valores de las correlaciones?</li>
</ul>
<ol start="7" style="list-style-type: decimal">
<li>Al estar los resultados de las 7 pruebas en diversas
escalas(metros,segundos), se deben normalizar las variables.</li>
</ol>
<pre class="r"><code>hep1=scale(hep)

hep1</code></pre>
<pre><code>##                         hurdles   highjump        shot     run200m   longjump    javelin
## Joyner-Kersee (USA)  2.02598714  1.2662190  1.75444462  2.16301826  2.6504631  1.2631989
## John (GDR)           1.71504427  0.1194546  2.04165699  0.99944520  1.2562469  0.3694941
## Behmer (GDR)         1.03485674  0.6928368  0.68574739  1.58656922  1.1815567  0.9403120
## Sablovskaite (URS)   0.23806563  0.1194546  1.37372123  0.71122069  0.1109979  0.4329183
## Choubenkova (URS)    0.43240493 -1.0273097  1.05979142  0.70054570  0.2852749  1.7821242
## Schulz (GDR)        -0.03400938  0.6928368  0.21819235 -0.06805301  0.3101716  0.4444500
## Fleming (AUS)        0.68504601  0.1194546 -0.19592783  1.06349510  0.4097585 -0.2878114
## Greiner (USA)        0.35466921  0.1194546  0.63899188  0.11342169  0.6587257 -0.9451168
## Lajbnerova (CZE)     0.19919778  0.6928368  0.73918225 -0.29222764 -0.2375562  0.2657090
## Bouraga (URS)        0.93768709 -0.4539276 -0.36959112  1.06349510  0.1856880 -0.6395275
## Wijnsma (HOL)       -0.03400938  1.2662190 -0.10909618 -0.47370233  0.3350683 -0.9854777
## Dimitrova (BUL)      0.95712102  0.1194546 -0.19592783  1.06349510  0.4097585 -0.2878114
## Scheider (SWI)      -0.22834867  1.2662190 -1.06424432 -0.30290262 -0.3869365  1.7936559
## Braun (FRG)          0.04372634  0.6928368 -0.00890581 -0.20682778 -0.2126595  0.9518437
## Ruotsalainen (FIN)  -0.11174509  0.1194546 -0.56997185 -0.02535308 -0.3122463  1.1997747
## Yuping (CHN)        -0.38382011  1.2662190  0.69242675 -0.44167739  0.4844486 -0.7721417
## Hagger (GB)          0.51014065  0.1194546 -0.28275947 -0.94340155  0.3350683 -1.5908906
## Brown (USA)         -0.65589512  0.6928368 -0.32283562 -0.26020269 -0.1877627  0.8826536
## Mulliner (GB)       -1.27778086 -1.6006919 -0.32951498 -0.35627753 -0.2624529 -1.0143069
## Hautenauve (BEL)    -0.59759333 -0.4539276 -0.91061910 -1.09285130 -0.5363168 -1.6139540
## Kytola (FIN)        -1.12230942 -0.4539276 -1.01080946 -1.17825116 -1.1338380 -0.5184449
## Geremias (BRA)      -0.96683799 -1.6006919 -0.14917232 -0.97542649 -1.7562559 -0.4723182
## Hui-Ing (TAI)       -2.17174161 -2.1740741 -2.11958283 -0.68720198 -1.8309461 -0.6164641
## Jeong-Mi (KOR)      -1.54985587 -1.6006919 -1.56519615 -2.16034951 -1.7562559 -0.5818691
##                         run800m       score
## Joyner-Kersee (USA)  1.04165853  2.36063285
## John (GDR)           1.43045040  1.54252238
## Behmer (GDR)         1.74278528  1.46154190
## Sablovskaite (URS)   0.43488295  0.80123954
## Choubenkova (URS)    1.14088993  0.80123954
## Schulz (GDR)         1.48413295  0.53338103
## Fleming (AUS)        0.38608062  0.40879568
## Greiner (USA)        0.20551202  0.29666887
## Lajbnerova (CZE)    -0.18490659  0.20322985
## Bouraga (URS)        0.02819690  0.20322985
## Wijnsma (HOL)        0.55688876  0.10563800
## Dimitrova (BUL)      0.38608062  0.03503963
## Scheider (SWI)      -0.00271124 -0.03555874
## Braun (FRG)         -1.28621241 -0.09369857
## Ruotsalainen (FIN)  -0.34920775 -0.11030995
## Yuping (CHN)        -1.91250893 -0.13937986
## Hagger (GB)         -0.58020543 -0.37193918
## Brown (USA)         -1.87346706 -0.37816845
## Mulliner (GB)       -0.50537520 -0.84743994
## Hautenauve (BEL)     0.16484341 -0.87235701
## Kytola (FIN)         0.25431434 -0.97202529
## Geremias (BRA)      -1.48142171 -1.34162850
## Hui-Ing (TAI)       -0.38824961 -1.79428861
## Jeong-Mi (KOR)      -0.69245078 -1.79636503
## attr(,&quot;scaled:center&quot;)
##     hurdles    highjump        shot     run200m    longjump     javelin     run800m 
##    2.687500    1.793750   13.173333    2.023750    6.205417   41.278333   28.516667 
##       score 
## 6154.125000 
## attr(,&quot;scaled:scale&quot;)
##      hurdles     highjump         shot      run200m     longjump      javelin 
##   0.51456398   0.05232112   1.49714995   0.93676972   0.40165938   3.46870690 
##      run800m        score 
##   6.14724800 481.59755096</code></pre>
<ol start="8" style="list-style-type: decimal">
<li>Con los datos normalizados podemos realizar un análisis cluster</li>
</ol>
<pre class="r"><code>hep1=scale(hep)
hc &lt;- hclust(dist(hep1[,-8]), &quot;ave&quot;)

dend1 &lt;- as.dendrogram(hc)

plot(dend1)</code></pre>
<p><img src="componentes_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<ol start="9" style="list-style-type: decimal">
<li>Análisis de componentes principales</li>
</ol>
<pre class="r"><code>library(&quot;HSAUR2&quot;)


hep=heptathlon[-grep(&quot;PNG&quot;,rownames(heptathlon)),]
hep</code></pre>
<pre><code>##                     hurdles highjump  shot run200m longjump javelin run800m score
## Joyner-Kersee (USA)    3.73     1.86 15.80    4.05     7.27   45.66   34.92  7291
## John (GDR)             3.57     1.80 16.23    2.96     6.71   42.56   37.31  6897
## Behmer (GDR)           3.22     1.83 14.20    3.51     6.68   44.54   39.23  6858
## Sablovskaite (URS)     2.81     1.80 15.23    2.69     6.25   42.78   31.19  6540
## Choubenkova (URS)      2.91     1.74 14.76    2.68     6.32   47.46   35.53  6540
## Schulz (GDR)           2.67     1.83 13.50    1.96     6.33   42.82   37.64  6411
## Fleming (AUS)          3.04     1.80 12.88    3.02     6.37   40.28   30.89  6351
## Greiner (USA)          2.87     1.80 14.13    2.13     6.47   38.00   29.78  6297
## Lajbnerova (CZE)       2.79     1.83 14.28    1.75     6.11   42.20   27.38  6252
## Bouraga (URS)          3.17     1.77 12.62    3.02     6.28   39.06   28.69  6252
## Wijnsma (HOL)          2.67     1.86 13.01    1.58     6.34   37.86   31.94  6205
## Dimitrova (BUL)        3.18     1.80 12.88    3.02     6.37   40.28   30.89  6171
## Scheider (SWI)         2.57     1.86 11.58    1.74     6.05   47.50   28.50  6137
## Braun (FRG)            2.71     1.83 13.16    1.83     6.12   44.58   20.61  6109
## Ruotsalainen (FIN)     2.63     1.80 12.32    2.00     6.08   45.44   26.37  6101
## Yuping (CHN)           2.49     1.86 14.21    1.61     6.40   38.60   16.76  6087
## Hagger (GB)            2.95     1.80 12.75    1.14     6.34   35.76   24.95  5975
## Brown (USA)            2.35     1.83 12.69    1.78     6.13   44.34   17.00  5972
## Mulliner (GB)          2.03     1.71 12.68    1.69     6.10   37.76   25.41  5746
## Hautenauve (BEL)       2.38     1.77 11.81    1.00     5.99   35.68   29.53  5734
## Kytola (FIN)           2.11     1.77 11.66    0.92     5.75   39.48   30.08  5686
## Geremias (BRA)         2.19     1.71 12.95    1.11     5.50   39.64   19.41  5508
## Hui-Ing (TAI)          1.57     1.68 10.00    1.38     5.47   39.14   26.13  5290
## Jeong-Mi (KOR)         1.89     1.71 10.83    0.00     5.50   39.26   24.26  5289</code></pre>
<pre class="r"><code>hep1=scale(hep)


modelo&lt;-princomp(hep1[,-8])
summary(modelo)</code></pre>
<pre><code>## Importance of components:
##                           Comp.1    Comp.2    Comp.3     Comp.4     Comp.5     Comp.6
## Standard deviation     2.0355565 0.9281898 0.8917226 0.66881197 0.53468878 0.33034975
## Proportion of Variance 0.6176632 0.1284278 0.1185345 0.06667967 0.04261745 0.01626797
## Cumulative Proportion  0.6176632 0.7460909 0.8646255 0.93130515 0.97392260 0.99019057
##                             Comp.7
## Standard deviation     0.256524732
## Proportion of Variance 0.009809432
## Cumulative Proportion  1.000000000</code></pre>
<pre class="r"><code>modelo</code></pre>
<pre><code>## Call:
## princomp(x = hep1[, -8])
## 
## Standard deviations:
##    Comp.1    Comp.2    Comp.3    Comp.4    Comp.5    Comp.6    Comp.7 
## 2.0355565 0.9281898 0.8917226 0.6688120 0.5346888 0.3303497 0.2565247 
## 
##  7  variables and  24 observations.</code></pre>
<pre class="r"><code>modelo$loadings</code></pre>
<pre><code>## 
## Loadings:
##          Comp.1 Comp.2 Comp.3 Comp.4 Comp.5 Comp.6 Comp.7
## hurdles   0.450         0.174         0.199  0.847       
## highjump  0.315 -0.651  0.209 -0.557               -0.332
## shot      0.402         0.153  0.548 -0.672        -0.229
## run200m   0.427  0.185 -0.130  0.231  0.618 -0.333 -0.470
## longjump  0.451         0.270         0.122 -0.383  0.749
## javelin   0.242 -0.326 -0.881                       0.211
## run800m   0.303  0.657 -0.193 -0.574 -0.319              
## 
##                Comp.1 Comp.2 Comp.3 Comp.4 Comp.5 Comp.6 Comp.7
## SS loadings     1.000  1.000  1.000  1.000  1.000  1.000  1.000
## Proportion Var  0.143  0.143  0.143  0.143  0.143  0.143  0.143
## Cumulative Var  0.143  0.286  0.429  0.571  0.714  0.857  1.000</code></pre>
<pre class="r"><code># modelo$scores PUNTAJES OBTENIDOS POR LAS VARIABLES EN CADA UNO DE LAS COMPOMPONENTES</code></pre>
<p>Para efectos de escritura las variables fueron bautizadas así</p>
<table>
<thead>
<tr class="header">
<th>Variable</th>
<th>Traducción</th>
<th>Representación</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>hurdles</td>
<td>Barreras</td>
<td><span class="math inline">\(\Large X_1\)</span></td>
</tr>
<tr class="even">
<td>highjump</td>
<td>Salto de altura</td>
<td><span class="math inline">\(\Large X_2\)</span></td>
</tr>
<tr class="odd">
<td>shot</td>
<td>Tiro</td>
<td><span class="math inline">\(\Large X_3\)</span></td>
</tr>
<tr class="even">
<td>run200m</td>
<td>Corrida 200 m</td>
<td><span class="math inline">\(\Large X_4\)</span></td>
</tr>
<tr class="odd">
<td>longjump</td>
<td>Salto largo</td>
<td><span class="math inline">\(\Large X_5\)</span></td>
</tr>
<tr class="even">
<td>Javelin</td>
<td>Javalina</td>
<td><span class="math inline">\(\Large X_6\)</span></td>
</tr>
<tr class="odd">
<td>run800m</td>
<td>Corrida 800m</td>
<td><span class="math inline">\(\Large X_7\)</span></td>
</tr>
<tr class="even">
<td>Score</td>
<td>Puntaje</td>
<td><span class="math inline">\(\Large X_8\)</span></td>
</tr>
</tbody>
</table>
<p>Las componentes principales estimadas corresponden a:</p>
<p>Componente 1:</p>
<p><span class="math inline">\(\large
Z_1=0.45X_1+0.315X_2+0.4X_3+0.43X_4+0.45X_5+0.24X_6+0.3X_7\)</span>
explicando el 61.76% de la varianza Esta componente es una media de
todas las medidas obtenidas en heptátlon.</p>
<pre class="r"><code>barplot(modelo$loadings[1:7,1])</code></pre>
<p><img src="componentes_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<p>Componente 2: <span class="math inline">\(\large
Z_2=-0.65X_2-0.18X_4-0.32X_6+0.657X_7\)</span> explicando el 12.84% de
la varianza Esta componente contrapone el valor de la corrida de 800m
con el salto de altura, la corrida de 200m y la javalina.</p>
<pre class="r"><code>barplot(modelo$loadings[1:7,2])</code></pre>
<p><img src="componentes_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<p>Componente 3: <span class="math inline">\(\large
Z_3=0.174X_1+0.21X_2+0.153X_3-0.13X_4+0.27X_5-.881X_6-0.193X_7\)</span>
explicando el 11.85% de la varianza Esta componente contrapone la
javalina y la corrida de 800m con el resto de las variables</p>
<p>Componente 4: <span class="math inline">\(\large
Z_4=-0.55X_2+0.548X_3+0.231X_4-0.574X_7\)</span> explicando el 6.67% de
la varianza</p>
<p>Componente 5: <span class="math inline">\(\large
Z_5=0.2X_1-0.67X_3+0.62X_4+0.122X_5-0.32X_7\)</span> explicando el 4.26%
de la varianza</p>
<p>Componente 6: <span class="math inline">\(\large
Z_6=0.847X_1-0.333X_4-0.383X_5\)</span> explicando el 1.62% de la
varianza</p>
<p>Componente 7: <span class="math inline">\(\large
Z_7=-0.33X_2-0.23X_3-0.47X_4+0.75X_5+0.211X_7\)</span> explicando el
0.9% de la varianza</p>
<p>10.Los gráficos resultantes corresponden a:</p>
<pre class="r"><code>screeplot(modelo)</code></pre>
<p><img src="componentes_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
<pre class="r"><code>plot(modelo$scores[,1],modelo$scores[,2])
abline(h=0)
abline(v=0)</code></pre>
<p><img src="componentes_files/figure-html/unnamed-chunk-13-2.png" width="672" /></p>
<pre class="r"><code>##
par(mfrow=c(1,1))
biplot(modelo,col=c(2,4),cex=0.7)</code></pre>
<p><img src="componentes_files/figure-html/unnamed-chunk-13-3.png" width="672" /></p>
<ol start="10" style="list-style-type: decimal">
<li>Compare los resultados obtenidos</li>
</ol>
</div>

<br>
<hr>
<p><center>Copyright &copy; 2019, webpage made with Rmarkdown.</center></p>
<hr>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
